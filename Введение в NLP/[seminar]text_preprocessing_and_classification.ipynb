{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PcL7r1hqySq"
   },
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-sGLT0vp4jt"
   },
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn8EWAjnr18g"
   },
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:03.848766Z",
     "start_time": "2021-09-29T10:06:02.467450Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btBdBLxbgrNV",
    "outputId": "a7fe3f5c-0700-424e-e917-819007411386"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:03.879767Z",
     "start_time": "2021-09-29T10:06:03.850768Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq-QOD9NlO_Q",
    "outputId": "e254cf47-27ef-46b7-c503-2bc58d835f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ],
   "source": [
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "tokens = word_tokenize(data.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:03.895768Z",
     "start_time": "2021-09-29T10:06:03.881767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFDKUzkS6Mci",
    "outputId": "0bbbcfce-22d9-4ea0-8912-877a3ec02baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I was going home when she rung.', 'It was a surprise.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQoG7qznyuf5"
   },
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/natasha/natasha-logos/master/natasha.svg\">](https://github.com/natasha/natasha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPeApu2mwYxY"
   },
   "source": [
    "[Razdel](https://natasha.github.io/razdel/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.269773Z",
     "start_time": "2021-09-29T10:06:03.898770Z"
    },
    "id": "TwJj5Z2fvbeN"
   },
   "outputs": [],
   "source": [
    "!pip install -q razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.301768Z",
     "start_time": "2021-09-29T10:06:06.271766Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy58Xd_vve-z",
    "outputId": "b5a29b12-0873-4d64-c116-db9da2a2e4f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object find_substrings at 0x000002997831B890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize, sentenize\n",
    "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrmhCpNdQo6r"
   },
   "source": [
    "#### Регулярные выражения\n",
    "\n",
    "Исчерпывающий пост https://habr.com/ru/post/349860/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.317767Z",
     "start_time": "2021-09-29T10:06:06.303768Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IccRpcG06Mfd",
    "outputId": "1560c7ef-9dde-45e8-fb5b-0998190cf8ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['super', 'c', 'a', 'a', 'c', 'a', 'c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall('[abc]|up|super', word) # нахождение шаблонов\n",
    "# при нахождении любого символа в строке 'abc' мы его выводим\n",
    "# | позволяет задавать несколько шаблонов (оператор \"ИЛИ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.333767Z",
     "start_time": "2021-09-29T10:06:06.319767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['su', 'c', 'a', 'a', 'c', 'a', 'c']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[abc]|su|super', word) # 'super' не появился из-за обработки 'su' -- первые два символа стали считаться обработанными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.348768Z",
     "start_time": "2021-09-29T10:06:06.335767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Je8YPHLZPJW7",
    "outputId": "e731e421-3a25-4039-a40f-18d281952745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['49', '432', '312']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d{1,3}', 'These are some numbers: 49 and 432312') # \\d{1,3} означает поиск чисел от 1-значных до 3-значных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.363766Z",
     "start_time": "2021-09-29T10:06:06.350766Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fzde8MX1PJXA",
    "outputId": "5d638269-ee23-42df-8ed7-50dd63349c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to split text'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[,\\.?!]','','How, to? split. text!') # вместо найденных шаблона вставляется строка\n",
    "# вместо знаков в 1 аргументе (набор знаков) вставляем 2 аргумент в 3 аргумент "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.379766Z",
     "start_time": "2021-09-29T10:06:06.365767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyswV9nuPJXF",
    "outputId": "d4d23159-3e92-4e1d-f7d1-be6ea5dee092"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'can', 'play', 'football']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()\n",
    "# галочка означает всё кроме, тире означает диапазон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz0wIRkRswOQ"
   },
   "source": [
    "### Удаление неинформативных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trdPOBM2jEMf"
   },
   "source": [
    "#### N-граммы\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--466CQV1q--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/78nf1vryed8h1tz05fim.gif\" height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.395766Z",
     "start_time": "2021-09-29T10:06:06.381767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYEBfCxLic3R",
    "outputId": "1e6f9ac7-a21f-427a-a421-6d936f2f6b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all',), ('work',), ('and',), ('no',), ('play',)]\n",
      "[('all', 'work'), ('work', 'and'), ('and', 'no'), ('no', 'play'), ('play', 'makes')]\n"
     ]
    }
   ],
   "source": [
    "unigram = list(nltk.ngrams(tokens, 1)) # позволяет оценить популярность слова\n",
    "bigram = list(nltk.ngrams(tokens, 2)) # позволяет оценить популярнось взаимодействия двух слов\n",
    "print(unigram[:5])\n",
    "print(bigram[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.411771Z",
     "start_time": "2021-09-29T10:06:06.396769Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AFeZqejmWwN",
    "outputId": "8f9fff61-090e-4e05-adc3-f9052610d5bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Популярные униграммы:  [(('all',), 2), (('work',), 2), (('and',), 2), (('no',), 2), (('play',), 2)]\n",
      "Популярные биграммы:  [(('all', 'work'), 2), (('work', 'and'), 2), (('and', 'no'), 2), (('no', 'play'), 2), (('play', 'makes'), 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "print('Популярные униграммы: ', FreqDist(unigram).most_common(5))\n",
    "print('Популярные биграммы: ', FreqDist(bigram).most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### с помощью n-грамм можно уменьшить словарь убрав редкие или часто встречающееся n-граммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слово которое встречается 1 раз может быть опечаткой\n",
    "### Слова которые встречаются много раз являются служебными (для грамматики)\n",
    "### Шаблоны также могут быть вредны (шаблон электронного письма)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W3jJ56hnBFu"
   },
   "source": [
    "#### Стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.427765Z",
     "start_time": "2021-09-29T10:06:06.415767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIBwQ3nBnEfV",
    "outputId": "5f6c8413-a652-4ea6-9b6d-450e099075cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.443768Z",
     "start_time": "2021-09-29T10:06:06.429767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1nk-TqEslRl",
    "outputId": "e56801a2-c8bf-479a-f1e8-ed312cdb3a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mustn', 'y', 'doing', \"won't\", 'more', 'll', \"it's\", 'those', \"weren't\", 'ours', 'his', 'is', 've', 'some', 'because', \"isn't\", 'out', 'own', 'having', 'before', 'where', 'no', 'isn', \"mightn't\", 'why', 'then', 'doesn', 'wouldn', 'did', 'he', 'aren', 'yours', 'had', 'off', \"couldn't\", 'ain', 'her', 'your', 'ourselves', 'you', \"wasn't\", 'there', \"haven't\", 'same', \"should've\", 'not', 'them', 'until', 'didn', 'any', \"aren't\", 'haven', 'what', 'these', 'for', \"don't\", 're', 'only', 'hasn', 'if', 'into', 'very', 'too', 'me', \"hasn't\", 'hers', 'ma', \"didn't\", 'himself', \"that'll\", 'been', 'here', 'down', 'to', 'between', 'yourselves', 'on', 'under', 'as', 'shan', 'once', 'all', 's', 'can', 'o', 'she', 'hadn', 'itself', 'through', 'further', 'him', 'couldn', 'now', \"she's\", 'd', 'than', 'has', 'this', 'won', 'themselves', 'that', 'when', 'such', 'myself', 'theirs', 'an', 'above', 'in', 'nor', 't', \"shan't\", 'against', 'don', 'below', 'its', 'does', 'each', 'while', \"hadn't\", \"mustn't\", \"needn't\", 'wasn', 'our', 'am', \"you've\", 'needn', 'both', 'do', \"doesn't\", 'mightn', 'should', 'by', 'the', 'from', 'was', 'are', 'about', 'herself', 'again', 'at', 'they', 'which', 'were', \"you'll\", \"wouldn't\", 'yourself', 'so', 'being', 'who', \"you'd\", 'will', 'be', 'how', \"shouldn't\", 'other', 'up', 'their', 'or', 'shouldn', 'have', 'with', 'a', 'during', 'my', 'but', 'm', 'i', 'we', 'after', 'whom', \"you're\", 'few', 'of', 'most', 'it', 'and', 'just', 'weren', 'over'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.458765Z",
     "start_time": "2021-09-29T10:06:06.445767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'или', 'потому', 'ни', 'много', 'его', 'все', 'ты', 'всего', 'том', 'и', 'ли', 'в', 'есть', 'ж', 'сам', 'нет', 'ему', 'так', 'ведь', 'теперь', 'про', 'при', 'тут', 'чуть', 'для', 'у', 'надо', 'они', 'перед', 'такой', 'потом', 'моя', 'он', 'о', 'нас', 'им', 'что', 'только', 'хорошо', 'же', 'еще', 'ей', 'не', 'нибудь', 'об', 'ним', 'было', 'кто', 'но', 'лучше', 'зачем', 'ну', 'два', 'тот', 'мой', 'она', 'будто', 'за', 'другой', 'где', 'меня', 'над', 'этой', 'более', 'всю', 'конечно', 'впрочем', 'чтобы', 'по', 'того', 'опять', 'из', 'совсем', 'свою', 'их', 'со', 'себя', 'этого', 'без', 'разве', 'него', 'до', 'почти', 'то', 'да', 'если', 'тебя', 'под', 'ничего', 'никогда', 'них', 'чтоб', 'всегда', 'через', 'там', 'чем', 'во', 'на', 'нельзя', 'мне', 'можно', 'быть', 'сейчас', 'какой', 'наконец', 'к', 'вот', 'как', 'я', 'чего', 'здесь', 'нее', 'больше', 'с', 'уже', 'мы', 'тоже', 'между', 'ее', 'хоть', 'эту', 'иногда', 'себе', 'вам', 'может', 'когда', 'а', 'всех', 'была', 'от', 'был', 'эти', 'тогда', 'уж', 'после', 'бы', 'вас', 'были', 'даже', 'ней', 'будет', 'вдруг', 'вы', 'один', 'тем', 'куда', 'три', 'какая', 'этом', 'этот', 'раз'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('russian'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.473768Z",
     "start_time": "2021-09-29T10:06:06.460767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFkfJm9ktAVa",
    "outputId": "11e85df4-d2e6-4f9f-ff23-f6cc50fee22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in tokens if word not in stopWords]) # удалили стоп-слова из списка tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### в случае классификации текста по тональности слово 'нет'  может быть важно (например, в отзывах к фильмам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.489768Z",
     "start_time": "2021-09-29T10:06:06.475769Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5QoqlHiS83f",
    "outputId": "628de9cf-0e10-48ee-e743-448512a7cd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation) # помогает разделить предложения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh-MYv6e-skM"
   },
   "source": [
    "#### Стемминг vs Лемматизация\n",
    "* ‘Caring’ -> Лемматизация -> ‘Care’\n",
    "* ‘Caring’ -> Стемминг -> ‘Car’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Борьба с различными видами слова (слово имеет разные формы, но одно и тоже значение)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAUKc1oTiQjf"
   },
   "source": [
    "### Стемминг\n",
    "* процесс нахождения основы слова для заданного исходного слова (убираем из конца несколько символов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.505765Z",
     "start_time": "2021-09-29T10:06:06.490766Z"
    },
    "id": "iRVu-TrON4sq"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "words = [\"game\", \"gaming\", \"gamed\", \"games\", \"compacted\"]\n",
    "words_ru = ['корова', 'мальчики', 'мужчины', 'столом', 'убежала']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.521766Z",
     "start_time": "2021-09-29T10:06:06.507766Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9HTGfsBN9eX",
    "outputId": "e4392b8d-20cb-4a60-9a09-1326d2fdf3f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['game', 'game', 'game', 'game', 'compact']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer() # более старый стеммер\n",
    "list(map(ps.stem, words)) # хороший пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.537768Z",
     "start_time": "2021-09-29T10:06:06.523767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5qZkB-oODkW",
    "outputId": "b2094c0b-6f4f-431b-801e-107fac105e9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['коров', 'мальчик', 'мужчин', 'стол', 'убежа']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = SnowballStemmer(language='russian') # усовершенствованная версия PorterStemmer (более новая)\n",
    "list(map(ss.stem, words_ru)) # плохой пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbTXbi9FJXr1"
   },
   "source": [
    "### Лематизация\n",
    "* процесс приведения словоформы к лемме — её нормальной (словарной) форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.553766Z",
     "start_time": "2021-09-29T10:06:06.540767Z"
    },
    "id": "QF4nnEz00thb"
   },
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "\n",
    "raw_ru = \"\"\"Не существует научных доказательств в пользу эффективности НЛП, оно \n",
    "признано псевдонаукой. Систематические обзоры указывают, что НЛП основано на \n",
    "устаревших представлениях об устройстве мозга, несовместимо с современной \n",
    "неврологией и содержит ряд фактических ошибок.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:06.775765Z",
     "start_time": "2021-09-29T10:06:06.758769Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mljfOAC4n21I",
    "outputId": "5bf02a63-b1cd-4923-cef6-610c496bad73"
   },
   "outputs": [],
   "source": [
    "#!pip install -q pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:07.203838Z",
     "start_time": "2021-09-29T10:06:06.917838Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Zez7jnXl5uJ",
    "outputId": "51782962-44ee-431d-c025-5a70226bf9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "не существовать научный доказательство в польза эффективность нлп, оно \n",
      "признать псевдонаукой. систематический обзор указывают, что нлп основать на \n",
      "устаревший представление о устройство мозга, несовместимый с современный \n",
      "неврология и содержать ряд фактический ошибок.\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "import pymorphy2 # rule-based библиотека (основана только на слове, контекст не смотрится)\n",
    "# у нас нас есть правилао и мы слово по этому правилу интрепретируем\n",
    "morph = pymorphy2.MorphAnalyzer() # анализатор морфологии\n",
    "pymorphy_results = list(map(lambda x: morph.parse(x), raw_ru.split(' ')))\n",
    "print(' '.join([res[0].normal_form for res in pymorphy_results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:07.265837Z",
     "start_time": "2021-09-29T10:06:07.257842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='научных', tag=OpencorporaTag('ADJF,Qual plur,gent'), normal_form='научный', score=0.774193, methods_stack=((DictionaryAnalyzer(), 'научных', 12, 21),)),\n",
       " Parse(word='научных', tag=OpencorporaTag('ADJF,Qual plur,loct'), normal_form='научный', score=0.209677, methods_stack=((DictionaryAnalyzer(), 'научных', 12, 26),)),\n",
       " Parse(word='научных', tag=OpencorporaTag('ADJF,Qual anim,plur,accs'), normal_form='научный', score=0.016129, methods_stack=((DictionaryAnalyzer(), 'научных', 12, 23),))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymorphy_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:12.159841Z",
     "start_time": "2021-09-29T10:06:07.435842Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7MDqIvWib4O",
    "outputId": "93dee74a-4769-4473-a6bb-e3e0b71bad2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\.conda\\envs\\deep\\lib\\site-packages\\spacy\\util.py:730: UserWarning: [W095] Model 'en_core_web_sm' (3.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dennis : listen , strange woman lie in pond distribute sword \n",
      " be no basis for a system of government .   Supreme executive power derive from \n",
      " a mandate from the masse , not from some farcical aquatic ceremony .\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "import spacy # нейросетевой подход (с рассмотрением контекста)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_results = nlp(raw)\n",
    "print(' '.join([token.lemma_ for token in spacy_results]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVC5gjCRk5bD"
   },
   "source": [
    "[Сравнение PyMorphy2 и PyMystem3](https://habr.com/ru/post/503420/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минус PyMystem3 в долгой инициализации (хотя если объединить все тексты, лемматизируем, затем разделим, то будет быстро)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yim_NVYA6MeS"
   },
   "source": [
    "### Part-of-Speech (определение части речи)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### уменьшили словарь и его помощью описываем текст (слово признак текста)\n",
    "### признаки слов тоже могут быть признаками текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:12.175838Z",
     "start_time": "2021-09-29T10:06:12.161838Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2t_MamYKqbSk",
    "outputId": "17c3a9fc-4fc2-4d0f-9353-a76e653cf6f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', OpencorporaTag('PRCL')),\n",
       " ('существовать', OpencorporaTag('VERB,impf,intr sing,3per,pres,indc')),\n",
       " ('научный', OpencorporaTag('ADJF,Qual plur,gent')),\n",
       " ('доказательство', OpencorporaTag('NOUN,inan,neut plur,gent')),\n",
       " ('в', OpencorporaTag('PREP')),\n",
       " ('польза', OpencorporaTag('NOUN,inan,femn sing,accs')),\n",
       " ('эффективность', OpencorporaTag('NOUN,inan,femn sing,gent')),\n",
       " ('нлп,', OpencorporaTag('UNKN')),\n",
       " ('оно', OpencorporaTag('NPRO,neut,3per,Anph sing,nomn'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "[(res[0].normal_form, res[0].tag) for res in pymorphy_results[:9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:12.191837Z",
     "start_time": "2021-09-29T10:06:12.178839Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Doa85yw6JWea",
    "outputId": "794ec981-0378-4020-e316-f1e2045d8949"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dennis', 'NOUN'),\n",
       " (':', 'PUNCT'),\n",
       " ('listen', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('strange', 'ADJ'),\n",
       " ('woman', 'NOUN'),\n",
       " ('lie', 'VERB')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "[(token.lemma_, token.pos_) for token in spacy_results[:7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:12.207841Z",
     "start_time": "2021-09-29T10:06:12.193837Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVGJLVjLtFDp",
    "outputId": "c01be447-80df-4477-c875-28889e7b7e36"
   },
   "outputs": [],
   "source": [
    "#!pip install -q rnnmorph"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T13:52:45.892047Z",
     "start_time": "2021-09-28T13:52:42.810355Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ms2yeEFqrtZ",
    "outputId": "dd9131e0-82bd-46a7-e54e-1bed989ff9fb"
   },
   "source": [
    "# 3\n",
    "from rnnmorph.predictor import RNNMorphPredictor # rnnmorph работает на реккурентных нейросетях\n",
    "predictor = RNNMorphPredictor(language=\"ru\")\n",
    "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
    "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]\n",
    "# не работает из-за нового numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_Slt2R76Mgk"
   },
   "source": [
    "### Named entities recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:14.925421Z",
     "start_time": "2021-09-29T10:06:14.906420Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvB43ZHT6MhR",
    "outputId": "3d490cfc-0b7f-4cb1-f655-7e9ca16f6a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:15.084421Z",
     "start_time": "2021-09-29T10:06:15.063419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### если привести всё к нижнему регистру, то имена компаний могут не распознаться (Apple - apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## при работе с текстом нет идеального пайплайна (для каждого он свой: нужно предварительно анализировать текст)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0-_oFwwqAwN"
   },
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIwDfmrYOMfi"
   },
   "source": [
    "### Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6DaLniC6MhY"
   },
   "source": [
    "#### 20 newsgroups\n",
    "Датасет с 18000 новостей, сгруппированных по 20 темам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:16.933245Z",
     "start_time": "2021-09-29T10:06:16.636251Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uS7IJNW6Mhb",
    "outputId": "ebc2f876-92c7-4032-a422-d51b2e3c2c4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:17.387263Z",
     "start_time": "2021-09-29T10:06:17.371265Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMbagpJE6Mhh",
    "outputId": "152aa470-abef-47d0-deb1-2bcef6280e07",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:07:38.746488Z",
     "start_time": "2021-09-29T10:07:38.727487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C:\\\\Users\\\\BIT\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\rec.autos\\\\102994',\n",
       "       'C:\\\\Users\\\\BIT\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\comp.sys.mac.hardware\\\\51861',\n",
       "       'C:\\\\Users\\\\BIT\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\comp.sys.mac.hardware\\\\51879',\n",
       "       ...,\n",
       "       'C:\\\\Users\\\\BIT\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\comp.sys.ibm.pc.hardware\\\\60695',\n",
       "       'C:\\\\Users\\\\BIT\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\comp.graphics\\\\38319',\n",
       "       'C:\\\\Users\\\\BIT\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\rec.motorcycles\\\\104440'],\n",
       "      dtype='<U93')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:06:18.058714Z",
     "start_time": "2021-09-29T10:06:18.046713Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QReW1K46Mhn",
    "outputId": "d243da37-1e2a-4a19-e22b-960f369915c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZtRIQmNQ4H0"
   },
   "source": [
    "#### Рассмотрим подвыборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:08:22.574025Z",
     "start_time": "2021-09-29T10:08:22.260939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhwuCp5B6Mhz",
    "outputId": "53f9bb20-9762-49b3-f2f2-0327bde7d576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:09:02.007899Z",
     "start_time": "2021-09-29T10:09:01.990904Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOREsv336MiA",
    "outputId": "f91d5c50-4e47-4ba9-cbbe-37acf3df847a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: rych@festival.ed.ac.uk (R Hawkes)\n",
      "Subject: 3DS: Where did all the texture rules go?\n",
      "Lines: 21\n",
      "\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "======================================================================\n",
      "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
      "Virtual Environment Laboratory\n",
      "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
      "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:10:06.735631Z",
     "start_time": "2021-09-29T10:10:06.721634Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBnDG-TN6MiF",
    "outputId": "33bc189f-0161-4287-bf48-e78fcdadd683"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XlZYpodRYDI"
   },
   "source": [
    "#### TF-IDF(напоминание)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohUk2n3jRbNp"
   },
   "source": [
    "$n_{\\mathbb{d}\\mathbb{w}}$ - число вхождений слова $\\mathbb{w}$ в документ $\\mathbb{d}$;<br>\n",
    "$N_{\\mathbb{w}}$ - число документов, содержащих $\\mathbb{w}$;<br>\n",
    "$N$ - число документов; <br><br>\n",
    "\n",
    "$p(\\mathbb{w}, \\mathbb{d}) = N_{\\mathbb{w}} / N$ - вероятность наличия слова $\\mathbb{w}$ в любом документе $\\mathbb{d}$\n",
    "<br>\n",
    "$P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}}}$ - вероятность встретить $n_{\\mathbb{d}\\mathbb{w}}$ раз слово $\\mathbb{w}$ в документе $\\mathbb{d}$<br><br>\n",
    "\n",
    "$-\\log{P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}})} = n_{\\mathbb{d}\\mathbb{w}} \\cdot \\log{(N / N_{\\mathbb{w}})} = TF(\\mathbb{w}, \\mathbb{d}) \\cdot IDF(\\mathbb{w})$<br><br>\n",
    "\n",
    "$TF(\\mathbb{w}, \\mathbb{d}) = n_{\\mathbb{d}\\mathbb{w}}$ - term frequency;<br>\n",
    "$IDF(\\mathbb{w}) = \\log{(N /N_{\\mathbb{w}})}$ - inverted document frequency;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чем меньше вероятность слова w, тем оно важнее для документа D\n",
    "### Чем TF-IDF больше, тем важнее слово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQvcMiFH6MiM"
   },
   "source": [
    "#### Давайте векторизуем эти тексты с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:18:58.517659Z",
     "start_time": "2021-09-29T10:18:58.511703Z"
    },
    "id": "98LLAoZO6MiU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baXLU0lj6MiY"
   },
   "source": [
    "#### Некоторые параметры: \n",
    "* input : string {‘filename’, ‘file’, ‘content’}\n",
    "*  lowercase : boolean, default True\n",
    "*  preprocessor : callable or None (default)\n",
    "*  tokenizer : callable or None (default)\n",
    "*  stop_words : string {‘english’}, list, or None (default)\n",
    "*  ngram_range : tuple (min_n, max_n)\n",
    "*  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "*  min_df : float in range [0.0, 1.0] or int, default=1\n",
    "*  max_features : int or None, default=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-m81BJxZFwJ"
   },
   "source": [
    "#### Перебор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:20:22.128365Z",
     "start_time": "2021-09-29T10:20:21.424364Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f7padHL6MiZ",
    "outputId": "a60445fa-ad78-4efb-ad13-51a8a59f5650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 34118)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:20:32.448333Z",
     "start_time": "2021-09-29T10:20:31.728331Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nf2s4HCY6Mie",
    "outputId": "159178a7-2cb6-438f-93fd-2532ec410368"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 42307)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Число признаков уменьшилось на 8 тысяч (с 42307 до 34118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:21:30.686736Z",
     "start_time": "2021-09-29T10:21:30.636733Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hwlTWapZR8M",
    "outputId": "e2ced468-e4d8-497c-8f27-4262fba6eea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000',\n",
       " '000000',\n",
       " '000005102000',\n",
       " '000021',\n",
       " '000062David42',\n",
       " '0000VEC',\n",
       " '0001']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### в признаки записались неинформативные слова, поэтому ограничиваем TF-IDF на min и max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:25:22.059016Z",
     "start_time": "2021-09-29T10:25:21.458016Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYfpk0ds6Mij",
    "outputId": "a605ac46-771c-44cd-c5c9-0774625740d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 9)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df, max_df\n",
    "vectorizer = TfidfVectorizer(min_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:25:22.262873Z",
     "start_time": "2021-09-29T10:25:22.254875Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ookt99atZ8sS",
    "outputId": "48acde37-ce1c-46e4-e131-bf3d99a36d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'from', 'in', 'lines', 'of', 'organization', 'subject', 'the', 'to']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names() # самые часто встречаемые слова (находятся в шаблоне) (не важны для классификации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:25:23.844766Z",
     "start_time": "2021-09-29T10:25:23.236763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e_h6c0X6Mim",
    "outputId": "1164d096-e211-478d-cb27-cc782b71690e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2391)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.8) # ограничили слова на min и max tf-idf\n",
    "# уменьшили кол-во признаков до 2391\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:26:29.869927Z",
     "start_time": "2021-09-29T10:26:27.290696Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUhOyx4NihL0",
    "outputId": "c5bdb88a-8a3b-4654-b0b4-9a8a5c79e132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1236)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram_range\n",
    "# уменьшили кол-во признаков до 1236\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.03, max_df=0.9)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:30:55.269978Z",
     "start_time": "2021-09-29T10:30:53.291874Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "7074cdSF6MjC",
    "outputId": "378752c9-3ae1-436f-d3c5-568363006d90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'oh , think landed miracle work , thirst hunger come conference bird'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# стоп-слова, preproc\n",
    "from nltk.corpus import stopwords # импортировали стоп-слова из модуля nltk.corpus\n",
    "stopWords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preproc_nltk(text):\n",
    "    #text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
    "    # text разбивается на слова с помощью word_tokenize c lower(), убираются стоп слова и лемматизируются WordNetLemmatizer \n",
    "    # и конкатерируются в исходную строку через пробелы \n",
    "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
    "\n",
    "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
    "preproc_nltk(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:31:15.340770Z",
     "start_time": "2021-09-29T10:31:05.208772Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIW3hCSy6MjX",
    "outputId": "338c71af-0740-4c8f-c058-684dd087ad97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time # замер скорости с preproc_nltk\n",
    "vectorizer = TfidfVectorizer(preprocessor=preproc_nltk) # препроцесс в векторайзере\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:33:10.765142Z",
     "start_time": "2021-09-29T10:33:10.038908Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lUmyAzJEB1SU",
    "outputId": "f7b9009d-14f0-4436-e2e5-b7082f7aa6b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh , I think I land miracle work ,   thirst hunger come conference bird'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preproc_spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "texts = newsgroups_train.data.copy()\n",
    "\n",
    "def preproc_spacy(text):\n",
    "    spacy_results = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in spacy_results if token.lemma_ not in stopWords])\n",
    "preproc_spacy(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:34:37.250841Z",
     "start_time": "2021-09-29T10:33:48.623753Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C5Ent0nG5zj",
    "outputId": "1af1abe9-bc09-480f-ced0-5caf77a7e0d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_texts = []\n",
    "for doc in nlp.pipe(texts, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]): # ручной препроцесс\n",
    "    # также можно делать парс текста и решается задача named entities recognition\n",
    "    # убрали стоп-слова и лемматизировали с использованием pipeline из spacy\n",
    "    new_texts.append(' '.join([tok.lemma_ for tok in doc if tok.lemma not in stopWords]))\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:37:31.831922Z",
     "start_time": "2021-09-29T10:37:31.827923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: rych@festival.ed.ac.uk (R Hawkes)\n",
      "Subject: 3DS: Where did all the texture rules go?\n",
      "Lines: 21\n",
      "\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "======================================================================\n",
      "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
      "Virtual Environment Laboratory\n",
      "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
      "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:37:10.378282Z",
     "start_time": "2021-09-29T10:37:10.369283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from : rych@festival.ed.ac.uk ( R Hawkes ) \n",
      " subject : 3ds : where do all the texture rule go ? \n",
      " line : 21 \n",
      "\n",
      " hi , \n",
      "\n",
      " I 've notice that if you only save a model ( with all your mapping plane \n",
      " position carefully ) to a .3ds file that when you reload it after restart \n",
      " 3ds , they be give a default position and orientation .   but if you save \n",
      " to a .PRJ file their position / orientation be preserve .   do anyone \n",
      " know why this information be not store in the .3ds file ?   nothing be \n",
      " explicitly say in the manual about save texture rule in the .prj file . \n",
      " I 'd like to be able to read the texture rule information , do anyone have \n",
      " the format for the .PRJ file ? \n",
      "\n",
      " be the .cel file format available from somewhere ? \n",
      "\n",
      " rych \n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      " Rycharde Hawkes \t\t\t\t email : rych@festival.ed.ac.uk \n",
      " Virtual Environment Laboratory \n",
      " Dept . of psychology \t\t\t Tel   : +44 31 650 3426 \n",
      " Univ . of Edinburgh \t\t\t fax   : +44 31 667 0150 \n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### скорее всего у spacy получилось лучше чем у nltk (но nltk быстрее)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lXAPHZA6Mj0"
   },
   "source": [
    "#### Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:41:42.285960Z",
     "start_time": "2021-09-29T10:41:37.898591Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZYcRkQ86Mj1",
    "outputId": "72392257-a3e9-405a-9238-169e7c0d115c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " 'atheism',\n",
       " 'center',\n",
       " 'edu keith',\n",
       " 'history',\n",
       " 'list',\n",
       " 'of course',\n",
       " 'regard',\n",
       " 'system',\n",
       " 'uk']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=1000)\n",
    "vectors = vectorizer.fit_transform(new_texts) # использовали ручной препроцес с использованием spacy\n",
    "vectorizer.get_feature_names()[::100]\n",
    "# каждое письмо заменили на вектор (1,1000) со значениями tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQHTlj3q6Mj6"
   },
   "source": [
    "#### Можем посмотреть на косинусную меру между векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:45:42.474776Z",
     "start_time": "2021-09-29T10:45:42.451777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.09244108,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.08977755,\n",
       "         0.09028781, 0.04727086, 0.        , 0.        , 0.18679336,\n",
       "         0.20551589, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.06969078, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.09551821, 0.        , 0.08504219, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.13241869, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.08722075, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.09080882,\n",
       "         0.09098496, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.05209291, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.05341256, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.19716027,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.09152101, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.09981158, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49073929, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06096153, 0.        , 0.        , 0.20844538,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.06391575, 0.        , 0.05928571,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.07935379, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.09858014, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12451158, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.14028734,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.1663371 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.04944887, 0.        , 0.        , 0.        , 0.10483376,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.05318128, 0.09170231,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.1054603 ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08228237, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.05889599, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.29291184, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06924621, 0.10058098, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.29719616, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.30658646,\n",
       "         0.05169229, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.06264639, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.04378198, 0.06733894, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.05521971, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.17383791, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.07147302,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.06096153, 0.06653626, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06379762, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.05534501, 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.todense()[0] # вектор tf-idf первого письма (его численное представление)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:44:02.401655Z",
     "start_time": "2021-09-29T10:44:02.384654Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VA8Fn5I46Mi0",
    "outputId": "632e1709-57eb-416c-f579-eaad32195408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = vectors.todense()[0]\n",
    "(vector != 0).sum() # кол-во ненулевых значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:44:04.146276Z",
     "start_time": "2021-09-29T10:44:04.138274Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jo4fKtAXqCl-",
    "outputId": "81b8f469-e889-4c92-942e-63f0a526311d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:49:14.033688Z",
     "start_time": "2021-09-29T10:49:14.021684Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsVQhR9y6Mj8",
    "outputId": "378d430b-f6d2-4f76-e2d9-bda51d8479de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "type(vectors) # sparse-matrix -- разреженная матрица (позволяет экономно её хранить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:49:17.545732Z",
     "start_time": "2021-09-29T10:49:17.484737Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kweWqI8ztDwC",
    "outputId": "b729a5b3-fd07-4bc5-99fe-75909a02cd8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.9031465093412"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(map(lambda x: (x != 0).sum(), vectors.todense()))) # в среднем 89 ненулевых значений в векторах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:50:44.529478Z",
     "start_time": "2021-09-29T10:50:44.511476Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS2G0ZZC6MkN",
    "outputId": "7dc5ec75-cf8e-4c15-a759-631dc63c6c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vectors = vectors.todense()\n",
    "dense_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:52:35.824608Z",
     "start_time": "2021-09-29T10:52:35.806602Z"
    },
    "id": "LGgb5aP76MkU"
   },
   "outputs": [],
   "source": [
    "def cosine_sim(v1, v2): # косинусная схожесть\n",
    "    # v1, v2 (1 x dim)\n",
    "    return np.array(v1 @ v2.T / norm(v1) / norm(v2))[0][0]\n",
    "# косинусное расстояние = 1 - косинусная схожесть\n",
    "# чем меньше расстояние тем лучше ; чем больше схожесть тем лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:52:35.979080Z",
     "start_time": "2021-09-29T10:52:35.967080Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_FrKM6k6MkY",
    "outputId": "462e7b13-1aa4-4506-e605-49feaf5ab150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(dense_vectors[0], dense_vectors[0]) # схожесть слова с самим собой равна 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:52:58.397862Z",
     "start_time": "2021-09-29T10:52:58.378861Z"
    },
    "id": "L1XF-isH6Mkh"
   },
   "outputs": [],
   "source": [
    "cosines = []\n",
    "for i in range(10):\n",
    "    cosines.append(cosine_sim(dense_vectors[0], dense_vectors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:53:00.426692Z",
     "start_time": "2021-09-29T10:53:00.412097Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODwgYEbe6Mkl",
    "outputId": "b6959653-9dea-438a-9590-9c2afedceab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.041994526657641695,\n",
       " 0.005915875089722349,\n",
       " 0.060537611541265704,\n",
       " 0.07089007602730961,\n",
       " 0.0473229115770439,\n",
       " 0.0336722125307721,\n",
       " 0.22677999604707713,\n",
       " 0.030437028116848494,\n",
       " 0.04013968640436646]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1, 3, 2, 0, 2, 0, 2, 1, 2, 1] метки классов этих векторов\n",
    "cosines # схожести между вектором 0 и векторами 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRZyJP3c6Mkq"
   },
   "source": [
    "#### Обучим любую известную модель на полученных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:55:08.853425Z",
     "start_time": "2021-09-29T10:55:08.839430Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RDfl72A6Mks",
    "outputId": "881d3b15-aa8b-479b-ce66-a06e91e47824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627,), (407,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем модели машинного обучения и разбиваем выборку\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(dense_vectors, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:55:19.561521Z",
     "start_time": "2021-09-29T10:55:18.082519Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjfwduNp6Mlo",
    "outputId": "8d86a9ea-2a38-487a-8147-1b2d6f5c7ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:55:52.025195Z",
     "start_time": "2021-09-29T10:55:51.494084Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6Evwipx6Mlv",
    "outputId": "943c6663-6329-4ad4-d040-1f54b4ea80f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9238329238329238"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T10:56:02.913060Z",
     "start_time": "2021-09-29T10:56:02.514062Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EBZRbXT6Mly",
    "outputId": "1b992f83-1c25-4e3d-f536-b284d660e1e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9164619164619164"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "accuracy_score(y_test, sgd.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### без обучения качество примерно 0.25 (т.к 4 класса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5OAwBJ0LuPb"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeddings -- числовое предствление текстов (вектор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:00:39.019431Z",
     "start_time": "2021-09-29T10:56:57.125088Z"
    },
    "id": "SKLGAYPvPJcJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "embeddings_pretrained = api.load('glove-twitter-25')\n",
    "# embeddings обученные на твиттере (внутри вектора размерности 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:04:45.202526Z",
     "start_time": "2021-09-29T11:04:30.920132Z"
    },
    "id": "fmH3vc7FSCuP"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec \n",
    "\n",
    "proc_words = [preproc_nltk(text).split() for text in newsgroups_train.data]\n",
    "embeddings_trained = Word2Vec(proc_words, # обучаем свои embeddings с помощью Word2Vec\n",
    "                 size=100,                 # размерность вектора\n",
    "                 min_count=3,             # минимальное кол-во вхожений слова в текста\n",
    "                 window=3                 # с окном размерности 3 смотрим на 2 влево и на 2 вправо от слова\n",
    "                ).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:07:33.909755Z",
     "start_time": "2021-09-29T11:07:33.897751Z"
    },
    "id": "0Lq20widPJcO"
   },
   "outputs": [],
   "source": [
    "def vectorize_sum(comment, embeddings):\n",
    "    \"\"\"\n",
    "    реализация функции, которая преобразует предварительно обработанный комментарий в сумму векторов токенов\n",
    "    \"\"\"\n",
    "    embedding_dim = embeddings.vectors.shape[1] # размерность вектора из embeddings\n",
    "    features = np.zeros([embedding_dim], dtype='float32') # иницализация фичей нулями\n",
    "\n",
    "    for word in preproc_nltk(comment).split():\n",
    "        if word in embeddings:\n",
    "            features += embeddings[f'{word}'] # сложили все вектора слов в тексте и получили вектор описывающий текст\n",
    "    \n",
    "    return features\n",
    "# минус -- достаточно примитивно\n",
    "# для аккумуляции знаний со всех эмбидингов можно использовать CNN, RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:24:28.250881Z",
     "start_time": "2021-09-29T11:24:28.215882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<user>',\n",
       " '.',\n",
       " ':',\n",
       " 'rt',\n",
       " ',',\n",
       " '<repeat>',\n",
       " '<hashtag>',\n",
       " '<number>',\n",
       " '<url>',\n",
       " '!',\n",
       " 'i',\n",
       " 'a',\n",
       " '\"',\n",
       " 'the',\n",
       " '?',\n",
       " 'you',\n",
       " 'to',\n",
       " '(',\n",
       " '<allcaps>',\n",
       " '<elong>',\n",
       " ')',\n",
       " 'me',\n",
       " 'de',\n",
       " '<smile>',\n",
       " '！',\n",
       " 'que',\n",
       " 'and',\n",
       " '。',\n",
       " '-',\n",
       " 'my',\n",
       " 'no',\n",
       " '、',\n",
       " 'is',\n",
       " 'it',\n",
       " '…',\n",
       " 'in',\n",
       " 'n',\n",
       " 'for',\n",
       " '/',\n",
       " 'of',\n",
       " 'la',\n",
       " \"'s\",\n",
       " '*',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'that',\n",
       " 'on',\n",
       " 'y',\n",
       " \"'\",\n",
       " 'e',\n",
       " 'o',\n",
       " 'u',\n",
       " 'en',\n",
       " 'this',\n",
       " 'el',\n",
       " 'so',\n",
       " 'be',\n",
       " \"'m\",\n",
       " 'with',\n",
       " 'just',\n",
       " '>',\n",
       " 'your',\n",
       " '^',\n",
       " 'like',\n",
       " 'have',\n",
       " 'te',\n",
       " 'at',\n",
       " '？',\n",
       " 'love',\n",
       " 'se',\n",
       " 'are',\n",
       " '<',\n",
       " 'm',\n",
       " 'r',\n",
       " 'if',\n",
       " 'all',\n",
       " 'b',\n",
       " '・',\n",
       " 'not',\n",
       " 'but',\n",
       " 'we',\n",
       " 'es',\n",
       " 'ya',\n",
       " '&',\n",
       " 'follow',\n",
       " 'up',\n",
       " 'what',\n",
       " 'get',\n",
       " 'lol',\n",
       " 'un',\n",
       " '♥',\n",
       " 'lo',\n",
       " 'when',\n",
       " 'was',\n",
       " '“',\n",
       " '”',\n",
       " 'one',\n",
       " 'por',\n",
       " 'si',\n",
       " 'out',\n",
       " '_',\n",
       " 'mi',\n",
       " 'can',\n",
       " '<sadface>',\n",
       " 'من',\n",
       " '♡',\n",
       " '´',\n",
       " 'he',\n",
       " 'con',\n",
       " 'they',\n",
       " 'now',\n",
       " 'go',\n",
       " '،',\n",
       " 'para',\n",
       " 'los',\n",
       " 'know',\n",
       " 'haha',\n",
       " 'good',\n",
       " 'tu',\n",
       " 'back',\n",
       " '~',\n",
       " 'about',\n",
       " 'new',\n",
       " ';',\n",
       " 'as',\n",
       " 'day',\n",
       " 'how',\n",
       " 'who',\n",
       " 'will',\n",
       " 'want',\n",
       " 'people',\n",
       " 'yo',\n",
       " 'eu',\n",
       " 'from',\n",
       " 'di',\n",
       " 'time',\n",
       " '<heart>',\n",
       " 's',\n",
       " 'aku',\n",
       " 'da',\n",
       " \"'re\",\n",
       " '<lolface>',\n",
       " 'una',\n",
       " 'got',\n",
       " 'las',\n",
       " 'more',\n",
       " 'x',\n",
       " 'she',\n",
       " 'today',\n",
       " '（',\n",
       " '>>',\n",
       " 'k',\n",
       " 'by',\n",
       " 'or',\n",
       " 'في',\n",
       " '･',\n",
       " 'too',\n",
       " 'le',\n",
       " 'é',\n",
       " '|',\n",
       " '[',\n",
       " '）',\n",
       " ']',\n",
       " 'see',\n",
       " 'why',\n",
       " 'yg',\n",
       " 'ca',\n",
       " 'como',\n",
       " 'her',\n",
       " '—',\n",
       " 'q',\n",
       " 'need',\n",
       " 'an',\n",
       " 'na',\n",
       " '笑',\n",
       " 'there',\n",
       " 'ω',\n",
       " 'happy',\n",
       " 'im',\n",
       " 'mas',\n",
       " 'je',\n",
       " 'life',\n",
       " 'really',\n",
       " 'make',\n",
       " 'yang',\n",
       " 'shit',\n",
       " 'think',\n",
       " 't',\n",
       " '❤',\n",
       " 'não',\n",
       " 'never',\n",
       " 'some',\n",
       " '～',\n",
       " 'oh',\n",
       " '★',\n",
       " 'did',\n",
       " 'would',\n",
       " 'del',\n",
       " '`',\n",
       " 'd',\n",
       " 'please',\n",
       " 'via',\n",
       " 'much',\n",
       " 'fuck',\n",
       " 'al',\n",
       " 'dia',\n",
       " '$',\n",
       " 'و',\n",
       " 'right',\n",
       " 'best',\n",
       " 'c',\n",
       " 'going',\n",
       " 'الله',\n",
       " 'pero',\n",
       " 'only',\n",
       " 'has',\n",
       " '♪',\n",
       " \"'ll\",\n",
       " 'twitter',\n",
       " '=',\n",
       " 'hahaha',\n",
       " 'its',\n",
       " 'nn',\n",
       " '｀',\n",
       " '¿',\n",
       " 'am',\n",
       " 'say',\n",
       " '<neutralface>',\n",
       " 'them',\n",
       " 'here',\n",
       " 'لا',\n",
       " 'off',\n",
       " 'still',\n",
       " 'dan',\n",
       " '+',\n",
       " 'night',\n",
       " 'w',\n",
       " 'ada',\n",
       " 'someone',\n",
       " 'even',\n",
       " 'then',\n",
       " '☆',\n",
       " 'ni',\n",
       " 'come',\n",
       " 'com',\n",
       " 'always',\n",
       " 'man',\n",
       " \"'ve\",\n",
       " 'been',\n",
       " 'his',\n",
       " 'itu',\n",
       " 'على',\n",
       " '-_-',\n",
       " '☺',\n",
       " 'over',\n",
       " 'um',\n",
       " 'ما',\n",
       " 'hate',\n",
       " 'girl',\n",
       " 'ai',\n",
       " 'had',\n",
       " 'pra',\n",
       " 'todo',\n",
       " 'mais',\n",
       " 'feel',\n",
       " 'let',\n",
       " 'ini',\n",
       " 'because',\n",
       " 'ﾟ',\n",
       " 'thanks',\n",
       " 'ah',\n",
       " 'way',\n",
       " 'ever',\n",
       " 'look',\n",
       " 'tweet',\n",
       " 'followers',\n",
       " 'should',\n",
       " 'our',\n",
       " 'xd',\n",
       " 'aja',\n",
       " 'esta',\n",
       " 'school',\n",
       " 'him',\n",
       " 'ser',\n",
       " 'take',\n",
       " 'than',\n",
       " 'video',\n",
       " 'em',\n",
       " 'last',\n",
       " 'wanna',\n",
       " 'does',\n",
       " 'us',\n",
       " 'miss',\n",
       " 'l',\n",
       " 'ga',\n",
       " 'better',\n",
       " 'well',\n",
       " 'could',\n",
       " '▽',\n",
       " '%',\n",
       " 'apa',\n",
       " 'cuando',\n",
       " 'team',\n",
       " '✔',\n",
       " '@',\n",
       " 'ok',\n",
       " '؟',\n",
       " '•',\n",
       " 'vida',\n",
       " 'quiero',\n",
       " 'les',\n",
       " 'being',\n",
       " 'real',\n",
       " 'down',\n",
       " 'kamu',\n",
       " 'everyone',\n",
       " 'gonna',\n",
       " 'live',\n",
       " 'tonight',\n",
       " 'yes',\n",
       " 'work',\n",
       " 'ass',\n",
       " 'retweet',\n",
       " 'nada',\n",
       " 'sama',\n",
       " 'first',\n",
       " '<<',\n",
       " 'photo',\n",
       " 'tomorrow',\n",
       " 'where',\n",
       " 'god',\n",
       " 'son',\n",
       " 'ke',\n",
       " 'ta',\n",
       " 'f',\n",
       " 'home',\n",
       " 'lagi',\n",
       " 'thank',\n",
       " 'birthday',\n",
       " '█',\n",
       " 'ha',\n",
       " 'great',\n",
       " 'lmao',\n",
       " 'omg',\n",
       " 'morning',\n",
       " 'más',\n",
       " 'mau',\n",
       " 'baby',\n",
       " 'dont',\n",
       " '｡',\n",
       " 'their',\n",
       " 'p',\n",
       " 'things',\n",
       " 'game',\n",
       " 'pas',\n",
       " 'bad',\n",
       " 'year',\n",
       " 'yeah',\n",
       " 'su',\n",
       " 'bitch',\n",
       " 'в',\n",
       " 'stop',\n",
       " 'hoy',\n",
       " 'something',\n",
       " 'meu',\n",
       " 'tak',\n",
       " 'gak',\n",
       " 'world',\n",
       " 'amor',\n",
       " 'h',\n",
       " '\\\\',\n",
       " 'ver',\n",
       " '；',\n",
       " 'porque',\n",
       " 'give',\n",
       " 'these',\n",
       " 'اللهم',\n",
       " 'were',\n",
       " 'hay',\n",
       " 'sleep',\n",
       " 'gue',\n",
       " 'every',\n",
       " 'friends',\n",
       " 'uma',\n",
       " 'tell',\n",
       " 'amo',\n",
       " 'vou',\n",
       " 'bien',\n",
       " '¡',\n",
       " 'again',\n",
       " '＾',\n",
       " '／',\n",
       " 'done',\n",
       " 'after',\n",
       " 'todos',\n",
       " 'girls',\n",
       " 'guys',\n",
       " 'getting',\n",
       " 'big',\n",
       " 'wait',\n",
       " 'justin',\n",
       " 'eh',\n",
       " '→',\n",
       " 'kan',\n",
       " 'kita',\n",
       " 'jajaja',\n",
       " 'wish',\n",
       " 'said',\n",
       " 'fucking',\n",
       " 'show',\n",
       " 'thing',\n",
       " 'next',\n",
       " 'você',\n",
       " 'nos',\n",
       " 'little',\n",
       " 'tengo',\n",
       " 'keep',\n",
       " 'person',\n",
       " \"''\",\n",
       " '∀',\n",
       " 'hope',\n",
       " 'كل',\n",
       " 'hey',\n",
       " 'bisa',\n",
       " 'free',\n",
       " 'made',\n",
       " 'foto',\n",
       " 'va',\n",
       " 'everything',\n",
       " 'iya',\n",
       " 'nigga',\n",
       " 'eso',\n",
       " 'et',\n",
       " 'watch',\n",
       " 'music',\n",
       " 'week',\n",
       " 'talk',\n",
       " 'ne',\n",
       " 'solo',\n",
       " 'gente',\n",
       " 'udah',\n",
       " '：',\n",
       " '--',\n",
       " '＼',\n",
       " 'mejor',\n",
       " 'facebook',\n",
       " 'ma',\n",
       " 'v',\n",
       " 'phone',\n",
       " 'most',\n",
       " 'same',\n",
       " 'okay',\n",
       " 'ik',\n",
       " 'before',\n",
       " 'minha',\n",
       " 'days',\n",
       " 'g',\n",
       " 'ti',\n",
       " 'damn',\n",
       " 'nice',\n",
       " 'voy',\n",
       " 'vai',\n",
       " 'call',\n",
       " 'long',\n",
       " 'tapi',\n",
       " 'http',\n",
       " 'sin',\n",
       " 'nunca',\n",
       " 'doing',\n",
       " 'other',\n",
       " 'find',\n",
       " 'il',\n",
       " 'sa',\n",
       " 'sorry',\n",
       " 'nya',\n",
       " 'orang',\n",
       " '°',\n",
       " 'hard',\n",
       " 'mean',\n",
       " 'die',\n",
       " 'اللي',\n",
       " 'tem',\n",
       " 'soy',\n",
       " 'este',\n",
       " 'kalo',\n",
       " 'só',\n",
       " 'th',\n",
       " 'win',\n",
       " 'nothing',\n",
       " 'into',\n",
       " 'face',\n",
       " 'cute',\n",
       " \"'d\",\n",
       " 'gracias',\n",
       " 'lah',\n",
       " 'и',\n",
       " 'any',\n",
       " 'play',\n",
       " '←',\n",
       " 'ko',\n",
       " 'text',\n",
       " '⌣',\n",
       " 'estoy',\n",
       " 'tau',\n",
       " 'ur',\n",
       " 'buat',\n",
       " '#',\n",
       " 'cause',\n",
       " 'я',\n",
       " 'put',\n",
       " 'kau',\n",
       " 'siempre',\n",
       " 'juga',\n",
       " 'casa',\n",
       " 'أن',\n",
       " 'help',\n",
       " 'start',\n",
       " 'feliz',\n",
       " 'old',\n",
       " 'ir',\n",
       " 'very',\n",
       " 'care',\n",
       " 'bir',\n",
       " 'makes',\n",
       " 'song',\n",
       " 'check',\n",
       " 'watching',\n",
       " 'ahora',\n",
       " 'jadi',\n",
       " 'os',\n",
       " 'may',\n",
       " 'friend',\n",
       " 'beautiful',\n",
       " 'heart',\n",
       " 'ka',\n",
       " 'vc',\n",
       " 'mundo',\n",
       " 'на',\n",
       " 'sure',\n",
       " 'tan',\n",
       " 'pretty',\n",
       " 'aqui',\n",
       " 'не',\n",
       " 'house',\n",
       " 'رتويت',\n",
       " 'يا',\n",
       " 'ja',\n",
       " 'true',\n",
       " 'muy',\n",
       " 'away',\n",
       " 'already',\n",
       " 'actually',\n",
       " 'believe',\n",
       " 'try',\n",
       " 'many',\n",
       " 'mañana',\n",
       " 'mis',\n",
       " 'lu',\n",
       " 'those',\n",
       " 'hot',\n",
       " 'qué',\n",
       " 'mal',\n",
       " 'عن',\n",
       " 'though',\n",
       " 'ask',\n",
       " 'amazing',\n",
       " 'bed',\n",
       " '}',\n",
       " 'two',\n",
       " 'mom',\n",
       " 'día',\n",
       " 've',\n",
       " 'dari',\n",
       " 'gameinsight',\n",
       " 'stay',\n",
       " 'fun',\n",
       " 'around',\n",
       " 'van',\n",
       " 'cont',\n",
       " 'ready',\n",
       " 'money',\n",
       " 'bu',\n",
       " 'funny',\n",
       " 'cool',\n",
       " 'hair',\n",
       " 'à',\n",
       " 'tho',\n",
       " '{',\n",
       " 'wo',\n",
       " 'hi',\n",
       " 'name',\n",
       " 'tiene',\n",
       " 'hahahaha',\n",
       " 'pa',\n",
       " 'algo',\n",
       " 'gotta',\n",
       " 'ولا',\n",
       " 'boy',\n",
       " 'another',\n",
       " \"c'est\",\n",
       " 'hari',\n",
       " 'jajajaja',\n",
       " 'having',\n",
       " 'cara',\n",
       " 'jaja',\n",
       " 'dm',\n",
       " 'looking',\n",
       " 'top',\n",
       " 'android',\n",
       " 'dah',\n",
       " 'wow',\n",
       " '░',\n",
       " 'eres',\n",
       " 'ben',\n",
       " 'must',\n",
       " 'news',\n",
       " 'met',\n",
       " 'está',\n",
       " 'nih',\n",
       " 'family',\n",
       " 'black',\n",
       " 'thought',\n",
       " 'nak',\n",
       " 'super',\n",
       " 'end',\n",
       " 'hace',\n",
       " 'remember',\n",
       " 'ama',\n",
       " 'party',\n",
       " 'cant',\n",
       " 'vamos',\n",
       " 'anything',\n",
       " 'anyone',\n",
       " 'فولو',\n",
       " 'perfect',\n",
       " 'guy',\n",
       " 'vez',\n",
       " 'christmas',\n",
       " 'dos',\n",
       " 'bueno',\n",
       " 'nao',\n",
       " 'years',\n",
       " 'vote',\n",
       " 'dormir',\n",
       " 'bro',\n",
       " 'else',\n",
       " 'quien',\n",
       " 'untuk',\n",
       " 'jangan',\n",
       " 'myself',\n",
       " 'head',\n",
       " 'mind',\n",
       " 'gua',\n",
       " 'talking',\n",
       " 'while',\n",
       " 'dat',\n",
       " 'food',\n",
       " 'д',\n",
       " 'coming',\n",
       " 'wkwk',\n",
       " 'trying',\n",
       " 'saya',\n",
       " 'mucho',\n",
       " 'without',\n",
       " 'wrong',\n",
       " '’s',\n",
       " 'baru',\n",
       " '__',\n",
       " 'hehe',\n",
       " 'hacer',\n",
       " 'lot',\n",
       " 'followed',\n",
       " 'crazy',\n",
       " 'hell',\n",
       " 'feeling',\n",
       " 'des',\n",
       " 'kok',\n",
       " 'j',\n",
       " 'stats',\n",
       " \"j'\",\n",
       " 'ان',\n",
       " 'tweets',\n",
       " 'non',\n",
       " 'cosas',\n",
       " 'era',\n",
       " 'high',\n",
       " 'niggas',\n",
       " 'change',\n",
       " 'movie',\n",
       " 'xx',\n",
       " 'mad',\n",
       " 'sih',\n",
       " 'sometimes',\n",
       " 'deh',\n",
       " 'allah',\n",
       " 'through',\n",
       " 'pour',\n",
       " 'ela',\n",
       " 'soon',\n",
       " 'gone',\n",
       " 'playing',\n",
       " 'smile',\n",
       " 'bukan',\n",
       " 'tv',\n",
       " 'fans',\n",
       " 'hasta',\n",
       " 'akan',\n",
       " \"y'\",\n",
       " 'looks',\n",
       " 'isso',\n",
       " '✌',\n",
       " 'tired',\n",
       " 'boys',\n",
       " 'might',\n",
       " 'dong',\n",
       " 'lg',\n",
       " 'use',\n",
       " 'maybe',\n",
       " 'until',\n",
       " 'menos',\n",
       " 'own',\n",
       " 'dengan',\n",
       " 'eat',\n",
       " 'ou',\n",
       " 'weekend',\n",
       " '˘',\n",
       " 'class',\n",
       " 'ele',\n",
       " 'harry',\n",
       " 'iphone',\n",
       " 'friday',\n",
       " 'single',\n",
       " 'ff',\n",
       " 'awesome',\n",
       " 'bout',\n",
       " 'muito',\n",
       " 'hoje',\n",
       " '¬',\n",
       " 'dios',\n",
       " 'such',\n",
       " 'estar',\n",
       " 'já',\n",
       " 'quando',\n",
       " 'esa',\n",
       " 'making',\n",
       " '━',\n",
       " 'times',\n",
       " 'lmfao',\n",
       " 'gw',\n",
       " 'moment',\n",
       " 'yet',\n",
       " 'aw',\n",
       " 'smh',\n",
       " 'banget',\n",
       " 'masih',\n",
       " 'qui',\n",
       " 'quem',\n",
       " '–',\n",
       " 'leave',\n",
       " 'du',\n",
       " 'une',\n",
       " 'guess',\n",
       " 'hit',\n",
       " 'с',\n",
       " 'pm',\n",
       " 'since',\n",
       " 'pues',\n",
       " 'est',\n",
       " 'job',\n",
       " 'ﾉ',\n",
       " 'mana',\n",
       " 'bom',\n",
       " 'siapa',\n",
       " 'suka',\n",
       " 'bieber',\n",
       " 'mention',\n",
       " 'lebih',\n",
       " 'favorite',\n",
       " 'bitches',\n",
       " 'forever',\n",
       " 'لي',\n",
       " 'final',\n",
       " 'read',\n",
       " 'alguien',\n",
       " 'open',\n",
       " 'yourself',\n",
       " 'ese',\n",
       " 'che',\n",
       " 'sex',\n",
       " 'yaa',\n",
       " 'car',\n",
       " 'direction',\n",
       " 'tidak',\n",
       " 'seu',\n",
       " 'gets',\n",
       " 'left',\n",
       " 're',\n",
       " 'jam',\n",
       " 'enough',\n",
       " 'إلا',\n",
       " 'once',\n",
       " '’',\n",
       " 'part',\n",
       " 'cada',\n",
       " '定期',\n",
       " 'لك',\n",
       " 'een',\n",
       " 'seen',\n",
       " 'kak',\n",
       " 'así',\n",
       " 'nem',\n",
       " 'عمل',\n",
       " 'white',\n",
       " 'told',\n",
       " 'says',\n",
       " 'esto',\n",
       " 'sad',\n",
       " 'mo',\n",
       " 'fue',\n",
       " 'yah',\n",
       " 'summer',\n",
       " 'ه',\n",
       " '⭕',\n",
       " '»',\n",
       " 'thats',\n",
       " 'مع',\n",
       " 'posted',\n",
       " 'wants',\n",
       " 'agora',\n",
       " 'together',\n",
       " 'fan',\n",
       " 'men',\n",
       " 'hear',\n",
       " 'full',\n",
       " '☀',\n",
       " 'sigo',\n",
       " 'pq',\n",
       " 'dulu',\n",
       " 'plus',\n",
       " 'foi',\n",
       " 'tudo',\n",
       " 'هو',\n",
       " 'ill',\n",
       " 'あ',\n",
       " 'thinking',\n",
       " 'wtf',\n",
       " 'pagi',\n",
       " 'mama',\n",
       " 'kalau',\n",
       " 'hati',\n",
       " 'sexy',\n",
       " 'sayang',\n",
       " 'baik',\n",
       " 'semua',\n",
       " 'hola',\n",
       " 'went',\n",
       " 'vos',\n",
       " 'tanto',\n",
       " 'finally',\n",
       " 'fb',\n",
       " 'sea',\n",
       " 'stupid',\n",
       " 'tus',\n",
       " 'seriously',\n",
       " 'hora',\n",
       " 'min',\n",
       " 'pic',\n",
       " 'estas',\n",
       " 'turn',\n",
       " 'hours',\n",
       " 'excited',\n",
       " 'nah',\n",
       " 'buy',\n",
       " 'saying',\n",
       " 'mah',\n",
       " 'break',\n",
       " 'needs',\n",
       " 'ce',\n",
       " 'room',\n",
       " 'choice',\n",
       " 'far',\n",
       " 'dead',\n",
       " 'quero',\n",
       " 'saw',\n",
       " 'kids',\n",
       " 'lil',\n",
       " 'whole',\n",
       " 'puede',\n",
       " 'fall',\n",
       " 'sus',\n",
       " 'lost',\n",
       " 'asi',\n",
       " 'word',\n",
       " '☹',\n",
       " 'also',\n",
       " 'ريتويت',\n",
       " 'probably',\n",
       " 'everybody',\n",
       " 'tarde',\n",
       " 'run',\n",
       " 'sei',\n",
       " 'follback',\n",
       " 'forget',\n",
       " 'sweet',\n",
       " 'welcome',\n",
       " 'selamat',\n",
       " '＿',\n",
       " 'sur',\n",
       " 'place',\n",
       " 'gusta',\n",
       " 'sabe',\n",
       " 'androidgames',\n",
       " 'tp',\n",
       " 'tiempo',\n",
       " 'بس',\n",
       " 'sou',\n",
       " 'tuh',\n",
       " 'vs',\n",
       " 'eyes',\n",
       " 'انا',\n",
       " 'picture',\n",
       " 'das',\n",
       " 'meet',\n",
       " 'anak',\n",
       " 'persona',\n",
       " 'essa',\n",
       " 'bored',\n",
       " 'following',\n",
       " 'nadie',\n",
       " 'nobody',\n",
       " 'dice',\n",
       " 'alone',\n",
       " 'sick',\n",
       " 'red',\n",
       " 'city',\n",
       " 'cinta',\n",
       " '月',\n",
       " 'linda',\n",
       " 'dream',\n",
       " 'story',\n",
       " 'km',\n",
       " 'het',\n",
       " 'waiting',\n",
       " '^_^',\n",
       " 'mine',\n",
       " 'что',\n",
       " 'reason',\n",
       " 'kk',\n",
       " 'لو',\n",
       " 'online',\n",
       " 'fast',\n",
       " 'udh',\n",
       " 'wanted',\n",
       " 'op',\n",
       " 'others',\n",
       " 'gay',\n",
       " 'n’t',\n",
       " 'used',\n",
       " 'sem',\n",
       " 'understand',\n",
       " 'moi',\n",
       " 'sm',\n",
       " 'aint',\n",
       " 'donde',\n",
       " 'bem',\n",
       " 'which',\n",
       " 'ng',\n",
       " 'followback',\n",
       " 'punya',\n",
       " 'late',\n",
       " 'anda',\n",
       " 'tidur',\n",
       " 'puedo',\n",
       " 'early',\n",
       " 'nd',\n",
       " 'personas',\n",
       " 'banyak',\n",
       " '✅',\n",
       " '➊',\n",
       " 'trust',\n",
       " 'noche',\n",
       " 'tl',\n",
       " '＞',\n",
       " '«',\n",
       " 'af',\n",
       " 'move',\n",
       " 'pro',\n",
       " 'bring',\n",
       " 'ku',\n",
       " 'called',\n",
       " 'relationship',\n",
       " 'idk',\n",
       " 'hurt',\n",
       " 'st',\n",
       " 'pernah',\n",
       " 'pessoas',\n",
       " 'hello',\n",
       " 'uno',\n",
       " 'unfollowers',\n",
       " 'cry',\n",
       " ...]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_pretrained.index2word # слова в предобученных эмбидингах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:23:42.752901Z",
     "start_time": "2021-09-29T11:23:42.748901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193514"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_pretrained.index2word) # количество слов в предобученных эмбидингах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:21:46.755145Z",
     "start_time": "2021-09-29T11:21:46.733144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " '>',\n",
       " ':',\n",
       " '--',\n",
       " ')',\n",
       " '(',\n",
       " '*',\n",
       " '@',\n",
       " \"''\",\n",
       " '?',\n",
       " '|',\n",
       " '``',\n",
       " \"'s\",\n",
       " \"n't\",\n",
       " '-',\n",
       " 'line',\n",
       " 'subject',\n",
       " '<',\n",
       " 'organization',\n",
       " '!',\n",
       " 'one',\n",
       " 'would',\n",
       " 'writes',\n",
       " 'article',\n",
       " ';',\n",
       " 'god',\n",
       " '...',\n",
       " 'space',\n",
       " 'people',\n",
       " 'like',\n",
       " ']',\n",
       " '[',\n",
       " 'know',\n",
       " 'think',\n",
       " '#',\n",
       " 'university',\n",
       " 'system',\n",
       " 'nntp-posting-host',\n",
       " 'say',\n",
       " 'time',\n",
       " 'image',\n",
       " 'also',\n",
       " '$',\n",
       " 'get',\n",
       " 'thing',\n",
       " 'could',\n",
       " \"'\",\n",
       " 'see',\n",
       " 'u',\n",
       " \"'m\",\n",
       " 'many',\n",
       " 'may',\n",
       " 'way',\n",
       " 'point',\n",
       " 'good',\n",
       " 'make',\n",
       " 'file',\n",
       " 'even',\n",
       " 'christian',\n",
       " 'well',\n",
       " 'world',\n",
       " 'year',\n",
       " 'program',\n",
       " 'jesus',\n",
       " 'use',\n",
       " 'first',\n",
       " 'much',\n",
       " '1',\n",
       " 'new',\n",
       " 'question',\n",
       " 'said',\n",
       " '+',\n",
       " 'need',\n",
       " 'want',\n",
       " 'data',\n",
       " 'work',\n",
       " 'science',\n",
       " '=',\n",
       " 'believe',\n",
       " 'find',\n",
       " 'something',\n",
       " 'mean',\n",
       " 'graphic',\n",
       " 'ca',\n",
       " 'atheist',\n",
       " 'anyone',\n",
       " 'right',\n",
       " 'nasa',\n",
       " 'life',\n",
       " 'problem',\n",
       " 'must',\n",
       " 'go',\n",
       " 'two',\n",
       " 'book',\n",
       " \"'ve\",\n",
       " 'please',\n",
       " 'distribution',\n",
       " 'read',\n",
       " 'take',\n",
       " 'group',\n",
       " 'religion',\n",
       " '&',\n",
       " 'word',\n",
       " 'version',\n",
       " 'computer',\n",
       " 'since',\n",
       " 'used',\n",
       " 'come',\n",
       " '2',\n",
       " 'might',\n",
       " 'launch',\n",
       " 'bible',\n",
       " '/',\n",
       " 'information',\n",
       " 'really',\n",
       " 'day',\n",
       " 'available',\n",
       " 'software',\n",
       " 'part',\n",
       " 'post',\n",
       " 'earth',\n",
       " 'still',\n",
       " 'better',\n",
       " 'look',\n",
       " 'true',\n",
       " 'case',\n",
       " 'another',\n",
       " 'keith',\n",
       " 'morality',\n",
       " 'law',\n",
       " 'example',\n",
       " 'using',\n",
       " 'help',\n",
       " 'fact',\n",
       " 'moral',\n",
       " 'different',\n",
       " 'give',\n",
       " 'satellite',\n",
       " 'support',\n",
       " 'argument',\n",
       " 'orbit',\n",
       " 'technology',\n",
       " 'etc',\n",
       " \"'d\",\n",
       " 'little',\n",
       " 'format',\n",
       " 'made',\n",
       " 'center',\n",
       " 'without',\n",
       " 'bit',\n",
       " 'value',\n",
       " 'someone',\n",
       " 'set',\n",
       " 'long',\n",
       " 'moon',\n",
       " 'evidence',\n",
       " 'rather',\n",
       " 'seems',\n",
       " 'number',\n",
       " '}',\n",
       " 'belief',\n",
       " 'research',\n",
       " '3',\n",
       " 'john',\n",
       " 'idea',\n",
       " \"'ll\",\n",
       " 'order',\n",
       " 'course',\n",
       " 'state',\n",
       " 'objective',\n",
       " 'source',\n",
       " 'reason',\n",
       " 'david',\n",
       " 'mission',\n",
       " 'anything',\n",
       " 'never',\n",
       " 'man',\n",
       " 'lot',\n",
       " 'claim',\n",
       " 'human',\n",
       " '..',\n",
       " 'thanks',\n",
       " 'real',\n",
       " \"'re\",\n",
       " 'sure',\n",
       " 'thought',\n",
       " 'going',\n",
       " 'let',\n",
       " 'however',\n",
       " 'around',\n",
       " 'try',\n",
       " 'actually',\n",
       " 'back',\n",
       " 'tell',\n",
       " 'least',\n",
       " 'nothing',\n",
       " 'color',\n",
       " 'wrong',\n",
       " '%',\n",
       " 'every',\n",
       " 'free',\n",
       " 'possible',\n",
       " 'person',\n",
       " 'place',\n",
       " 'wrote',\n",
       " 'cost',\n",
       " 'robert',\n",
       " 'name',\n",
       " 'view',\n",
       " 'jpeg',\n",
       " 'posting',\n",
       " '1993',\n",
       " 'code',\n",
       " 'either',\n",
       " 'probably',\n",
       " 'got',\n",
       " 'others',\n",
       " 'henry',\n",
       " 'send',\n",
       " 'put',\n",
       " '4',\n",
       " 'answer',\n",
       " 'reply-to',\n",
       " 'far',\n",
       " 'based',\n",
       " 'lunar',\n",
       " 'project',\n",
       " 'shuttle',\n",
       " 'enough',\n",
       " 'list',\n",
       " 'end',\n",
       " 'issue',\n",
       " 'package',\n",
       " 'atheism',\n",
       " 'last',\n",
       " 'given',\n",
       " 'show',\n",
       " 'ftp',\n",
       " 'child',\n",
       " 'great',\n",
       " 'high',\n",
       " 'opinion',\n",
       " 'islam',\n",
       " 'called',\n",
       " 'yet',\n",
       " 'note',\n",
       " '5',\n",
       " 'else',\n",
       " 'found',\n",
       " 'x',\n",
       " 'jim',\n",
       " 'power',\n",
       " 'address',\n",
       " 'object',\n",
       " 'quite',\n",
       " 'looking',\n",
       " 'religious',\n",
       " 'usa',\n",
       " 'sun',\n",
       " 'email',\n",
       " 'reference',\n",
       " 'keywords',\n",
       " 'user',\n",
       " 'general',\n",
       " 'sandvik',\n",
       " 'standard',\n",
       " 'large',\n",
       " 'message',\n",
       " 'news',\n",
       " 'exist',\n",
       " '3d',\n",
       " 'change',\n",
       " 'display',\n",
       " 'perhaps',\n",
       " 'following',\n",
       " 'society',\n",
       " 'saying',\n",
       " 'trying',\n",
       " 'site',\n",
       " 'rocket',\n",
       " 'run',\n",
       " 'agree',\n",
       " 'matter',\n",
       " 'call',\n",
       " 'statement',\n",
       " 'yes',\n",
       " 'livesey',\n",
       " 'faith',\n",
       " 'mark',\n",
       " 'act',\n",
       " 'keep',\n",
       " 'muslim',\n",
       " 'though',\n",
       " 'old',\n",
       " 'faq',\n",
       " 'public',\n",
       " 'inc.',\n",
       " 'national',\n",
       " 'several',\n",
       " 'next',\n",
       " 'done',\n",
       " 'matthew',\n",
       " 'material',\n",
       " 'station',\n",
       " 'apr',\n",
       " 'institute',\n",
       " 'level',\n",
       " 'death',\n",
       " 'understand',\n",
       " 'flight',\n",
       " 'small',\n",
       " 'able',\n",
       " 'maybe',\n",
       " 'known',\n",
       " '15',\n",
       " 'surface',\n",
       " 'truth',\n",
       " 'c',\n",
       " 'whether',\n",
       " 'stuff',\n",
       " 'rule',\n",
       " 'sort',\n",
       " 'big',\n",
       " 'kind',\n",
       " 'therefore',\n",
       " '8',\n",
       " 'bill',\n",
       " 'position',\n",
       " 'pat',\n",
       " 'bad',\n",
       " 'mind',\n",
       " 'jon',\n",
       " 'seen',\n",
       " 'original',\n",
       " '10',\n",
       " 'brian',\n",
       " 'access',\n",
       " 'islamic',\n",
       " 'frank',\n",
       " 'result',\n",
       " 'service',\n",
       " 'start',\n",
       " 'b',\n",
       " 'commercial',\n",
       " 'process',\n",
       " 'love',\n",
       " '20',\n",
       " 'seem',\n",
       " 'three',\n",
       " 'spacecraft',\n",
       " 'purpose',\n",
       " 'simply',\n",
       " 'info',\n",
       " 'gif',\n",
       " 'second',\n",
       " 'form',\n",
       " 'money',\n",
       " 'mail',\n",
       " 'ever',\n",
       " 'library',\n",
       " 'window',\n",
       " 'model',\n",
       " 'mar',\n",
       " 'whole',\n",
       " 'hope',\n",
       " 'government',\n",
       " 'everyone',\n",
       " '24',\n",
       " 'hand',\n",
       " 'e-mail',\n",
       " 'p',\n",
       " 'universe',\n",
       " 'light',\n",
       " 'quote',\n",
       " '6',\n",
       " 'le',\n",
       " 'california',\n",
       " 'church',\n",
       " 'koresh',\n",
       " 'area',\n",
       " 'christ',\n",
       " 'including',\n",
       " 'mode',\n",
       " 'live',\n",
       " 'written',\n",
       " 'christianity',\n",
       " 'activity',\n",
       " 'woman',\n",
       " 'current',\n",
       " 'fax',\n",
       " 'include',\n",
       " 'action',\n",
       " 'history',\n",
       " 'development',\n",
       " 'sense',\n",
       " 'theory',\n",
       " 'sorry',\n",
       " '16',\n",
       " 'certainly',\n",
       " 'remember',\n",
       " '7',\n",
       " 'type',\n",
       " 'heard',\n",
       " 'text',\n",
       " 'james',\n",
       " 'design',\n",
       " 'event',\n",
       " 'cause',\n",
       " 'best',\n",
       " 'always',\n",
       " 'michael',\n",
       " 'pretty',\n",
       " 'consider',\n",
       " 'net',\n",
       " 'polygon',\n",
       " 'away',\n",
       " 'kent',\n",
       " 'contact',\n",
       " 'algorithm',\n",
       " 'ask',\n",
       " 'explain',\n",
       " 'talking',\n",
       " 'box',\n",
       " 'application',\n",
       " 'billion',\n",
       " 'conclusion',\n",
       " 'video',\n",
       " 'interested',\n",
       " 'jew',\n",
       " 'often',\n",
       " 'term',\n",
       " 'ray',\n",
       " 'solar',\n",
       " 'upon',\n",
       " 'technical',\n",
       " 'existence',\n",
       " 'today',\n",
       " 'internet',\n",
       " 'created',\n",
       " 'almost',\n",
       " 'feel',\n",
       " 'making',\n",
       " 'accept',\n",
       " 'scientific',\n",
       " 'men',\n",
       " 'reading',\n",
       " 'within',\n",
       " 'unix',\n",
       " 'knowledge',\n",
       " '14',\n",
       " 'week',\n",
       " 'directory',\n",
       " 'tool',\n",
       " 'solntze.wpd.sgi.com',\n",
       " 'x-newsreader',\n",
       " 'international',\n",
       " 'similar',\n",
       " 'via',\n",
       " 'fred',\n",
       " 'sound',\n",
       " 'political',\n",
       " 'reality',\n",
       " 'probe',\n",
       " 'war',\n",
       " 'ago',\n",
       " 'base',\n",
       " 'mac',\n",
       " 'april',\n",
       " 'response',\n",
       " '....',\n",
       " 'important',\n",
       " 'baalke',\n",
       " 'particular',\n",
       " 'hard',\n",
       " 'star',\n",
       " 'provide',\n",
       " 'analysis',\n",
       " 'various',\n",
       " 'vehicle',\n",
       " 'evil',\n",
       " 'everything',\n",
       " 'newton.apple.com',\n",
       " 'control',\n",
       " 'definition',\n",
       " 'member',\n",
       " 'already',\n",
       " 'force',\n",
       " 'write',\n",
       " 'study',\n",
       " 'paul',\n",
       " 'assume',\n",
       " 'guess',\n",
       " 'test',\n",
       " 'thus',\n",
       " 'engineering',\n",
       " 'card',\n",
       " 'mathew',\n",
       " 'face',\n",
       " 'date',\n",
       " 'asked',\n",
       " 'kill',\n",
       " 'nature',\n",
       " 'error',\n",
       " 'oh',\n",
       " '12',\n",
       " 'copy',\n",
       " 'meaning',\n",
       " 'interesting',\n",
       " 'communication',\n",
       " '30',\n",
       " 'later',\n",
       " 'context',\n",
       " 'discussion',\n",
       " 'company',\n",
       " 'de',\n",
       " 'american',\n",
       " 'correct',\n",
       " 'getting',\n",
       " 'zoo.toronto.edu',\n",
       " 'country',\n",
       " 'tin',\n",
       " 'command',\n",
       " 'report',\n",
       " 'working',\n",
       " '\\\\',\n",
       " 'story',\n",
       " 'sgi',\n",
       " 'western',\n",
       " 'simple',\n",
       " 'gmt',\n",
       " 'become',\n",
       " 'reply',\n",
       " 'considered',\n",
       " 'although',\n",
       " 'natural',\n",
       " 'propulsion',\n",
       " 'full',\n",
       " 'laboratory',\n",
       " 'exists',\n",
       " 'concept',\n",
       " '{',\n",
       " 'g',\n",
       " 'planetary',\n",
       " 'exactly',\n",
       " 'product',\n",
       " 'speak',\n",
       " 'processing',\n",
       " 'care',\n",
       " 'military',\n",
       " 'picture',\n",
       " 'cco.caltech.edu',\n",
       " '11',\n",
       " 'according',\n",
       " 'planet',\n",
       " 'language',\n",
       " 'function',\n",
       " 'lab',\n",
       " '1.1',\n",
       " 'interpretation',\n",
       " 'peter',\n",
       " 'convert',\n",
       " 'built',\n",
       " '_',\n",
       " '9',\n",
       " 'unless',\n",
       " 'black',\n",
       " 'm.',\n",
       " 'choice',\n",
       " 'field',\n",
       " 'open',\n",
       " 'office',\n",
       " '19',\n",
       " 'n',\n",
       " 'sky',\n",
       " 'guy',\n",
       " 'sin',\n",
       " 'driver',\n",
       " 'author',\n",
       " 'spencer',\n",
       " 'innocent',\n",
       " 'individual',\n",
       " 'sex',\n",
       " 'city',\n",
       " 'died',\n",
       " 'along',\n",
       " 'present',\n",
       " 'major',\n",
       " 'biblical',\n",
       " 'per',\n",
       " 'animal',\n",
       " 'private',\n",
       " 'deal',\n",
       " 'clear',\n",
       " 'access.digex.com',\n",
       " 'nice',\n",
       " 'machine',\n",
       " 'v',\n",
       " 'follow',\n",
       " 'r',\n",
       " 'imagine',\n",
       " 'pc',\n",
       " 'ra',\n",
       " 'hardware',\n",
       " 'schneider',\n",
       " 'mormon',\n",
       " 'tiff',\n",
       " 'posted',\n",
       " 'routine',\n",
       " 'anybody',\n",
       " 'strong',\n",
       " 'useful',\n",
       " 'turn',\n",
       " 'e',\n",
       " 'plane',\n",
       " 'pasadena',\n",
       " 'fall',\n",
       " 'personal',\n",
       " 'goal',\n",
       " 'among',\n",
       " 'million',\n",
       " 'comment',\n",
       " 'body',\n",
       " '93',\n",
       " '13',\n",
       " 'taking',\n",
       " 'jaeger',\n",
       " 'future',\n",
       " 'orbital',\n",
       " 'due',\n",
       " 'germany',\n",
       " 'college',\n",
       " 'fast',\n",
       " 'screen',\n",
       " '0',\n",
       " '23',\n",
       " 'kelvin.jpl.nasa.gov',\n",
       " 'mass',\n",
       " 'local',\n",
       " 'situation',\n",
       " 'white',\n",
       " 'murder',\n",
       " 'plan',\n",
       " 'lord',\n",
       " 'told',\n",
       " 'instead',\n",
       " 'department',\n",
       " 'likely',\n",
       " 'network',\n",
       " 'radio',\n",
       " '_/',\n",
       " 'hi',\n",
       " 'involved',\n",
       " 'attempt',\n",
       " 'job',\n",
       " 'mentioned',\n",
       " 'whatever',\n",
       " 'quality',\n",
       " 'indeed',\n",
       " 'talk',\n",
       " 'observation',\n",
       " 'experience',\n",
       " 'deleted',\n",
       " 'allen',\n",
       " 'w.',\n",
       " '___',\n",
       " 'low',\n",
       " 'netcom.com',\n",
       " 'physical',\n",
       " 'interest',\n",
       " 'took',\n",
       " 'hear',\n",
       " 'loss',\n",
       " 'certain',\n",
       " 'doubt',\n",
       " 'passage',\n",
       " 'australia',\n",
       " 'writing',\n",
       " 'astronomy',\n",
       " '21',\n",
       " 'memory',\n",
       " 'otherwise',\n",
       " 'king',\n",
       " 'operation',\n",
       " 'telescope',\n",
       " 'rushdie',\n",
       " 'environment',\n",
       " 'short',\n",
       " 'needed',\n",
       " 'die',\n",
       " 'bob',\n",
       " 'option',\n",
       " 'basis',\n",
       " 'nsmca',\n",
       " 'map',\n",
       " 'dept',\n",
       " 'comet',\n",
       " 'stop',\n",
       " 'phone',\n",
       " 'detail',\n",
       " 'rest',\n",
       " 'effort',\n",
       " 'especially',\n",
       " 'check',\n",
       " 'allan',\n",
       " 'verse',\n",
       " 'authority',\n",
       " 'dr.',\n",
       " 'tom',\n",
       " 'degree',\n",
       " 'common',\n",
       " 'online',\n",
       " 'side',\n",
       " 'false',\n",
       " 'resource',\n",
       " 'request',\n",
       " 'access.digex.net',\n",
       " 'toronto',\n",
       " 'effect',\n",
       " 'edge',\n",
       " 'tony',\n",
       " 'animation',\n",
       " 'newsgroup',\n",
       " 'anyway',\n",
       " 'archive',\n",
       " 'facility',\n",
       " 'saw',\n",
       " 'bb',\n",
       " 'left',\n",
       " 'necessary',\n",
       " 'nation',\n",
       " 'server',\n",
       " 'jupiter',\n",
       " 'recently',\n",
       " 'ibm',\n",
       " '17',\n",
       " 'early',\n",
       " '/|',\n",
       " 'came',\n",
       " 'prove',\n",
       " 'viewer',\n",
       " 'save',\n",
       " 'century',\n",
       " '18',\n",
       " 'size',\n",
       " 'page',\n",
       " 'washington',\n",
       " 'anonymous',\n",
       " 'contradiction',\n",
       " 'wish',\n",
       " 'friend',\n",
       " 'volume',\n",
       " 'hold',\n",
       " 'land',\n",
       " 'physic',\n",
       " 'stephen',\n",
       " 'fit',\n",
       " 'ron',\n",
       " '22',\n",
       " 'specific',\n",
       " 'thousand',\n",
       " 'russian',\n",
       " 'difference',\n",
       " 'paper',\n",
       " 'lack',\n",
       " 'thinking',\n",
       " 'engine',\n",
       " 'worth',\n",
       " 'beyond',\n",
       " 'single',\n",
       " 'prb',\n",
       " 'mine',\n",
       " 'allow',\n",
       " 'article-i.d',\n",
       " 'air',\n",
       " 'method',\n",
       " 'understanding',\n",
       " 'usually',\n",
       " 'age',\n",
       " 'fallacy',\n",
       " 'basic',\n",
       " 'description',\n",
       " 'radius',\n",
       " 'dave',\n",
       " '25',\n",
       " 'speed',\n",
       " 'add',\n",
       " 'advance',\n",
       " 'ground',\n",
       " 'cut',\n",
       " 'market',\n",
       " 'currently',\n",
       " 'lead',\n",
       " 'structure',\n",
       " 'return',\n",
       " 'obvious',\n",
       " 'element',\n",
       " 'behavior',\n",
       " 'greek',\n",
       " 'complete',\n",
       " 'couple',\n",
       " 'business',\n",
       " 'san',\n",
       " 'require',\n",
       " 'developed',\n",
       " 'summary',\n",
       " 'building',\n",
       " 'us',\n",
       " 'night',\n",
       " 'shall',\n",
       " 'lie',\n",
       " 'prophet',\n",
       " 'father',\n",
       " 'satan',\n",
       " 'aurora.alaska.edu',\n",
       " 'mention',\n",
       " 'stated',\n",
       " 'medium',\n",
       " 'principle',\n",
       " 'holy',\n",
       " 'described',\n",
       " 'motto',\n",
       " 'launched',\n",
       " 'vga',\n",
       " 'school',\n",
       " 'ancient',\n",
       " 'capability',\n",
       " 'mantis.co.uk',\n",
       " 'started',\n",
       " 'build',\n",
       " 'special',\n",
       " 'gregg',\n",
       " 'taken',\n",
       " 'halat',\n",
       " 'dead',\n",
       " 'practice',\n",
       " 'fund',\n",
       " 'home',\n",
       " 'mr.',\n",
       " 'easy',\n",
       " 'basically',\n",
       " 'minute',\n",
       " 'funding',\n",
       " 'create',\n",
       " 'chris',\n",
       " 'includes',\n",
       " 'uk',\n",
       " 'benedikt',\n",
       " 'higgins',\n",
       " 'juda',\n",
       " 'killed',\n",
       " 'theist',\n",
       " 'postscript',\n",
       " 'reasonable',\n",
       " 'hour',\n",
       " 'house',\n",
       " 'vice.ico.tek.com',\n",
       " 'agency',\n",
       " 'punishment',\n",
       " 'jpl',\n",
       " 'feature',\n",
       " 'canada',\n",
       " 'none',\n",
       " 'in-reply-to',\n",
       " 'leave',\n",
       " 'c.',\n",
       " 'rate',\n",
       " 'inside',\n",
       " 'head',\n",
       " 'define',\n",
       " 'freedom',\n",
       " 'jewish',\n",
       " 'j.',\n",
       " 'programming',\n",
       " 'homosexual',\n",
       " 'class',\n",
       " '100',\n",
       " 'payload',\n",
       " 'figure',\n",
       " 'caused',\n",
       " 'running',\n",
       " 'offer',\n",
       " 'necessarily',\n",
       " 'tyre',\n",
       " '26',\n",
       " 'adam',\n",
       " 'specifically',\n",
       " 'press',\n",
       " 'included',\n",
       " 'j',\n",
       " 'gas',\n",
       " 'expect',\n",
       " 'month',\n",
       " '-+',\n",
       " 'young',\n",
       " 'requires',\n",
       " 'carry',\n",
       " 'perfect',\n",
       " 'teach',\n",
       " 'steve',\n",
       " 'po.cwru.edu',\n",
       " 'titan',\n",
       " 'exploration',\n",
       " 'peace',\n",
       " 'cview',\n",
       " 'charge',\n",
       " 'foot',\n",
       " 'drive',\n",
       " 'jet',\n",
       " 'venus',\n",
       " 'alternative',\n",
       " 'teaching',\n",
       " 'u.s.',\n",
       " 'past',\n",
       " 'premise',\n",
       " 'pay',\n",
       " 'sometimes',\n",
       " 'killing',\n",
       " 'son',\n",
       " 'mr',\n",
       " 'possibility',\n",
       " 'hole',\n",
       " 'direct',\n",
       " 'sci.space',\n",
       " 'willing',\n",
       " 'thread',\n",
       " 'ad',\n",
       " 'happened',\n",
       " 'buy',\n",
       " 'energy',\n",
       " 'outside',\n",
       " 'ken',\n",
       " 'longer',\n",
       " 'price',\n",
       " 'north',\n",
       " 'whose',\n",
       " 'key',\n",
       " 'amount',\n",
       " 'game',\n",
       " 'astronaut',\n",
       " 'a.',\n",
       " 'wanted',\n",
       " 'account',\n",
       " 'obviously',\n",
       " 'close',\n",
       " 'defined',\n",
       " 'wonder',\n",
       " 'ed',\n",
       " 'gospel',\n",
       " 'approach',\n",
       " 'clearly',\n",
       " 'database',\n",
       " 'move',\n",
       " 'happy',\n",
       " 'scientist',\n",
       " 'section',\n",
       " 'community',\n",
       " 'period',\n",
       " 'board',\n",
       " 'tried',\n",
       " 'corporation',\n",
       " 'series',\n",
       " 'poster',\n",
       " 'except',\n",
       " 'computing',\n",
       " 'logic',\n",
       " 'stage',\n",
       " '28',\n",
       " 'majority',\n",
       " 'virtual',\n",
       " '1.',\n",
       " 'conference',\n",
       " 'near',\n",
       " 'gravity',\n",
       " 'pixel',\n",
       " 'regard',\n",
       " 'required',\n",
       " 'liar',\n",
       " 'letter',\n",
       " '42',\n",
       " 'four',\n",
       " 'drawing',\n",
       " 'observatory',\n",
       " '256',\n",
       " 'disk',\n",
       " 'bobby',\n",
       " 'unit',\n",
       " 'texas',\n",
       " 'disclaimer',\n",
       " 'draw',\n",
       " 'valid',\n",
       " 'addition',\n",
       " 'apply',\n",
       " 'chance',\n",
       " 'sphere',\n",
       " 'provides',\n",
       " 'wo',\n",
       " 'homosexuality',\n",
       " 'landing',\n",
       " 'zoology',\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_trained.index2word # слова в обученных эмбидингах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:15:34.080012Z",
     "start_time": "2021-09-29T11:15:34.071008Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1KaMKBHsSHd",
    "outputId": "65336ef9-6d63-4c40-881d-d22ca4b8b2c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13566"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_trained.index2word) # количество слов в обученных эмбидингах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:17:49.604361Z",
     "start_time": "2021-09-29T11:17:37.827364Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krjpVRsLPJcf",
    "outputId": "0f24b897-f3c5-4ee7-84fe-1ca5a2abeafe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627, 25), (407, 25))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_pretrained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:18:00.853236Z",
     "start_time": "2021-09-29T11:17:56.935762Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWhQ007PPJcn",
    "outputId": "ba51dbd6-e7ef-4ed5-eac0-948d32f76a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027027027027027"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))\n",
    "# обучение с претреннированными эмбидингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:18:12.683288Z",
     "start_time": "2021-09-29T11:18:00.856236Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oT_Rr4nOUUu8",
    "outputId": "08a28d12-283e-4eab-d80c-6208cc6ceadd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627, 100), (407, 100))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_trained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T11:18:25.032287Z",
     "start_time": "2021-09-29T11:18:12.688292Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVMeZBLbVMjO",
    "outputId": "653442de-cfa8-4170-bfa6-1f87e00a6e29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\.conda\\envs\\deep\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8624078624078624"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))\n",
    "# обучение с обученными эмбидингами (почему ами????)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_K8NLmDVds1"
   },
   "source": [
    "### результат хуже из-за малой размерности векторов и примитивности операций (сложение векторов)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[seminar]text_preprocessing_and_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "11.8333px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.717px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
