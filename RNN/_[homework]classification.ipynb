{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot3c4fjZwC4T"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2JdzEXmwRU5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TItJgQMp5p4E"
   },
   "source": [
    "# Задание 3\n",
    "\n",
    "## Классификация текстов\n",
    "\n",
    "В этом задании вам предстоит попробовать несколько методов, используемых в задаче классификации, а также понять насколько хорошо модель понимает смысл слов и какие слова в примере влияют на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:29.911603Z",
     "start_time": "2021-10-10T14:37:28.177529Z"
    },
    "id": "1emhHMhniZMu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, gc\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torchtext import datasets\n",
    "\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyOlPZA26Ppy"
   },
   "source": [
    "В этом задании мы будем использовать библиотеку torchtext. Она довольна проста в использовании и поможет нам сконцентрироваться на задаче, а не на написании Dataloader-а."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:29.926579Z",
     "start_time": "2021-10-10T14:37:29.913584Z"
    },
    "id": "-VuQ1E10_tX_"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, lower=True, include_lengths=True)  # Поле текста\n",
    "LABEL = LabelField(dtype=torch.float)  # Поле метки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:29.941580Z",
     "start_time": "2021-10-10T14:37:29.928579Z"
    },
    "id": "SBK4ipzS122j"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNWLG7mG6n2d"
   },
   "source": [
    "Датасет на котором мы будем проводить эксперементы это комментарии к фильмам из сайта IMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:44.114604Z",
     "start_time": "2021-10-10T14:37:29.944580Z"
    },
    "id": "mRzUSWeAi6Xq"
   },
   "outputs": [],
   "source": [
    "train, test = datasets.IMDB.splits(TEXT, LABEL)  # загрузим датасет\n",
    "train, valid = train.split(random_state=random.seed(SEED))  # разобьем на части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:45.506594Z",
     "start_time": "2021-10-10T14:37:44.118593Z"
    },
    "id": "uQfIRhWPjURL"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:45.569580Z",
     "start_time": "2021-10-10T14:37:45.508584Z"
    },
    "id": "bSoBkdcj4roR"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size = 64,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_CRDES360wG"
   },
   "source": [
    "## RNN\n",
    "\n",
    "Для начала попробуем использовать рекурентные нейронные сети. На семинаре вы познакомились с GRU, вы можете также попробовать LSTM. Можно использовать для классификации как hidden_state, так и output последнего токена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:45.585581Z",
     "start_time": "2021-10-10T14:37:45.571581Z"
    },
    "id": "J1yE1KPQqDat"
   },
   "outputs": [],
   "source": [
    "class RNNBaseline(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim,num_layers=n_layers,bidirectional=bidirectional)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=hidden_dim*2,out_features=output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size] (sents = columns)\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim] (z = emb_word)\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        \n",
    "        # cell arg for LSTM, remove for GRU\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        #unpack sequence\n",
    "        #output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)  \n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim] # 1 слой - forward, 2 слой - backward\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = torch.cat((hidden[-2,:,:],hidden[-1,:,:]),1)\n",
    "        hidden=self.dropout(hidden)\n",
    "        #hidden = [batch size, hid dim * num directions] or [batch_size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7dLGFg4M7Te"
   },
   "source": [
    "Поиграйтесь с гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:45.600581Z",
     "start_time": "2021-10-10T14:37:45.587581Z"
    },
    "id": "ggTiORJ-8t0J"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "emb_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.2\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "patience=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:45.823592Z",
     "start_time": "2021-10-10T14:37:45.602579Z"
    },
    "id": "mIiM_ZBt9_91"
   },
   "outputs": [],
   "source": [
    "model = RNNBaseline(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=emb_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    n_layers=n_layers,\n",
    "    bidirectional=bidirectional,\n",
    "    dropout=dropout,\n",
    "    pad_idx=PAD_IDX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:48.105594Z",
     "start_time": "2021-10-10T14:37:45.827579Z"
    },
    "id": "mFeG88M--NbD"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:48.120587Z",
     "start_time": "2021-10-10T14:37:48.107582Z"
    },
    "id": "olAS-mVI-VfT"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:37:48.182578Z",
     "start_time": "2021-10-10T14:37:48.122581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter)).text[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jlfEAJu9akO"
   },
   "source": [
    "Обучите сетку! Используйте любые вам удобные инструменты, Catalyst, PyTorch Lightning или свои велосипеды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:43:11.925023Z",
     "start_time": "2021-10-10T14:37:48.184582Z"
    },
    "id": "87dgw6ok9hR0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.6429314613342285, Validation Loss: 0.6251583695411682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.5516434907913208, Validation Loss: 0.5389180779457092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.39293333888053894, Validation Loss: 0.43005791306495667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.2657189965248108, Validation Loss: 0.4217824637889862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.16688859462738037, Validation Loss: 0.43720921874046326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.10236067324876785, Validation Loss: 0.5248586535453796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "cur_patience = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_iter), total=len(train_iter), leave=False)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for it, batch in pbar: \n",
    "        opt.zero_grad()\n",
    "        input_embeds=batch.text[0].to(device)\n",
    "        text_length=batch.text[1].cpu()\n",
    "        labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "        preds=model(input_embeds,text_length)\n",
    "        loss=loss_func(preds,labels)\n",
    "        loss.requires_grad_()\n",
    "        loss.backward()\n",
    "        train_loss+=loss\n",
    "        opt.step()\n",
    "        \n",
    "    train_loss /= len(train_iter)\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    pbar = tqdm(enumerate(valid_iter), total=len(valid_iter), leave=False)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    with torch.no_grad():\n",
    "        for it, batch in pbar:\n",
    "            with torch.no_grad():\n",
    "                input_embeds=batch.text[0].to(device)\n",
    "                text_length=batch.text[1].cpu()\n",
    "                all_labels+=batch.label.tolist()\n",
    "                labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "                preds=model(input_embeds,text_length)\n",
    "                all_preds+=list(map(lambda pred:np.where(pred > 0, 1, 0),preds.cpu()))\n",
    "                val_loss+=loss_func(preds,labels)\n",
    "            \n",
    "    val_loss /= len(valid_iter)\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "    else:\n",
    "        cur_patience += 1\n",
    "        if cur_patience == patience:\n",
    "            cur_patience = 0\n",
    "            break\n",
    "    \n",
    "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, train_loss, val_loss))\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:43:12.222995Z",
     "start_time": "2021-10-10T14:43:11.927023Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(best_model,'bestRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:43:55.710268Z",
     "start_time": "2021-10-10T14:43:12.224996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6932282447814941\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "pbar = tqdm(enumerate(test_iter), total=len(test_iter), leave=False)\n",
    "pbar.set_description(f\"Test\")\n",
    "with torch.no_grad():\n",
    "    for it, batch in pbar:\n",
    "        with torch.no_grad():\n",
    "            input_embeds=batch.text[0].to(device)\n",
    "            text_length=batch.text[1].cpu()\n",
    "            all_labels+=batch.label.tolist()\n",
    "            labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "            preds=model(input_embeds,text_length)\n",
    "            all_preds+=list(map(lambda pred:np.where(pred > 0, 1, 0),preds.cpu()))\n",
    "            test_loss+=loss_func(preds,labels)\n",
    "            \n",
    "test_loss /= len(test_iter)\n",
    "print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:43:55.802268Z",
     "start_time": "2021-10-10T14:43:55.710268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8191608287451669"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_labels,all_preds,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4i-Go_ICT_U"
   },
   "source": [
    "Посчитайте f1-score вашего классификатора на тестовом датасете.\n",
    "\n",
    "**Ответ**: 0.819399011037634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:43:56.182270Z",
     "start_time": "2021-10-10T14:43:55.802268Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzDqc3__JIMe"
   },
   "source": [
    "## CNN\n",
    "\n",
    "![](https://www.researchgate.net/publication/333752473/figure/fig1/AS:769346934673412@1560438011375/Standard-CNN-on-text-classification.png)\n",
    "\n",
    "Для классификации текстов также часто используют сверточные нейронные сети. Идея в том, что как правило предложения содержат словосочетания из двух-трех слов, например \"очень хороший фильм\" или \"невероятная скука\". Проходясь сверткой по этим словам мы получим какой-то большой скор и выхватим его с помощью MaxPool. Далее идет обычная полносвязная сетка. Важный момент: свертки применяются не последовательно, а параллельно. Давайте попробуем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.154556Z",
     "start_time": "2021-10-10T14:43:56.182270Z"
    },
    "id": "rU-76tNI-STt"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, lower=True, batch_first=True)  # batch_first тк мы используем conv  \n",
    "LABEL = LabelField(batch_first=True, dtype=torch.float)\n",
    "\n",
    "train, tst = datasets.IMDB.splits(TEXT, LABEL)\n",
    "trn, vld = train.split(random_state=random.seed(SEED))\n",
    "\n",
    "TEXT.build_vocab(trn)\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.282547Z",
     "start_time": "2021-10-10T14:44:09.158557Z"
    },
    "id": "RQpS9KKUJQVH"
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (trn, vld, tst),\n",
    "        batch_sizes=(128, 256, 256),\n",
    "        sort=False,\n",
    "        sort_key= lambda x: len(x.src),\n",
    "        sort_within_batch=False,\n",
    "        device=device,\n",
    "        repeat=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.346545Z",
     "start_time": "2021-10-10T14:44:09.282547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 891])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter)).text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asgbwMePPNNl"
   },
   "source": [
    "Вы можете использовать Conv2d с `in_channels=1, kernel_size=(kernel_sizes[0], emb_dim))` или Conv1d c `in_channels=emb_dim, kernel_size=kernel_size[0]`. Но хорошенько подумайте над shape в обоих случаях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.362546Z",
     "start_time": "2021-10-10T14:44:09.346545Z"
    },
    "id": "qPP_-0E-JYTQ"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        emb_dim,\n",
    "        out_channels,\n",
    "        kernel_sizes,\n",
    "        dropout=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.conv_0 = nn.Conv1d(in_channels=emb_dim,out_channels=out_channels,kernel_size=kernel_sizes[0],stride=2)\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(in_channels=emb_dim,out_channels=out_channels,kernel_size=kernel_sizes[1],stride=2)\n",
    "        \n",
    "        self.conv_2 = nn.Conv1d(in_channels=emb_dim,out_channels=out_channels,kernel_size=kernel_sizes[2],stride=2)\n",
    "        \n",
    "        self.fc = nn.Linear(len(kernel_sizes) * out_channels, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size] (sents = columns)\n",
    "        embedded = self.embedding(text)\n",
    "        #print('1',embedded.shape)\n",
    "        #embedded = [sent len, batch size, emb dim] (z = emb_word)\n",
    "        #embedded = embedded.unsqueeze(1)\n",
    "        #print('2',embedded.shape)\n",
    "        embedded = embedded.permute(0,2,1)\n",
    "        #print('3',embedded.shape)\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded))  # may be reshape here\n",
    "        conved_1 = F.relu(self.conv_1(embedded))  # may be reshape here\n",
    "        conved_2 = F.relu(self.conv_2(embedded))  # may be reshape here\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.844953Z",
     "start_time": "2021-10-10T14:44:09.364865Z"
    },
    "id": "Y-U_2T5oKNed"
   },
   "outputs": [],
   "source": [
    "kernel_sizes = [3, 4, 5]\n",
    "vocab_size = len(TEXT.vocab)\n",
    "out_channels=64\n",
    "dropout = 0.5\n",
    "dim = 300\n",
    "patience=3\n",
    "model = CNN(vocab_size=vocab_size, emb_dim=dim, out_channels=out_channels,\n",
    "            kernel_sizes=kernel_sizes, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.932954Z",
     "start_time": "2021-10-10T14:44:09.844953Z"
    },
    "id": "vC2ThnfNKPIR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(202065, 300)\n",
       "  (conv_0): Conv1d(300, 64, kernel_size=(3,), stride=(2,))\n",
       "  (conv_1): Conv1d(300, 64, kernel_size=(4,), stride=(2,))\n",
       "  (conv_2): Conv1d(300, 64, kernel_size=(5,), stride=(2,))\n",
       "  (fc): Linear(in_features=192, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.944960Z",
     "start_time": "2021-10-10T14:44:09.932954Z"
    },
    "id": "mExblVtPKRw4"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:44:09.960960Z",
     "start_time": "2021-10-10T14:44:09.944960Z"
    },
    "id": "QVwSgwkEKTw5"
   },
   "outputs": [],
   "source": [
    "max_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIQgLCELDoOA"
   },
   "source": [
    "Обучите!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:47:24.331433Z",
     "start_time": "2021-10-10T14:44:09.960960Z"
    },
    "id": "zQZbJ791KXHb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.6644595861434937, Validation Loss: 0.526606559753418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.5289759635925293, Validation Loss: 0.48467785120010376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.44773128628730774, Validation Loss: 0.42374905943870544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.36872854828834534, Validation Loss: 0.3878984749317169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.28996771574020386, Validation Loss: 0.3669291138648987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.2166883945465088, Validation Loss: 0.3758828043937683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.1570805311203003, Validation Loss: 0.43048998713493347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "cur_patience = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_iter), total=len(train_iter), leave=False)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for it, batch in pbar: \n",
    "        opt.zero_grad()\n",
    "        input_embeds=batch.text\n",
    "        labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "        preds=model(input_embeds)\n",
    "        loss=loss_func(preds,labels)\n",
    "        loss.requires_grad_()\n",
    "        loss.backward()\n",
    "        train_loss+=loss\n",
    "        opt.step()\n",
    "\n",
    "    train_loss /= len(train_iter)\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    pbar = tqdm(enumerate(val_iter), total=len(val_iter), leave=False)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    with torch.no_grad():\n",
    "        for it, batch in pbar:\n",
    "            with torch.no_grad():\n",
    "                input_embeds=batch.text\n",
    "                all_labels+=batch.label.tolist()\n",
    "                labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "                preds=model(input_embeds)\n",
    "                all_preds+=list(map(lambda pred:np.where(pred > 0, 1, 0),preds.cpu()))\n",
    "                val_loss+=loss_func(preds,labels)\n",
    "\n",
    "    val_loss /= len(val_iter)\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "    else:\n",
    "        cur_patience += 1\n",
    "        if cur_patience == patience:\n",
    "            cur_patience = 0\n",
    "            break\n",
    "    \n",
    "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, train_loss, val_loss))\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:47:25.166963Z",
     "start_time": "2021-10-10T14:47:24.333435Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(best_model,'bestCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:47:36.036365Z",
     "start_time": "2021-10-10T14:47:25.171952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.42569705843925476\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "pbar = tqdm(enumerate(test_iter), total=len(test_iter), leave=False)\n",
    "pbar.set_description(f\"Test\")\n",
    "with torch.no_grad():\n",
    "    for it, batch in pbar:\n",
    "        input_embeds=batch.text\n",
    "        all_labels+=batch.label.tolist()\n",
    "        labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "        preds=model(input_embeds)\n",
    "        all_preds+=list(map(lambda pred:np.where(pred > 0, 1, 0),preds.cpu()))\n",
    "        test_loss+=loss_func(preds,labels)\n",
    "            \n",
    "test_loss /= len(test_iter)\n",
    "print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:47:36.148364Z",
     "start_time": "2021-10-10T14:47:36.038370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8309058843945097"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_labels,all_preds,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UVCacK0EhPR"
   },
   "source": [
    "Посчитайте f1-score вашего классификатора.\n",
    "\n",
    "**Ответ**: 0.8309058843945097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VspGMN0ESiS"
   },
   "source": [
    "## Интерпретируемость\n",
    "\n",
    "Посмотрим, куда смотрит наша модель. Достаточно запустить код ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:47:36.164365Z",
     "start_time": "2021-10-10T14:47:36.150369Z"
    },
    "id": "ye2SvjXrPgJh"
   },
   "outputs": [],
   "source": [
    "#!pip install -q captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:47:36.498369Z",
     "start_time": "2021-10-10T14:47:36.166366Z"
    },
    "id": "6e5XPKSZO6DY"
   },
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n",
    "\n",
    "PAD_IND = TEXT.vocab.stoi['pad']\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "lig = LayerIntegratedGradients(model, model.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:47:36.514366Z",
     "start_time": "2021-10-10T14:47:36.500369Z"
    },
    "id": "DvqWhd-fPe9e"
   },
   "outputs": [],
   "source": [
    "def forward_with_softmax(inp):\n",
    "    logits = model(inp)\n",
    "    return torch.softmax(logits, 0)[0][1]\n",
    "\n",
    "def forward_with_sigmoid(input):\n",
    "    return torch.sigmoid(model(input))\n",
    "\n",
    "\n",
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model, sentence, min_len = 7, label = 0):\n",
    "    model.eval()\n",
    "    text = [tok for tok in TEXT.tokenize(sentence)]\n",
    "    if len(text) < min_len:\n",
    "        text += ['pad'] * (min_len - len(text))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in text]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    input_indices = torch.tensor(indexed, device=device)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "    \n",
    "    # input_indices dim: [sequence_length]\n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = forward_with_sigmoid(input_indices).item()\n",
    "    pred_ind = round(pred)\n",
    "\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(input_indices, reference_indices, \\\n",
    "                                           n_steps=5000, return_convergence_delta=True)\n",
    "\n",
    "    print('pred: ', LABEL.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "    \n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            LABEL.vocab.itos[pred_ind],\n",
    "                            LABEL.vocab.itos[label],\n",
    "                            LABEL.vocab.itos[1],\n",
    "                            attributions.sum(),       \n",
    "                            text,\n",
    "                            delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:48:24.259369Z",
     "start_time": "2021-10-10T14:47:36.516365Z"
    },
    "id": "VtYy633vS8Me"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  pos ( 0.81 ) , delta:  tensor([2.7922e-05], device='cuda:0', dtype=torch.float64)\n",
      "pred:  neg ( 0.27 ) , delta:  tensor([3.8100e-05], device='cuda:0', dtype=torch.float64)\n",
      "pred:  pos ( 0.99 ) , delta:  tensor([9.8730e-05], device='cuda:0', dtype=torch.float64)\n",
      "pred:  neg ( 0.02 ) , delta:  tensor([4.4304e-05], device='cuda:0', dtype=torch.float64)\n",
      "pred:  neg ( 0.35 ) , delta:  tensor([0.0002], device='cuda:0', dtype=torch.float64)\n",
      "pred:  pos ( 0.54 ) , delta:  tensor([3.5911e-05], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "interpret_sentence(model, 'It was a fantastic performance !', label=1)\n",
    "interpret_sentence(model, 'Best film ever', label=1)\n",
    "interpret_sentence(model, 'Such a great show!', label=1)\n",
    "interpret_sentence(model, 'It was a horrible movie', label=0)\n",
    "interpret_sentence(model, 'I\\'ve never watched something as bad', label=0)\n",
    "interpret_sentence(model, 'It is a disgusting movie!', label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqIRSCWlRTOe"
   },
   "source": [
    "Попробуйте добавить свои примеры!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:48:24.275386Z",
     "start_time": "2021-10-10T14:48:24.261370Z"
    },
    "id": "4URAkcWXTGBi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.81)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.98</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.27)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.18</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 51%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.41</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show!                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.02)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.35</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.35)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.32</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I've                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.54)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.35</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie!                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvEHEaurElu8"
   },
   "source": [
    "## Эмбеддинги слов\n",
    "\n",
    "Вы ведь не забыли, как мы можем применить знания о word2vec и GloVe. Давайте попробуем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:48:24.797374Z",
     "start_time": "2021-10-10T14:48:24.278369Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:48:30.025378Z",
     "start_time": "2021-10-10T14:48:24.799363Z"
    },
    "id": "iW46gGLNuo0q"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, vectors=GloVe(name='6B',dim=300))\n",
    "# подсказка: один из импортов пока не использовался, быть может он нужен в строке выше :)\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "word_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "kernel_sizes = [3, 4, 5]\n",
    "vocab_size = len(TEXT.vocab)\n",
    "dropout = 0.5\n",
    "dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:48:44.259378Z",
     "start_time": "2021-10-10T14:48:30.027370Z"
    },
    "id": "MZ4YwLlcltm3"
   },
   "outputs": [],
   "source": [
    "train, tst = datasets.IMDB.splits(TEXT, LABEL)\n",
    "trn, vld = train.split(random_state=random.seed(SEED))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (trn, vld, tst),\n",
    "        batch_sizes=(128, 256, 256),\n",
    "        sort=False,\n",
    "        sort_key= lambda x: len(x.src),\n",
    "        sort_within_batch=False,\n",
    "        device=device,\n",
    "        repeat=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:48:44.986362Z",
     "start_time": "2021-10-10T14:48:44.260368Z"
    },
    "id": "2l5pDvZgl7Fp"
   },
   "outputs": [],
   "source": [
    "model = CNN(vocab_size=vocab_size, emb_dim=dim, out_channels=64,\n",
    "            kernel_sizes=kernel_sizes, dropout=dropout)\n",
    "\n",
    "word_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "prev_shape = model.embedding.weight.shape\n",
    "\n",
    "model.embedding.weight.data.copy_(word_embeddings)\n",
    "\n",
    "assert prev_shape == model.embedding.weight.shape\n",
    "model.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwiQjcuiFGTC"
   },
   "source": [
    "Вы знаете, что делать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:50:14.486570Z",
     "start_time": "2021-10-10T14:48:44.988363Z"
    },
    "id": "fNqcFHT8cT0b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.519368588924408, Validation Loss: 0.38863396644592285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.3089892268180847, Validation Loss: 0.35591715574264526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.1747584044933319, Validation Loss: 0.38263168931007385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.07251763343811035, Validation Loss: 0.4372585117816925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "cur_patience = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_iter), total=len(train_iter), leave=False)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    for it, batch in pbar: \n",
    "        opt.zero_grad()\n",
    "        input_embeds=batch.text\n",
    "        labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "        preds=model(input_embeds)\n",
    "        loss=loss_func(preds,labels)\n",
    "        loss.requires_grad_()\n",
    "        loss.backward()\n",
    "        train_loss+=loss\n",
    "        opt.step()\n",
    "\n",
    "    train_loss /= len(train_iter)\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    pbar = tqdm(enumerate(val_iter), total=len(val_iter), leave=False)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    with torch.no_grad():\n",
    "        for it, batch in pbar:\n",
    "            with torch.no_grad():\n",
    "                input_embeds=batch.text\n",
    "                all_labels+=batch.label.tolist()\n",
    "                labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "                preds=model(input_embeds)\n",
    "                all_preds+=list(map(lambda pred:np.where(pred > 0, 1, 0),preds.cpu()))\n",
    "                val_loss+=loss_func(preds,labels)\n",
    "\n",
    "    val_loss /= len(val_iter)\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "    else:\n",
    "        cur_patience += 1\n",
    "        if cur_patience == patience:\n",
    "            cur_patience = 0\n",
    "            break\n",
    "    \n",
    "    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, train_loss, val_loss))\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:50:15.343410Z",
     "start_time": "2021-10-10T14:50:14.488572Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(best_model,'bestCNN_EMB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:50:26.508086Z",
     "start_time": "2021-10-10T14:50:15.345409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.566675066947937\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "pbar = tqdm(enumerate(test_iter), total=len(test_iter), leave=False)\n",
    "pbar.set_description(f\"Test\")\n",
    "with torch.no_grad():\n",
    "    for it, batch in pbar:\n",
    "        input_embeds=batch.text\n",
    "        all_labels+=batch.label.tolist()\n",
    "        labels=torch.unsqueeze(batch.label,1).to(device)\n",
    "        preds=model(input_embeds)\n",
    "        all_preds+=list(map(lambda pred:np.where(pred > 0, 1, 0),preds.cpu()))\n",
    "        test_loss+=loss_func(preds,labels)\n",
    "            \n",
    "test_loss /= len(test_iter)\n",
    "print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:50:26.618087Z",
     "start_time": "2021-10-10T14:50:26.510086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918142211356327"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_labels,all_preds,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2IdEWJQKESg"
   },
   "source": [
    "Посчитайте f1-score вашего классификатора.\n",
    "\n",
    "**Ответ**: 0.7918142211356327"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sl7h_wIRGPD"
   },
   "source": [
    "Проверим насколько все хорошо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:51:15.425084Z",
     "start_time": "2021-10-10T14:50:26.620087Z"
    },
    "id": "iPCm55FLir3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  pos ( 0.96 ) , delta:  tensor([0.0002], device='cuda:0', dtype=torch.float64)\n",
      "pred:  neg ( 0.05 ) , delta:  tensor([4.6202e-05], device='cuda:0', dtype=torch.float64)\n",
      "pred:  pos ( 0.97 ) , delta:  tensor([5.3753e-05], device='cuda:0', dtype=torch.float64)\n",
      "pred:  neg ( 0.00 ) , delta:  tensor([0.0001], device='cuda:0', dtype=torch.float64)\n",
      "pred:  neg ( 0.19 ) , delta:  tensor([8.2251e-05], device='cuda:0', dtype=torch.float64)\n",
      "pred:  neg ( 0.01 ) , delta:  tensor([1.7849e-05], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PAD_IND = TEXT.vocab.stoi['pad']\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "lig = LayerIntegratedGradients(model, model.embedding)\n",
    "vis_data_records_ig = []\n",
    "\n",
    "interpret_sentence(model, 'It was a fantastic performance !', label=1)\n",
    "interpret_sentence(model, 'Best film ever', label=1)\n",
    "interpret_sentence(model, 'Such a great show!', label=1)\n",
    "interpret_sentence(model, 'It was a horrible movie', label=0)\n",
    "interpret_sentence(model, 'I\\'ve never watched something as bad', label=0)\n",
    "interpret_sentence(model, 'It is a disgusting movie!', label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T14:51:15.441087Z",
     "start_time": "2021-10-10T14:51:15.426086Z"
    },
    "id": "NMDazB3AlFWA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.96)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.46</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 56%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.05)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.41</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.97)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.46</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 58%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show!                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.70</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.19)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.30</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I've                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.01)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.34</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie!                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " [homework]classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
