{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUI02UFXY5lZ"
   },
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ RNN. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "–ü—Ä–∏–≤–µ—Ç! –í —ç—Ç–æ —Å–µ–º–∏–Ω–∞—Ä–µ –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è —Å –∑–∞–¥–∞—á–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –ø–æ–∏—Å–∫–∞ —Ç–µ–º–∞—Ç–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏, –∞ —Ç–∞–∫–∂–µ —Å –¥–≤—É–º—è –∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π ‚Äì¬†RNN –∏ GRU.\n",
    "\n",
    "–ù–∞–º –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –æ—Ç `HuggingFaceü§ó` –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º `datasets`. –û–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:22:10.909467Z",
     "start_time": "2021-10-09T08:22:10.905467Z"
    },
    "id": "4eSlBJXbpNhH"
   },
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:23:27.683970Z",
     "start_time": "2021-10-09T08:23:22.686493Z"
    },
    "id": "gwNeXLCXr4ue"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:34:11.226542Z",
     "start_time": "2021-10-09T08:34:11.209541Z"
    },
    "id": "IBGF3mNQKAgN"
   },
   "outputs": [],
   "source": [
    "# –ó–∞ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º!\n",
    "SEED = 0xDEAD\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YX-nNNuqZ9GN"
   },
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π: `AgNews`. –í –Ω–µ–º —Ä–∞–∑–¥–µ–ª–µ–Ω—ã —Ç–µ–∫—Å—Ç—ã –Ω–∞ 4 —Ç–µ–º—ã: `World`, `Sports`, `Business`, `Sci/Tech`. –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:34:37.602227Z",
     "start_time": "2021-10-09T08:34:36.086654Z"
    },
    "id": "_LREB3dpscnH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\BIT\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc4fc42750a49e2b45717ff1dacf7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 120000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"ag_news\")\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:39:20.208614Z",
     "start_time": "2021-10-09T08:39:20.191615Z"
    },
    "id": "-YysP5HpsiBX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QK1tDYKaTJa"
   },
   "source": [
    "–í `dataset` –Ω–∞—Ö–æ–¥—è—Ç—Å—è `train` –∏ `test` —á–∞—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:34:44.534852Z",
     "start_time": "2021-10-09T08:34:44.528851Z"
    },
    "id": "wjEB-Yv09AQo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmSIXBJPaegW"
   },
   "source": [
    "–ß—Ç–æ–±—ã –ø—Ä–µ–≤—Ä–∞—â–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–±–æ—Ä–∞ —Å–ª–æ–≤ –≤ –Ω–∞–±–æ—Ä –≤–µ–∫—Ç–æ—Ä–æ–≤ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏. –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏—Ö —Å–ø–∏—Å–æ–∫ –∏ –≤—ã–±–µ—Ä–µ–º –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:35:47.348432Z",
     "start_time": "2021-10-09T08:35:47.044372Z"
    },
    "id": "FGW4jSiswVDy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(api.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:38:24.064618Z",
     "start_time": "2021-10-09T08:35:48.187576Z"
    },
    "id": "xd1RzPKhwC3q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAIznT0Kaue8"
   },
   "source": [
    "–¢–æ–∫–µ–Ω–µ–∑–∏—Ä—É–µ–º –Ω–∞—à —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:39:37.048664Z",
     "start_time": "2021-10-09T08:39:23.821666Z"
    },
    "id": "F6k91UgcAQNz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891284dd7f1447f481cc29170b52745c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800f09a29bbb4f328834c69f233e5ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH=128\n",
    "\n",
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "dataset = dataset.map( # –æ–±—Ä–∞—â–∞–µ–º—Å—è –∫ dataset (train –∏ test)\n",
    "    lambda item: {\n",
    "        \"tokenized\": tokenizer.tokenize(item[\"text\"])[:MAX_LENGTH] # —Å–æ–∑–¥–∞—ë–º tokenized –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è (text, label)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:40:01.164937Z",
     "start_time": "2021-10-09T08:40:01.149942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'tokenized'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'tokenized'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:42:58.872115Z",
     "start_time": "2021-10-09T08:42:51.008113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wall',\n",
       " 'St',\n",
       " '.',\n",
       " 'Bears',\n",
       " 'Claw',\n",
       " 'Back',\n",
       " 'Into',\n",
       " 'the',\n",
       " 'Black',\n",
       " '(',\n",
       " 'Reuters',\n",
       " ')',\n",
       " 'Reuters',\n",
       " '-',\n",
       " 'Short',\n",
       " '-',\n",
       " 'sellers',\n",
       " ',',\n",
       " 'Wall',\n",
       " 'Street',\n",
       " \"'\",\n",
       " 's',\n",
       " 'dwindling',\n",
       " '\\\\',\n",
       " 'band',\n",
       " 'of',\n",
       " 'ultra',\n",
       " '-',\n",
       " 'cynics',\n",
       " ',',\n",
       " 'are',\n",
       " 'seeing',\n",
       " 'green',\n",
       " 'again',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['tokenized'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqrtz1bDk2Ws"
   },
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –º–∞–ø–∏–Ω–≥ –∏–∑ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:45:07.121108Z",
     "start_time": "2021-10-09T08:45:06.790104Z"
    },
    "id": "SMDWoNeEArA6"
   },
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(word2vec.index2word)} # –∫–ª—é—á - —Å–ª–æ–≤–æ, –∑–Ω–∞—á–µ–Ω–∏–µ - –∏–Ω–¥–µ–∫—Å\n",
    "# word2vec.index2word - –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–æ (–ª–∏—Å—Ç —Å–ª–æ–≤)\n",
    "# word2idx - –ø–æ —Å–ª–æ–≤—É –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:45:53.814476Z",
     "start_time": "2021-10-09T08:45:53.768478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<user>': 0,\n",
       " '.': 1,\n",
       " ':': 2,\n",
       " 'rt': 3,\n",
       " ',': 4,\n",
       " '<repeat>': 5,\n",
       " '<hashtag>': 6,\n",
       " '<number>': 7,\n",
       " '<url>': 8,\n",
       " '!': 9,\n",
       " 'i': 10,\n",
       " 'a': 11,\n",
       " '\"': 12,\n",
       " 'the': 13,\n",
       " '?': 14,\n",
       " 'you': 15,\n",
       " 'to': 16,\n",
       " '(': 17,\n",
       " '<allcaps>': 18,\n",
       " '<elong>': 19,\n",
       " ')': 20,\n",
       " 'me': 21,\n",
       " 'de': 22,\n",
       " '<smile>': 23,\n",
       " 'ÔºÅ': 24,\n",
       " 'que': 25,\n",
       " 'and': 26,\n",
       " '„ÄÇ': 27,\n",
       " '-': 28,\n",
       " 'my': 29,\n",
       " 'no': 30,\n",
       " '„ÄÅ': 31,\n",
       " 'is': 32,\n",
       " 'it': 33,\n",
       " '‚Ä¶': 34,\n",
       " 'in': 35,\n",
       " 'n': 36,\n",
       " 'for': 37,\n",
       " '/': 38,\n",
       " 'of': 39,\n",
       " 'la': 40,\n",
       " \"'s\": 41,\n",
       " '*': 42,\n",
       " 'do': 43,\n",
       " \"n't\": 44,\n",
       " 'that': 45,\n",
       " 'on': 46,\n",
       " 'y': 47,\n",
       " \"'\": 48,\n",
       " 'e': 49,\n",
       " 'o': 50,\n",
       " 'u': 51,\n",
       " 'en': 52,\n",
       " 'this': 53,\n",
       " 'el': 54,\n",
       " 'so': 55,\n",
       " 'be': 56,\n",
       " \"'m\": 57,\n",
       " 'with': 58,\n",
       " 'just': 59,\n",
       " '>': 60,\n",
       " 'your': 61,\n",
       " '^': 62,\n",
       " 'like': 63,\n",
       " 'have': 64,\n",
       " 'te': 65,\n",
       " 'at': 66,\n",
       " 'Ôºü': 67,\n",
       " 'love': 68,\n",
       " 'se': 69,\n",
       " 'are': 70,\n",
       " '<': 71,\n",
       " 'm': 72,\n",
       " 'r': 73,\n",
       " 'if': 74,\n",
       " 'all': 75,\n",
       " 'b': 76,\n",
       " '„Éª': 77,\n",
       " 'not': 78,\n",
       " 'but': 79,\n",
       " 'we': 80,\n",
       " 'es': 81,\n",
       " 'ya': 82,\n",
       " '&': 83,\n",
       " 'follow': 84,\n",
       " 'up': 85,\n",
       " 'what': 86,\n",
       " 'get': 87,\n",
       " 'lol': 88,\n",
       " 'un': 89,\n",
       " '‚ô•': 90,\n",
       " 'lo': 91,\n",
       " 'when': 92,\n",
       " 'was': 93,\n",
       " '‚Äú': 94,\n",
       " '‚Äù': 95,\n",
       " 'one': 96,\n",
       " 'por': 97,\n",
       " 'si': 98,\n",
       " 'out': 99,\n",
       " '_': 100,\n",
       " 'mi': 101,\n",
       " 'can': 102,\n",
       " '<sadface>': 103,\n",
       " 'ŸÖŸÜ': 104,\n",
       " '‚ô°': 105,\n",
       " '¬¥': 106,\n",
       " 'he': 107,\n",
       " 'con': 108,\n",
       " 'they': 109,\n",
       " 'now': 110,\n",
       " 'go': 111,\n",
       " 'ÿå': 112,\n",
       " 'para': 113,\n",
       " 'los': 114,\n",
       " 'know': 115,\n",
       " 'haha': 116,\n",
       " 'good': 117,\n",
       " 'tu': 118,\n",
       " 'back': 119,\n",
       " '~': 120,\n",
       " 'about': 121,\n",
       " 'new': 122,\n",
       " ';': 123,\n",
       " 'as': 124,\n",
       " 'day': 125,\n",
       " 'how': 126,\n",
       " 'who': 127,\n",
       " 'will': 128,\n",
       " 'want': 129,\n",
       " 'people': 130,\n",
       " 'yo': 131,\n",
       " 'eu': 132,\n",
       " 'from': 133,\n",
       " 'di': 134,\n",
       " 'time': 135,\n",
       " '<heart>': 136,\n",
       " 's': 137,\n",
       " 'aku': 138,\n",
       " 'da': 139,\n",
       " \"'re\": 140,\n",
       " '<lolface>': 141,\n",
       " 'una': 142,\n",
       " 'got': 143,\n",
       " 'las': 144,\n",
       " 'more': 145,\n",
       " 'x': 146,\n",
       " 'she': 147,\n",
       " 'today': 148,\n",
       " 'Ôºà': 149,\n",
       " '>>': 150,\n",
       " 'k': 151,\n",
       " 'by': 152,\n",
       " 'or': 153,\n",
       " 'ŸÅŸä': 154,\n",
       " 'ÔΩ•': 155,\n",
       " 'too': 156,\n",
       " 'le': 157,\n",
       " '√©': 158,\n",
       " '|': 159,\n",
       " '[': 160,\n",
       " 'Ôºâ': 161,\n",
       " ']': 162,\n",
       " 'see': 163,\n",
       " 'why': 164,\n",
       " 'yg': 165,\n",
       " 'ca': 166,\n",
       " 'como': 167,\n",
       " 'her': 168,\n",
       " '‚Äî': 169,\n",
       " 'q': 170,\n",
       " 'need': 171,\n",
       " 'an': 172,\n",
       " 'na': 173,\n",
       " 'Á¨ë': 174,\n",
       " 'there': 175,\n",
       " 'œâ': 176,\n",
       " 'happy': 177,\n",
       " 'im': 178,\n",
       " 'mas': 179,\n",
       " 'je': 180,\n",
       " 'life': 181,\n",
       " 'really': 182,\n",
       " 'make': 183,\n",
       " 'yang': 184,\n",
       " 'shit': 185,\n",
       " 'think': 186,\n",
       " 't': 187,\n",
       " '‚ù§': 188,\n",
       " 'n√£o': 189,\n",
       " 'never': 190,\n",
       " 'some': 191,\n",
       " 'ÔΩû': 192,\n",
       " 'oh': 193,\n",
       " '‚òÖ': 194,\n",
       " 'did': 195,\n",
       " 'would': 196,\n",
       " 'del': 197,\n",
       " '`': 198,\n",
       " 'd': 199,\n",
       " 'please': 200,\n",
       " 'via': 201,\n",
       " 'much': 202,\n",
       " 'fuck': 203,\n",
       " 'al': 204,\n",
       " 'dia': 205,\n",
       " '$': 206,\n",
       " 'Ÿà': 207,\n",
       " 'right': 208,\n",
       " 'best': 209,\n",
       " 'c': 210,\n",
       " 'going': 211,\n",
       " 'ÿßŸÑŸÑŸá': 212,\n",
       " 'pero': 213,\n",
       " 'only': 214,\n",
       " 'has': 215,\n",
       " '‚ô™': 216,\n",
       " \"'ll\": 217,\n",
       " 'twitter': 218,\n",
       " '=': 219,\n",
       " 'hahaha': 220,\n",
       " 'its': 221,\n",
       " 'nn': 222,\n",
       " 'ÔΩÄ': 223,\n",
       " '¬ø': 224,\n",
       " 'am': 225,\n",
       " 'say': 226,\n",
       " '<neutralface>': 227,\n",
       " 'them': 228,\n",
       " 'here': 229,\n",
       " 'ŸÑÿß': 230,\n",
       " 'off': 231,\n",
       " 'still': 232,\n",
       " 'dan': 233,\n",
       " '+': 234,\n",
       " 'night': 235,\n",
       " 'w': 236,\n",
       " 'ada': 237,\n",
       " 'someone': 238,\n",
       " 'even': 239,\n",
       " 'then': 240,\n",
       " '‚òÜ': 241,\n",
       " 'ni': 242,\n",
       " 'come': 243,\n",
       " 'com': 244,\n",
       " 'always': 245,\n",
       " 'man': 246,\n",
       " \"'ve\": 247,\n",
       " 'been': 248,\n",
       " 'his': 249,\n",
       " 'itu': 250,\n",
       " 'ÿπŸÑŸâ': 251,\n",
       " '-_-': 252,\n",
       " '‚ò∫': 253,\n",
       " 'over': 254,\n",
       " 'um': 255,\n",
       " 'ŸÖÿß': 256,\n",
       " 'hate': 257,\n",
       " 'girl': 258,\n",
       " 'ai': 259,\n",
       " 'had': 260,\n",
       " 'pra': 261,\n",
       " 'todo': 262,\n",
       " 'mais': 263,\n",
       " 'feel': 264,\n",
       " 'let': 265,\n",
       " 'ini': 266,\n",
       " 'because': 267,\n",
       " 'Ôæü': 268,\n",
       " 'thanks': 269,\n",
       " 'ah': 270,\n",
       " 'way': 271,\n",
       " 'ever': 272,\n",
       " 'look': 273,\n",
       " 'tweet': 274,\n",
       " 'followers': 275,\n",
       " 'should': 276,\n",
       " 'our': 277,\n",
       " 'xd': 278,\n",
       " 'aja': 279,\n",
       " 'esta': 280,\n",
       " 'school': 281,\n",
       " 'him': 282,\n",
       " 'ser': 283,\n",
       " 'take': 284,\n",
       " 'than': 285,\n",
       " 'video': 286,\n",
       " 'em': 287,\n",
       " 'last': 288,\n",
       " 'wanna': 289,\n",
       " 'does': 290,\n",
       " 'us': 291,\n",
       " 'miss': 292,\n",
       " 'l': 293,\n",
       " 'ga': 294,\n",
       " 'better': 295,\n",
       " 'well': 296,\n",
       " 'could': 297,\n",
       " '‚ñΩ': 298,\n",
       " '%': 299,\n",
       " 'apa': 300,\n",
       " 'cuando': 301,\n",
       " 'team': 302,\n",
       " '‚úî': 303,\n",
       " '@': 304,\n",
       " 'ok': 305,\n",
       " 'ÿü': 306,\n",
       " '‚Ä¢': 307,\n",
       " 'vida': 308,\n",
       " 'quiero': 309,\n",
       " 'les': 310,\n",
       " 'being': 311,\n",
       " 'real': 312,\n",
       " 'down': 313,\n",
       " 'kamu': 314,\n",
       " 'everyone': 315,\n",
       " 'gonna': 316,\n",
       " 'live': 317,\n",
       " 'tonight': 318,\n",
       " 'yes': 319,\n",
       " 'work': 320,\n",
       " 'ass': 321,\n",
       " 'retweet': 322,\n",
       " 'nada': 323,\n",
       " 'sama': 324,\n",
       " 'first': 325,\n",
       " '<<': 326,\n",
       " 'photo': 327,\n",
       " 'tomorrow': 328,\n",
       " 'where': 329,\n",
       " 'god': 330,\n",
       " 'son': 331,\n",
       " 'ke': 332,\n",
       " 'ta': 333,\n",
       " 'f': 334,\n",
       " 'home': 335,\n",
       " 'lagi': 336,\n",
       " 'thank': 337,\n",
       " 'birthday': 338,\n",
       " '‚ñà': 339,\n",
       " 'ha': 340,\n",
       " 'great': 341,\n",
       " 'lmao': 342,\n",
       " 'omg': 343,\n",
       " 'morning': 344,\n",
       " 'm√°s': 345,\n",
       " 'mau': 346,\n",
       " 'baby': 347,\n",
       " 'dont': 348,\n",
       " 'ÔΩ°': 349,\n",
       " 'their': 350,\n",
       " 'p': 351,\n",
       " 'things': 352,\n",
       " 'game': 353,\n",
       " 'pas': 354,\n",
       " 'bad': 355,\n",
       " 'year': 356,\n",
       " 'yeah': 357,\n",
       " 'su': 358,\n",
       " 'bitch': 359,\n",
       " '–≤': 360,\n",
       " 'stop': 361,\n",
       " 'hoy': 362,\n",
       " 'something': 363,\n",
       " 'meu': 364,\n",
       " 'tak': 365,\n",
       " 'gak': 366,\n",
       " 'world': 367,\n",
       " 'amor': 368,\n",
       " 'h': 369,\n",
       " '\\\\': 370,\n",
       " 'ver': 371,\n",
       " 'Ôºõ': 372,\n",
       " 'porque': 373,\n",
       " 'give': 374,\n",
       " 'these': 375,\n",
       " 'ÿßŸÑŸÑŸáŸÖ': 376,\n",
       " 'were': 377,\n",
       " 'hay': 378,\n",
       " 'sleep': 379,\n",
       " 'gue': 380,\n",
       " 'every': 381,\n",
       " 'friends': 382,\n",
       " 'uma': 383,\n",
       " 'tell': 384,\n",
       " 'amo': 385,\n",
       " 'vou': 386,\n",
       " 'bien': 387,\n",
       " '¬°': 388,\n",
       " 'again': 389,\n",
       " 'Ôºæ': 390,\n",
       " 'Ôºè': 391,\n",
       " 'done': 392,\n",
       " 'after': 393,\n",
       " 'todos': 394,\n",
       " 'girls': 395,\n",
       " 'guys': 396,\n",
       " 'getting': 397,\n",
       " 'big': 398,\n",
       " 'wait': 399,\n",
       " 'justin': 400,\n",
       " 'eh': 401,\n",
       " '‚Üí': 402,\n",
       " 'kan': 403,\n",
       " 'kita': 404,\n",
       " 'jajaja': 405,\n",
       " 'wish': 406,\n",
       " 'said': 407,\n",
       " 'fucking': 408,\n",
       " 'show': 409,\n",
       " 'thing': 410,\n",
       " 'next': 411,\n",
       " 'voc√™': 412,\n",
       " 'nos': 413,\n",
       " 'little': 414,\n",
       " 'tengo': 415,\n",
       " 'keep': 416,\n",
       " 'person': 417,\n",
       " \"''\": 418,\n",
       " '‚àÄ': 419,\n",
       " 'hope': 420,\n",
       " 'ŸÉŸÑ': 421,\n",
       " 'hey': 422,\n",
       " 'bisa': 423,\n",
       " 'free': 424,\n",
       " 'made': 425,\n",
       " 'foto': 426,\n",
       " 'va': 427,\n",
       " 'everything': 428,\n",
       " 'iya': 429,\n",
       " 'nigga': 430,\n",
       " 'eso': 431,\n",
       " 'et': 432,\n",
       " 'watch': 433,\n",
       " 'music': 434,\n",
       " 'week': 435,\n",
       " 'talk': 436,\n",
       " 'ne': 437,\n",
       " 'solo': 438,\n",
       " 'gente': 439,\n",
       " 'udah': 440,\n",
       " 'Ôºö': 441,\n",
       " '--': 442,\n",
       " 'Ôºº': 443,\n",
       " 'mejor': 444,\n",
       " 'facebook': 445,\n",
       " 'ma': 446,\n",
       " 'v': 447,\n",
       " 'phone': 448,\n",
       " 'most': 449,\n",
       " 'same': 450,\n",
       " 'okay': 451,\n",
       " 'ik': 452,\n",
       " 'before': 453,\n",
       " 'minha': 454,\n",
       " 'days': 455,\n",
       " 'g': 456,\n",
       " 'ti': 457,\n",
       " 'damn': 458,\n",
       " 'nice': 459,\n",
       " 'voy': 460,\n",
       " 'vai': 461,\n",
       " 'call': 462,\n",
       " 'long': 463,\n",
       " 'tapi': 464,\n",
       " 'http': 465,\n",
       " 'sin': 466,\n",
       " 'nunca': 467,\n",
       " 'doing': 468,\n",
       " 'other': 469,\n",
       " 'find': 470,\n",
       " 'il': 471,\n",
       " 'sa': 472,\n",
       " 'sorry': 473,\n",
       " 'nya': 474,\n",
       " 'orang': 475,\n",
       " '¬∞': 476,\n",
       " 'hard': 477,\n",
       " 'mean': 478,\n",
       " 'die': 479,\n",
       " 'ÿßŸÑŸÑŸä': 480,\n",
       " 'tem': 481,\n",
       " 'soy': 482,\n",
       " 'este': 483,\n",
       " 'kalo': 484,\n",
       " 's√≥': 485,\n",
       " 'th': 486,\n",
       " 'win': 487,\n",
       " 'nothing': 488,\n",
       " 'into': 489,\n",
       " 'face': 490,\n",
       " 'cute': 491,\n",
       " \"'d\": 492,\n",
       " 'gracias': 493,\n",
       " 'lah': 494,\n",
       " '–∏': 495,\n",
       " 'any': 496,\n",
       " 'play': 497,\n",
       " '‚Üê': 498,\n",
       " 'ko': 499,\n",
       " 'text': 500,\n",
       " '‚å£': 501,\n",
       " 'estoy': 502,\n",
       " 'tau': 503,\n",
       " 'ur': 504,\n",
       " 'buat': 505,\n",
       " '#': 506,\n",
       " 'cause': 507,\n",
       " '—è': 508,\n",
       " 'put': 509,\n",
       " 'kau': 510,\n",
       " 'siempre': 511,\n",
       " 'juga': 512,\n",
       " 'casa': 513,\n",
       " 'ÿ£ŸÜ': 514,\n",
       " 'help': 515,\n",
       " 'start': 516,\n",
       " 'feliz': 517,\n",
       " 'old': 518,\n",
       " 'ir': 519,\n",
       " 'very': 520,\n",
       " 'care': 521,\n",
       " 'bir': 522,\n",
       " 'makes': 523,\n",
       " 'song': 524,\n",
       " 'check': 525,\n",
       " 'watching': 526,\n",
       " 'ahora': 527,\n",
       " 'jadi': 528,\n",
       " 'os': 529,\n",
       " 'may': 530,\n",
       " 'friend': 531,\n",
       " 'beautiful': 532,\n",
       " 'heart': 533,\n",
       " 'ka': 534,\n",
       " 'vc': 535,\n",
       " 'mundo': 536,\n",
       " '–Ω–∞': 537,\n",
       " 'sure': 538,\n",
       " 'tan': 539,\n",
       " 'pretty': 540,\n",
       " 'aqui': 541,\n",
       " '–Ω–µ': 542,\n",
       " 'house': 543,\n",
       " 'ÿ±ÿ™ŸàŸäÿ™': 544,\n",
       " 'Ÿäÿß': 545,\n",
       " 'ja': 546,\n",
       " 'true': 547,\n",
       " 'muy': 548,\n",
       " 'away': 549,\n",
       " 'already': 550,\n",
       " 'actually': 551,\n",
       " 'believe': 552,\n",
       " 'try': 553,\n",
       " 'many': 554,\n",
       " 'ma√±ana': 555,\n",
       " 'mis': 556,\n",
       " 'lu': 557,\n",
       " 'those': 558,\n",
       " 'hot': 559,\n",
       " 'qu√©': 560,\n",
       " 'mal': 561,\n",
       " 'ÿπŸÜ': 562,\n",
       " 'though': 563,\n",
       " 'ask': 564,\n",
       " 'amazing': 565,\n",
       " 'bed': 566,\n",
       " '}': 567,\n",
       " 'two': 568,\n",
       " 'mom': 569,\n",
       " 'd√≠a': 570,\n",
       " 've': 571,\n",
       " 'dari': 572,\n",
       " 'gameinsight': 573,\n",
       " 'stay': 574,\n",
       " 'fun': 575,\n",
       " 'around': 576,\n",
       " 'van': 577,\n",
       " 'cont': 578,\n",
       " 'ready': 579,\n",
       " 'money': 580,\n",
       " 'bu': 581,\n",
       " 'funny': 582,\n",
       " 'cool': 583,\n",
       " 'hair': 584,\n",
       " '√†': 585,\n",
       " 'tho': 586,\n",
       " '{': 587,\n",
       " 'wo': 588,\n",
       " 'hi': 589,\n",
       " 'name': 590,\n",
       " 'tiene': 591,\n",
       " 'hahahaha': 592,\n",
       " 'pa': 593,\n",
       " 'algo': 594,\n",
       " 'gotta': 595,\n",
       " 'ŸàŸÑÿß': 596,\n",
       " 'boy': 597,\n",
       " 'another': 598,\n",
       " \"c'est\": 599,\n",
       " 'hari': 600,\n",
       " 'jajajaja': 601,\n",
       " 'having': 602,\n",
       " 'cara': 603,\n",
       " 'jaja': 604,\n",
       " 'dm': 605,\n",
       " 'looking': 606,\n",
       " 'top': 607,\n",
       " 'android': 608,\n",
       " 'dah': 609,\n",
       " 'wow': 610,\n",
       " '‚ñë': 611,\n",
       " 'eres': 612,\n",
       " 'ben': 613,\n",
       " 'must': 614,\n",
       " 'news': 615,\n",
       " 'met': 616,\n",
       " 'est√°': 617,\n",
       " 'nih': 618,\n",
       " 'family': 619,\n",
       " 'black': 620,\n",
       " 'thought': 621,\n",
       " 'nak': 622,\n",
       " 'super': 623,\n",
       " 'end': 624,\n",
       " 'hace': 625,\n",
       " 'remember': 626,\n",
       " 'ama': 627,\n",
       " 'party': 628,\n",
       " 'cant': 629,\n",
       " 'vamos': 630,\n",
       " 'anything': 631,\n",
       " 'anyone': 632,\n",
       " 'ŸÅŸàŸÑŸà': 633,\n",
       " 'perfect': 634,\n",
       " 'guy': 635,\n",
       " 'vez': 636,\n",
       " 'christmas': 637,\n",
       " 'dos': 638,\n",
       " 'bueno': 639,\n",
       " 'nao': 640,\n",
       " 'years': 641,\n",
       " 'vote': 642,\n",
       " 'dormir': 643,\n",
       " 'bro': 644,\n",
       " 'else': 645,\n",
       " 'quien': 646,\n",
       " 'untuk': 647,\n",
       " 'jangan': 648,\n",
       " 'myself': 649,\n",
       " 'head': 650,\n",
       " 'mind': 651,\n",
       " 'gua': 652,\n",
       " 'talking': 653,\n",
       " 'while': 654,\n",
       " 'dat': 655,\n",
       " 'food': 656,\n",
       " '–¥': 657,\n",
       " 'coming': 658,\n",
       " 'wkwk': 659,\n",
       " 'trying': 660,\n",
       " 'saya': 661,\n",
       " 'mucho': 662,\n",
       " 'without': 663,\n",
       " 'wrong': 664,\n",
       " '‚Äôs': 665,\n",
       " 'baru': 666,\n",
       " '__': 667,\n",
       " 'hehe': 668,\n",
       " 'hacer': 669,\n",
       " 'lot': 670,\n",
       " 'followed': 671,\n",
       " 'crazy': 672,\n",
       " 'hell': 673,\n",
       " 'feeling': 674,\n",
       " 'des': 675,\n",
       " 'kok': 676,\n",
       " 'j': 677,\n",
       " 'stats': 678,\n",
       " \"j'\": 679,\n",
       " 'ÿßŸÜ': 680,\n",
       " 'tweets': 681,\n",
       " 'non': 682,\n",
       " 'cosas': 683,\n",
       " 'era': 684,\n",
       " 'high': 685,\n",
       " 'niggas': 686,\n",
       " 'change': 687,\n",
       " 'movie': 688,\n",
       " 'xx': 689,\n",
       " 'mad': 690,\n",
       " 'sih': 691,\n",
       " 'sometimes': 692,\n",
       " 'deh': 693,\n",
       " 'allah': 694,\n",
       " 'through': 695,\n",
       " 'pour': 696,\n",
       " 'ela': 697,\n",
       " 'soon': 698,\n",
       " 'gone': 699,\n",
       " 'playing': 700,\n",
       " 'smile': 701,\n",
       " 'bukan': 702,\n",
       " 'tv': 703,\n",
       " 'fans': 704,\n",
       " 'hasta': 705,\n",
       " 'akan': 706,\n",
       " \"y'\": 707,\n",
       " 'looks': 708,\n",
       " 'isso': 709,\n",
       " '‚úå': 710,\n",
       " 'tired': 711,\n",
       " 'boys': 712,\n",
       " 'might': 713,\n",
       " 'dong': 714,\n",
       " 'lg': 715,\n",
       " 'use': 716,\n",
       " 'maybe': 717,\n",
       " 'until': 718,\n",
       " 'menos': 719,\n",
       " 'own': 720,\n",
       " 'dengan': 721,\n",
       " 'eat': 722,\n",
       " 'ou': 723,\n",
       " 'weekend': 724,\n",
       " 'Àò': 725,\n",
       " 'class': 726,\n",
       " 'ele': 727,\n",
       " 'harry': 728,\n",
       " 'iphone': 729,\n",
       " 'friday': 730,\n",
       " 'single': 731,\n",
       " 'ff': 732,\n",
       " 'awesome': 733,\n",
       " 'bout': 734,\n",
       " 'muito': 735,\n",
       " 'hoje': 736,\n",
       " '¬¨': 737,\n",
       " 'dios': 738,\n",
       " 'such': 739,\n",
       " 'estar': 740,\n",
       " 'j√°': 741,\n",
       " 'quando': 742,\n",
       " 'esa': 743,\n",
       " 'making': 744,\n",
       " '‚îÅ': 745,\n",
       " 'times': 746,\n",
       " 'lmfao': 747,\n",
       " 'gw': 748,\n",
       " 'moment': 749,\n",
       " 'yet': 750,\n",
       " 'aw': 751,\n",
       " 'smh': 752,\n",
       " 'banget': 753,\n",
       " 'masih': 754,\n",
       " 'qui': 755,\n",
       " 'quem': 756,\n",
       " '‚Äì': 757,\n",
       " 'leave': 758,\n",
       " 'du': 759,\n",
       " 'une': 760,\n",
       " 'guess': 761,\n",
       " 'hit': 762,\n",
       " '—Å': 763,\n",
       " 'pm': 764,\n",
       " 'since': 765,\n",
       " 'pues': 766,\n",
       " 'est': 767,\n",
       " 'job': 768,\n",
       " 'Ôæâ': 769,\n",
       " 'mana': 770,\n",
       " 'bom': 771,\n",
       " 'siapa': 772,\n",
       " 'suka': 773,\n",
       " 'bieber': 774,\n",
       " 'mention': 775,\n",
       " 'lebih': 776,\n",
       " 'favorite': 777,\n",
       " 'bitches': 778,\n",
       " 'forever': 779,\n",
       " 'ŸÑŸä': 780,\n",
       " 'final': 781,\n",
       " 'read': 782,\n",
       " 'alguien': 783,\n",
       " 'open': 784,\n",
       " 'yourself': 785,\n",
       " 'ese': 786,\n",
       " 'che': 787,\n",
       " 'sex': 788,\n",
       " 'yaa': 789,\n",
       " 'car': 790,\n",
       " 'direction': 791,\n",
       " 'tidak': 792,\n",
       " 'seu': 793,\n",
       " 'gets': 794,\n",
       " 'left': 795,\n",
       " 're': 796,\n",
       " 'jam': 797,\n",
       " 'enough': 798,\n",
       " 'ÿ•ŸÑÿß': 799,\n",
       " 'once': 800,\n",
       " '‚Äô': 801,\n",
       " 'part': 802,\n",
       " 'cada': 803,\n",
       " 'ÂÆöÊúü': 804,\n",
       " 'ŸÑŸÉ': 805,\n",
       " 'een': 806,\n",
       " 'seen': 807,\n",
       " 'kak': 808,\n",
       " 'as√≠': 809,\n",
       " 'nem': 810,\n",
       " 'ÿπŸÖŸÑ': 811,\n",
       " 'white': 812,\n",
       " 'told': 813,\n",
       " 'says': 814,\n",
       " 'esto': 815,\n",
       " 'sad': 816,\n",
       " 'mo': 817,\n",
       " 'fue': 818,\n",
       " 'yah': 819,\n",
       " 'summer': 820,\n",
       " 'Ÿá': 821,\n",
       " '‚≠ï': 822,\n",
       " '¬ª': 823,\n",
       " 'thats': 824,\n",
       " 'ŸÖÿπ': 825,\n",
       " 'posted': 826,\n",
       " 'wants': 827,\n",
       " 'agora': 828,\n",
       " 'together': 829,\n",
       " 'fan': 830,\n",
       " 'men': 831,\n",
       " 'hear': 832,\n",
       " 'full': 833,\n",
       " '‚òÄ': 834,\n",
       " 'sigo': 835,\n",
       " 'pq': 836,\n",
       " 'dulu': 837,\n",
       " 'plus': 838,\n",
       " 'foi': 839,\n",
       " 'tudo': 840,\n",
       " 'ŸáŸà': 841,\n",
       " 'ill': 842,\n",
       " '„ÅÇ': 843,\n",
       " 'thinking': 844,\n",
       " 'wtf': 845,\n",
       " 'pagi': 846,\n",
       " 'mama': 847,\n",
       " 'kalau': 848,\n",
       " 'hati': 849,\n",
       " 'sexy': 850,\n",
       " 'sayang': 851,\n",
       " 'baik': 852,\n",
       " 'semua': 853,\n",
       " 'hola': 854,\n",
       " 'went': 855,\n",
       " 'vos': 856,\n",
       " 'tanto': 857,\n",
       " 'finally': 858,\n",
       " 'fb': 859,\n",
       " 'sea': 860,\n",
       " 'stupid': 861,\n",
       " 'tus': 862,\n",
       " 'seriously': 863,\n",
       " 'hora': 864,\n",
       " 'min': 865,\n",
       " 'pic': 866,\n",
       " 'estas': 867,\n",
       " 'turn': 868,\n",
       " 'hours': 869,\n",
       " 'excited': 870,\n",
       " 'nah': 871,\n",
       " 'buy': 872,\n",
       " 'saying': 873,\n",
       " 'mah': 874,\n",
       " 'break': 875,\n",
       " 'needs': 876,\n",
       " 'ce': 877,\n",
       " 'room': 878,\n",
       " 'choice': 879,\n",
       " 'far': 880,\n",
       " 'dead': 881,\n",
       " 'quero': 882,\n",
       " 'saw': 883,\n",
       " 'kids': 884,\n",
       " 'lil': 885,\n",
       " 'whole': 886,\n",
       " 'puede': 887,\n",
       " 'fall': 888,\n",
       " 'sus': 889,\n",
       " 'lost': 890,\n",
       " 'asi': 891,\n",
       " 'word': 892,\n",
       " '‚òπ': 893,\n",
       " 'also': 894,\n",
       " 'ÿ±Ÿäÿ™ŸàŸäÿ™': 895,\n",
       " 'probably': 896,\n",
       " 'everybody': 897,\n",
       " 'tarde': 898,\n",
       " 'run': 899,\n",
       " 'sei': 900,\n",
       " 'follback': 901,\n",
       " 'forget': 902,\n",
       " 'sweet': 903,\n",
       " 'welcome': 904,\n",
       " 'selamat': 905,\n",
       " 'Ôºø': 906,\n",
       " 'sur': 907,\n",
       " 'place': 908,\n",
       " 'gusta': 909,\n",
       " 'sabe': 910,\n",
       " 'androidgames': 911,\n",
       " 'tp': 912,\n",
       " 'tiempo': 913,\n",
       " 'ÿ®ÿ≥': 914,\n",
       " 'sou': 915,\n",
       " 'tuh': 916,\n",
       " 'vs': 917,\n",
       " 'eyes': 918,\n",
       " 'ÿßŸÜÿß': 919,\n",
       " 'picture': 920,\n",
       " 'das': 921,\n",
       " 'meet': 922,\n",
       " 'anak': 923,\n",
       " 'persona': 924,\n",
       " 'essa': 925,\n",
       " 'bored': 926,\n",
       " 'following': 927,\n",
       " 'nadie': 928,\n",
       " 'nobody': 929,\n",
       " 'dice': 930,\n",
       " 'alone': 931,\n",
       " 'sick': 932,\n",
       " 'red': 933,\n",
       " 'city': 934,\n",
       " 'cinta': 935,\n",
       " 'Êúà': 936,\n",
       " 'linda': 937,\n",
       " 'dream': 938,\n",
       " 'story': 939,\n",
       " 'km': 940,\n",
       " 'het': 941,\n",
       " 'waiting': 942,\n",
       " '^_^': 943,\n",
       " 'mine': 944,\n",
       " '—á—Ç–æ': 945,\n",
       " 'reason': 946,\n",
       " 'kk': 947,\n",
       " 'ŸÑŸà': 948,\n",
       " 'online': 949,\n",
       " 'fast': 950,\n",
       " 'udh': 951,\n",
       " 'wanted': 952,\n",
       " 'op': 953,\n",
       " 'others': 954,\n",
       " 'gay': 955,\n",
       " 'n‚Äôt': 956,\n",
       " 'used': 957,\n",
       " 'sem': 958,\n",
       " 'understand': 959,\n",
       " 'moi': 960,\n",
       " 'sm': 961,\n",
       " 'aint': 962,\n",
       " 'donde': 963,\n",
       " 'bem': 964,\n",
       " 'which': 965,\n",
       " 'ng': 966,\n",
       " 'followback': 967,\n",
       " 'punya': 968,\n",
       " 'late': 969,\n",
       " 'anda': 970,\n",
       " 'tidur': 971,\n",
       " 'puedo': 972,\n",
       " 'early': 973,\n",
       " 'nd': 974,\n",
       " 'personas': 975,\n",
       " 'banyak': 976,\n",
       " '‚úÖ': 977,\n",
       " '‚ûä': 978,\n",
       " 'trust': 979,\n",
       " 'noche': 980,\n",
       " 'tl': 981,\n",
       " 'Ôºû': 982,\n",
       " '¬´': 983,\n",
       " 'af': 984,\n",
       " 'move': 985,\n",
       " 'pro': 986,\n",
       " 'bring': 987,\n",
       " 'ku': 988,\n",
       " 'called': 989,\n",
       " 'relationship': 990,\n",
       " 'idk': 991,\n",
       " 'hurt': 992,\n",
       " 'st': 993,\n",
       " 'pernah': 994,\n",
       " 'pessoas': 995,\n",
       " 'hello': 996,\n",
       " 'uno': 997,\n",
       " 'unfollowers': 998,\n",
       " 'cry': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G_q_EgHlCWC"
   },
   "source": [
    "–ü–µ—Ä–µ–≤–µ–¥–µ–º —Ç–æ–∫–µ–Ω—ã –≤ –∏–Ω–¥–µ–∫—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:55:50.370476Z",
     "start_time": "2021-10-09T08:55:50.361478Z"
    },
    "id": "WVQX-b8mEKtA"
   },
   "outputs": [],
   "source": [
    "def encode(word):\n",
    "    if word in word2idx.keys():\n",
    "        return word2idx[word]\n",
    "    return word2idx[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:56:37.333268Z",
     "start_time": "2021-10-09T08:55:50.845820Z"
    },
    "id": "r9byefh6DSjV"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5306f78413d54716a01bafdbb3b90a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c723033351ca4eb5805d81b6a223a08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda item: { # item —ç–ª–µ–º–µ–Ω—Ç —Å–ª–æ–≤–∞—Ä—è –∏–∑ —Å–ª–æ–≤–∞—Ä—è {'train':...,'test':...}\n",
    "        \"features\": [encode(word) for word in item[\"tokenized\"]] # –∑–∞–º–µ–Ω—è–µ–º –Ω–∞–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∫–∞–∂–¥–æ–≥–æ item['features'] –Ω–∞ –ª–∏—Å—Ç –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ item['tokenized']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:56:40.570138Z",
     "start_time": "2021-10-09T08:56:40.549144Z"
    },
    "id": "Y05UCYA4D0OC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'label': 2,\n",
       " 'tokenized': ['Wall',\n",
       "  'St',\n",
       "  '.',\n",
       "  'Bears',\n",
       "  'Claw',\n",
       "  'Back',\n",
       "  'Into',\n",
       "  'the',\n",
       "  'Black',\n",
       "  '(',\n",
       "  'Reuters',\n",
       "  ')',\n",
       "  'Reuters',\n",
       "  '-',\n",
       "  'Short',\n",
       "  '-',\n",
       "  'sellers',\n",
       "  ',',\n",
       "  'Wall',\n",
       "  'Street',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'dwindling',\n",
       "  '\\\\',\n",
       "  'band',\n",
       "  'of',\n",
       "  'ultra',\n",
       "  '-',\n",
       "  'cynics',\n",
       "  ',',\n",
       "  'are',\n",
       "  'seeing',\n",
       "  'green',\n",
       "  'again',\n",
       "  '.'],\n",
       " 'features': [62980,\n",
       "  62980,\n",
       "  1,\n",
       "  62980,\n",
       "  62980,\n",
       "  62980,\n",
       "  62980,\n",
       "  13,\n",
       "  62980,\n",
       "  17,\n",
       "  62980,\n",
       "  20,\n",
       "  62980,\n",
       "  28,\n",
       "  62980,\n",
       "  28,\n",
       "  49286,\n",
       "  4,\n",
       "  62980,\n",
       "  62980,\n",
       "  48,\n",
       "  137,\n",
       "  214902,\n",
       "  370,\n",
       "  1645,\n",
       "  39,\n",
       "  8606,\n",
       "  28,\n",
       "  380053,\n",
       "  4,\n",
       "  70,\n",
       "  1321,\n",
       "  1745,\n",
       "  389,\n",
       "  1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T08:58:12.147280Z",
     "start_time": "2021-10-09T08:58:12.125283Z"
    },
    "id": "UiHvDSTAHJ8D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\AppData\\Local\\Temp/ipykernel_7068/3782232894.py:1: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use DatasetDict.remove_columns instead.\n",
      "  dataset.remove_columns_([\"text\", \"tokenized\"])\n"
     ]
    }
   ],
   "source": [
    "dataset.remove_columns_([\"text\", \"tokenized\"]) # —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å –µ—Å—Ç—å —Ñ–∏—á–∏ (–∏–Ω–¥–µ–∫—Å—ã –≤–µ–∫—Ç–æ—Ä–æ–≤ word2vec), —É–¥–∞–ª—è–µ–º —Ç–µ–∫—Å—Ç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOI1-AlYlbgA"
   },
   "source": [
    "–ü–µ—Ä–µ–≤–µ–¥–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:01:45.953901Z",
     "start_time": "2021-10-09T09:01:45.947905Z"
    },
    "id": "6VZ9EBnCK9V3"
   },
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:01:46.869483Z",
     "start_time": "2021-10-09T09:01:46.829222Z"
    },
    "id": "FWdVJKsnPtYX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(2),\n",
       " 'features': tensor([ 62980,  62980,      1,  62980,  62980,  62980,  62980,     13,  62980,\n",
       "             17,  62980,     20,  62980,     28,  62980,     28,  49286,      4,\n",
       "          62980,  62980,     48,    137, 214902,    370,   1645,     39,   8606,\n",
       "             28, 380053,      4,     70,   1321,   1745,    389,      1])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6haisMrlmSu"
   },
   "source": [
    "–•–æ—Ç–∏–º —Å–∫–ª–µ–∏—Ç—å –æ–±—ä–µ–∫—Ç—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω–Ω—ã –≤ –±–∞—Ç—á–∏. –î–ª—è —ç—Ç–æ–≥–æ –¥–∞–≤–∞–π—Ç–µ –Ω–∞–ø–∏—à–µ–º `collate_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:01:48.771221Z",
     "start_time": "2021-10-09T09:01:48.753221Z"
    },
    "id": "hzwuahwBxb2l"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch): # torch.long –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü\n",
    "    max_len = max(len(row[\"features\"]) for row in batch) # –¥–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞—Ç—á–µ\n",
    "    input_embeds = torch.empty((len(batch), max_len), dtype=torch.long) # –º–∞—Ç—Ä–∏—Ü–∞ –¥–ª–∏–Ω–∞ –±–∞—Ç—á–∞ x –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É (batch_size x seq_len)\n",
    "    labels = torch.empty(len(batch), dtype=torch.long) # –≤–µ–∫—Ç–æ—Ä –ª–µ–π–±–ª–æ–≤\n",
    "    for idx, row in enumerate(batch): # –∑–∞–ø–æ–ª–Ω—è–µ–º input_embeds –¥–∞–Ω–Ω—ã–º–∏; row —Å–ª–æ–≤–∞—Ä–∞—Ä—å(features, labels) (—ç–ª–µ–º–µ–Ω—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞)\n",
    "        to_pad = max_len - len(row[\"features\"]) # –∫–æ–ª-–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–ø–∞–¥–¥–∏–Ω–≥–∞\n",
    "        input_embeds[idx] = torch.cat((row[\"features\"], torch.zeros(to_pad))) # –≤ —Å–æ–æ—Ç–≤–µ—Ç. –ø–æ –∏–Ω–¥–µ–∫—Å—É —Å—Ç—Ä–æ–∫—É –º–∞—Ç—Ä–∏—Ü—ã input_embeds –≤—Å—Ç–∞–≤–ª—è–µ–º –∫–æ–Ω–∫–∞—Ç. —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏ –Ω—É–ª–µ–π –¥–æ–ø–ø–∞–¥–∏–Ω–≥–∞ (—Å—Ç—Ä–æ–∫–∞ - —Å–ª–æ–≤–æ) \n",
    "        labels[idx] = row[\"label\"] # –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é—â–∏–π –ø–æ –∏–Ω–¥–µ–∫—Å—É —ç–ª–µ–º–µ–Ω—Ç –≤–µ–∫—Ç—Ä–æ—Ä–∞ –ª–µ–π–±–ª–æ–≤ –≤—Å—Ç–≤–ª—è–µ–º –ª–µ–π–±–ª\n",
    "    return {\"features\": input_embeds, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:59:02.687976Z",
     "start_time": "2021-10-09T09:59:02.681976Z"
    },
    "id": "FdVbtWJzszbu"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = { # —Å–ª–æ–≤–∞—Ä—å('train':train_loader,'test':test_loader)\n",
    "    k: DataLoader(\n",
    "        ds, shuffle=(k==\"train\"), batch_size=32, collate_fn=collate_fn\n",
    "    ) for k, ds in dataset.items()\n",
    "}# k - train,test; ds - —Å–ª–æ–≤–∞—Ä—å(features,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbsqpZ-WfPqe"
   },
   "source": [
    "## CNN\n",
    "\n",
    "–ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º: CNN. –û–¥–Ω–æ–º–µ—Ä–Ω–∞—è –∫–æ–Ω–≤–æ–ª—é—Ü–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –í –∫–æ–Ω—Ü–µ –Ω–∞–¥–æ —Å–æ–±—Ä–∞—Ç—å –≤–µ–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é `AdaptiveMaxPool1d` –∏–ª–∏ `AdaptiveAvgPool1d`. –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –ª—é–±—É—é Feed Forward Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T10:07:28.537573Z",
     "start_time": "2021-10-09T10:07:28.419571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct  9 13:07:28 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 472.12       Driver Version: 472.12       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P8     2W /  N/A |   2657MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7068      C   ...onda\\envs\\deep\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     10408    C+G   Insufficient Permissions        N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:56:34.218193Z",
     "start_time": "2021-10-09T09:56:34.198195Z"
    },
    "id": "e9DMopWCiBlD"
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module): # –¥–µ–ª–∞–µ–º —Å–≤—ë—Ä—Ç–∫–∏ –Ω–∞ –≤–µ–∫—Ç–æ—Ä–∞—Ö\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4): # –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞ –∏–∑ 3 —Å–ª–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ (3 —Å–ª–æ–≤–∞ –≥—Ä—É–±—ã—Ö))\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embedding_dim=embed_size) # 1193514 x 25\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2), # embed_size –∏ hidden_size –æ—Ç–≤–µ—á–∞—é—Ç –∑–∞ —Ä–∞–∑–º–µ—Ä —Å—Ç–æ–ª–±—Ü–æ–≤(—Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–ª–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1), # –±–µ—Ä—ë—Ç –º–∞–∫—Å–∏–º—É–º –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º, –∏–∑–º–µ–Ω—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–∞–Ω–∞–ª (–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü - —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) (batch_size x hidden_size (50) x 1)\n",
    "            nn.Flatten(),\n",
    "        ) nn.AdaptiveMaxPool1d\n",
    "        self.cl = nn.Sequential(\n",
    "            nn.Linear(hidden_size, num_classes) # (batch_size x hidden_size x 1) -> (batch_size x num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # x - batch_size x seq_len (—Å—Ç—Ä–æ–∫–∏-–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è —Å–ø–∏—Å–∫–∞–º–∏ –∏–Ω–¥–µ–∫—Å–æ–≤)\n",
    "        x = self.embeddings(x)  # –ø–æ–¥–∞—é—Ç—Å—è –∏–Ω–¥–µ–∫—Å—ã –ø–æ–ª—É—á–∞—é—Ç—Å—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(0, 2, 1) # –º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ —Ü–∏—Ñ—Ä (batch_size, embed_dim, seq_le); x - –±–∞—Ç—á —Å—Ç–æ–ª–±—Ü–æ–≤-—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é—â–∏—Ö —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏\n",
    "        x = self.cnn(x) #Conv-BN-RELU+Conv-BN-RELU+Conv-BN-RELU+AMaxPool\n",
    "        prediction = self.cl(x) # batch_size x num_classes\n",
    "        return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:56:41.520459Z",
     "start_time": "2021-10-09T09:56:37.929234Z"
    },
    "id": "2Ed-3nQHjDrd"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNNModel(word2vec.vector_size, 50).to(device) # 50 - hidden_size - –Ω–∞ —Å–∫–æ–ª—å–∫–æ –∫–∞–Ω–∞–ª–æ–≤ –±—É–¥–µ–º —Ä–∞—Å—à–∏—Ä—è—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ —Å–≤—ë—Ä–∫—Ç–∞—Ö\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oZjYEBkgauj"
   },
   "source": [
    "–ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:57:39.998558Z",
     "start_time": "2021-10-09T09:57:39.986558Z"
    },
    "id": "Y7Smd5_03CSp"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\n",
    "def training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2):\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum() # argmax(-1) - (batch_size x num_classes -> batch_size x 1 (–Ω–æ–º–µ—Ä —Å—Ç–æ–ª–±—Ü–∞))\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T10:00:48.911014Z",
     "start_time": "2021-10-09T09:59:05.532180Z"
    },
    "id": "oOi77V2XjDpg"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.4036913812160492, accuracy: 0.8590788841247559\n"
     ]
    }
   ],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN8E8-ZSgnul"
   },
   "source": [
    "## RNN\n",
    "\n",
    "–í—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å: RNN. –≠—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Å–µ—Ç—å, –æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ –ø—Ä–æ—à–ª–æ–π –∏—Ç—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ. –≠—Ç–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Ñ–æ—Ä–º—É–ª:\n",
    "\n",
    "$$\n",
    "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
    "$$\n",
    "\n",
    "–ù–∞–ø–∏—à–µ–º —ç—Ç–æ—Ç –º–æ–¥—É–ª—å –Ω–∞ `Torch`!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:21:37.165994Z",
     "start_time": "2021-10-09T11:21:37.148998Z"
    },
    "id": "zBKQXeMOwie-"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.w_h = nn.Parameter(torch.rand(hidden_size, hidden_size)) # W.T\n",
    "        self.b_h = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_x = nn.Parameter(torch.rand(embed_size, hidden_size)) # V.T # (batch_size x embed_size * embed_size x hidden_size -> batch_size x hidden_size)\n",
    "        self.b_x = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        '''\n",
    "        x ‚Äì torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
    "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
    "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
    "        '''\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device) # (batch_size x hidden_size) [hidden - —Å—Ç—Ä–æ–∫–∞, –≤ —Ç–µ—Ç—Ä–∞–¥–∏ h –±—ã–ª —Å—Ç–æ–ª–±—Ü–æ–º]\n",
    "        seq_length = x.size(1) \n",
    "        for cur_idx in range(seq_length):\n",
    "            hidden = torch.tanh( # hidden –∑–∞–¥–∞–Ω —Ä–µ–∫–∫—É—Ä–µ–Ω—Ç–Ω–æ\n",
    "                x[:, cur_idx] @ self.w_x + self.b_x + hidden @ self.w_h + self.b_h # x[:,cur_idx] –±–µ—Ä—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–ª–æ–≤–∞ –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è -> (batch_size x embed_dim)\n",
    "            ) # x[:, cur_idx] @ self.w_x -- (batch_size x embed_size * embed_size x hidden_size -> batch_size x hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:21:37.541265Z",
     "start_time": "2021-10-09T11:21:37.534262Z"
    },
    "id": "9LJ3ZIuZzamP"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.rnn = RNN(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes) # (batch_size x hidden_size) -> (batch_size x num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x) # (batch_size,seq_len, embed_dim)\n",
    "        hidden = self.rnn(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:21:38.988346Z",
     "start_time": "2021-10-09T11:21:38.309349Z"
    },
    "id": "ftuDhqdtzaj-"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RNNModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:26:33.925267Z",
     "start_time": "2021-10-09T11:21:40.022189Z"
    },
    "id": "Yx62ofTU3CNY"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 1.4723517894744873, accuracy: 0.2510526180267334\n"
     ]
    }
   ],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJqh9eWIhxE0"
   },
   "source": [
    "## GRU\n",
    "\n",
    "–¢—Ä–µ—Ç—å—è –º–æ–¥–µ–ª—å: GRU. –û–Ω–∞ —É—Å–ª–æ–∂–Ω–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è `RNN`. –ì–ª–∞–Ω–∞—è –∏–¥–µ—è GRU: –≥–µ–π—Ç—ã. –¢–∞–∫ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è \"–ø–∞–º—è—Ç—å\" –º–æ–¥–µ–ª–∏ ‚Äì –æ–Ω–∞ –º–∞—Å–∫–∏—Ä—É–µ—Ç —á–∞—Å—Ç—å —Å—Ç–∞—Ä–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, —Å–æ–∑–¥–∞–≤–∞—è –Ω–∞ —ç—Ç–æ–º –º–µ—Å—Ç–µ –Ω–æ–≤–æ–µ. –ú–æ–¥–µ–ª—å GRU –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "            r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
    "            z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
    "            n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
    "            h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
    "        \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:31:24.738545Z",
     "start_time": "2021-10-09T11:31:24.718546Z"
    },
    "id": "Hi1yv2cy3CJB"
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "# –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è r\n",
    "        self.w_rh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_rh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_rx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_rx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "# –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è z\n",
    "        self.w_zh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_zh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_zx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_zx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "# –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è n\n",
    "        self.w_nh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_nh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_nx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_nx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden = None):\n",
    "        '''\n",
    "        x ‚Äì torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
    "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
    "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
    "        '''\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device) # (batch_size,hidden_size) [—Å—Ç—Ä–æ–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞]\n",
    "        \n",
    "        for cur_idx in range(x.size(1)):\n",
    "            r = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_rx + self.b_rx + hidden @ self.w_rh + self.b_rh\n",
    "            )\n",
    "            z = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_zx + self.b_zx + hidden @ self.w_zh + self.b_zh\n",
    "            )\n",
    "            n = torch.tanh(\n",
    "                x[:, cur_idx] @ self.w_nx + self.b_nx + r * (hidden @ self.w_nh + self.b_nh)\n",
    "            )\n",
    "            hidden = (1 - z) * n + z * hidden\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:31:25.162010Z",
     "start_time": "2021-10-09T11:31:25.146013Z"
    },
    "id": "bisyVic-3CDu"
   },
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.gru = GRU(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        hidden = self.gru(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:31:26.204312Z",
     "start_time": "2021-10-09T11:31:25.541308Z"
    },
    "id": "UASjrUtDzaf3"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T11:45:03.798869Z",
     "start_time": "2021-10-09T11:31:26.206308Z"
    },
    "id": "wlom9sHdzac6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.8999207019805908, accuracy: 0.6455262899398804\n"
     ]
    }
   ],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG4My7G5i5Vs"
   },
   "source": [
    "## GRU + Embeddings\n",
    "\n",
    "–ú—ã –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ –∑–∞–≥—Ä—É–∑–∏–ª–∏ —ç–º–±—ç–¥–∏–Ω–≥–∏ –≤ –Ω–∞—á–∞–ª–µ. –î–∞–≤–∞–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö –≤–º–µ—Å—Ç–æ —Å–ª—É—á–∞–π–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏! –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–¥–æ –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å —Å–ø–æ—Å–æ–± –ø–æ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –º–æ–¥–µ–ª—å –∏ –¥–æ–±–∞–≤–∏—Ç—å –≤ –º–æ–¥–µ–ª—å –º–æ–¥—É–ª—å `Embedding`. –ü–æ-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–µ–º –Ω–∞ –º–æ–¥–µ–ª–∏ `GRU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:14:49.317157Z",
     "start_time": "2021-10-09T12:14:48.642133Z"
    },
    "id": "SbYLzLdYLxjc"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:00:44.909247Z",
     "start_time": "2021-10-09T11:58:48.953411Z"
    },
    "id": "_-TxEwzMLsuz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\AppData\\Local\\Temp/ipykernel_7068/1175556816.py:4: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word)) # –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç–≤—É—é—â—É—é —Å—Ç—Ä–æ–∫—É (—Å–ª–æ–≤–æ) –ø–æ –∏–Ω–¥–µ–∫—Å—É —Å—Ç–∞–≤–∏–º –≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (—ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:14:26.787895Z",
     "start_time": "2021-10-09T12:00:44.912243Z"
    },
    "id": "Opw85y82Mhvf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.4243246912956238, accuracy: 0.8534210324287415\n"
     ]
    }
   ],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T91mZsx_b8z8"
   },
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–∏ –Ω–∞ –ø–µ—Ä–≤—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö –æ–±—É—á–µ–Ω–∏—è. –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç –Ω–µ —Å–∏–ª—å–Ω–æ –ø–æ—Ä—Ç–∏—Ç—å –Ω–∞—à–∏ —ç–º–±–µ–¥–∏–Ω–≥–∏ –Ω–∞ –ø–µ—Ä–≤—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:15:00.897423Z",
     "start_time": "2021-10-09T12:15:00.889426Z"
    },
    "id": "trrbDTJqMvLK"
   },
   "outputs": [],
   "source": [
    "def freeze_embeddings(model, req_grad=False):\n",
    "    embeddings = model.embed\n",
    "    for c_p in embeddings.parameters():\n",
    "        c_p.requires_grad = req_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:15:01.689262Z",
     "start_time": "2021-10-09T12:15:01.666268Z"
    },
    "id": "zcPZxlseJME5"
   },
   "outputs": [],
   "source": [
    "def training_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2, num_freeze_iter=1000):\n",
    "    freeze_embeddings(model)\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
    "        for batch in pbar:\n",
    "            if num_iter > num_freeze_iter and e < 1:\n",
    "                freeze_embeddings(model, True)\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:15:03.237363Z",
     "start_time": "2021-10-09T12:15:02.602359Z"
    },
    "id": "fYbcqM2iKERh"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:16:55.434228Z",
     "start_time": "2021-10-09T12:15:03.239358Z"
    },
    "id": "E3i8-_MhKHCo"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T12:29:47.466269Z",
     "start_time": "2021-10-09T12:16:55.437219Z"
    },
    "id": "jKIdxoobKLas"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 0.46335598826408386, accuracy: 0.8368420600891113\n"
     ]
    }
   ],
   "source": [
    "training_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω–æ —Å –∑–∞–º–æ—Ä–æ–∑–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ª—É—á—à–µ, –Ω–æ –Ω–µ –≤ —ç—Ç–æ—Ç —Ä–∞–∑ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JDRH3TkK6VS"
   },
   "source": [
    "–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∞—Ç—å –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞–∑–Ω—ã–µ –ø–æ —Å–º—ã—Å–ª—É —Å–ª–æ–≤–∞, –Ω–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è –≤–º–µ—Å—Ç–µ —á–∞—Å—Ç–æ, –∏–º–µ–ª–∏ —Å—Ö–æ–∂–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar_cnn and rnn",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
