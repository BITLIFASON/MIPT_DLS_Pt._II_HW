{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot3c4fjZwC4T"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2JdzEXmwRU5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMohh_6CwC4W"
   },
   "source": [
    "### Задача определения частей речи, Part-Of-Speech Tagger (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Aad2tmBwC4Y"
   },
   "source": [
    "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:29.926753Z",
     "start_time": "2021-10-20T11:42:27.671749Z"
    },
    "id": "gYYV0mdmwC4f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict, deque\n",
    "from nltk.corpus import brown\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPgI52lRwC4n"
   },
   "source": [
    "Вам в помощь http://www.nltk.org/book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxdJxMEAwC4o"
   },
   "source": [
    "Загрузим brown корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:30.329745Z",
     "start_time": "2021-10-20T11:42:29.928748Z"
    },
    "id": "ZvhXAL_9wC4q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASm3Dpggs25b"
   },
   "source": [
    "Существует множество наборов грамматических тегов, или тегсетов, например:\n",
    "* НКРЯ\n",
    "* Mystem\n",
    "* UPenn\n",
    "* OpenCorpora (его использует pymorphy2)\n",
    "* Universal Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wto8PSC6wC4v"
   },
   "source": [
    "<b>Существует не одна система тегирования, поэтому будьте внимательны, когда прогнозируете тег слов в тексте и вычисляете качество прогноза. Можете получить несправедливо низкое качество вашего решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ6tuHA_wC4z"
   },
   "source": [
    "На данный момент стандартом является **Universal Dependencies**. Подробнее про проект можно почитать [вот тут](http://universaldependencies.org/), а про теги — [вот тут](http://universaldependencies.org/u/pos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:30.359748Z",
     "start_time": "2021-10-20T11:42:30.331750Z"
    },
    "id": "Cht7dImWwC42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiTimRRywC47"
   },
   "source": [
    "<img src=\"https://4.bp.blogspot.com/-IcFli2wljs0/WrVCw3umY_I/AAAAAAAACYM/UJ_neoUAs3wF95dj2Ouf3BzxXzB_b2TbQCLcBGAs/s1600/postags.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyDBMcBSwC48"
   },
   "source": [
    "Мы имеем массив предложений пар (слово-тег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:30.471751Z",
     "start_time": "2021-10-20T11:42:30.362747Z"
    },
    "id": "BobflewQwC4-",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "brown_tagged_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSu1KqRrwC5L"
   },
   "source": [
    "Первое предложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:30.487747Z",
     "start_time": "2021-10-20T11:42:30.473747Z"
    },
    "id": "zCHCZPlkwC5N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIV2MiRxwC5Q"
   },
   "source": [
    "Все пары (слово-тег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:30.595746Z",
     "start_time": "2021-10-20T11:42:30.489749Z"
    },
    "id": "dVx9e9HcwC5R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_words = brown.tagged_words(tagset='universal')\n",
    "brown_tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-ADby6LwC5V"
   },
   "source": [
    "Проанализируйте данные, с которыми Вы работаете. Используйте `nltk.FreqDist()` для подсчета частоты встречаемости тега и слова в нашем корпусе. Под частой элемента подразумевается кол-во этого элемента в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:35.503751Z",
     "start_time": "2021-10-20T11:42:30.597747Z"
    },
    "id": "JzRoXuKFcMZK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Приведем слова к нижнему регистру\n",
    "brown_tagged_words = list(map(lambda x: (x[0].lower(), x[1]), brown_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:41.797751Z",
     "start_time": "2021-10-20T11:42:35.505748Z"
    },
    "id": "4giWaqXjwC5W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во предложений:  57340\n"
     ]
    }
   ],
   "source": [
    "print('Кол-во предложений: ', len(brown_tagged_sents))\n",
    "tags = [tag for (word, tag) in brown_tagged_words] # наши теги\n",
    "words = [word for (word, tag) in brown_tagged_words] # наши слова\n",
    "\n",
    "tag_num = pd.Series(nltk.FreqDist(tags)).sort_values(ascending=False) # тег - кол-во тега в корпусе\n",
    "word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False) # слово - кол-во слова в корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:41.813752Z",
     "start_time": "2021-10-20T11:42:41.799748Z"
    },
    "id": "yfiPpCcLwC5Z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN    275558\n",
       "VERB    182750\n",
       ".       147565\n",
       "ADP     144766\n",
       "DET     137019\n",
       "ADJ      83721\n",
       "ADV      56239\n",
       "PRON     49334\n",
       "CONJ     38151\n",
       "PRT      29829\n",
       "NUM      14874\n",
       "X         1386\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:42.095746Z",
     "start_time": "2021-10-20T11:42:41.817747Z"
    },
    "id": "8Y1huw7TwC5b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(tag_num.index, tag_num.values)\n",
    "plt.title(\"Tag_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:42.111745Z",
     "start_time": "2021-10-20T11:42:42.097748Z"
    },
    "id": "gBbhnJsmwC5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    69971\n",
       ",      58334\n",
       ".      49346\n",
       "of     36412\n",
       "and    28853\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:42.365746Z",
     "start_time": "2021-10-20T11:42:42.113751Z"
    },
    "id": "1WmEOBMkwC5i"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(word_num.index[:10], word_num.values[:10])\n",
    "plt.title(\"Word_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n08z2PjMwC5o"
   },
   "source": [
    "### Вопрос 1:\n",
    "* Кол-во слова `cat` в корпусе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:42.397748Z",
     "start_time": "2021-10-20T11:42:42.367748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num['cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhB7di3YwC5p"
   },
   "source": [
    "> Ответ: 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsCfVLsewC5s"
   },
   "source": [
    "### Вопрос 2:\n",
    "* Самое популярное слово с самым популярным тегом? <br>(*сначала выбираете слова с самым популярным тегом, а затем выбираете самое популярное слово из уже выбранных*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:42.539747Z",
     "start_time": "2021-10-20T11:42:42.399746Z"
    }
   },
   "outputs": [],
   "source": [
    "word_pop_tag = [word for (word,tag) in brown_tagged_words if tag == 'NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:42.617752Z",
     "start_time": "2021-10-20T11:42:42.541747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n"
     ]
    }
   ],
   "source": [
    "for word in word_num.index:\n",
    "    if word in word_pop_tag:\n",
    "        print(word)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:43.884746Z",
     "start_time": "2021-10-20T11:42:42.619748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "a\n",
      "in\n",
      "for\n",
      "i\n",
      "one\n",
      "will\n",
      "more\n",
      ":\n",
      "can\n",
      "time\n",
      "may\n",
      "do\n",
      "my\n",
      "man\n",
      "must\n",
      "af\n",
      "back\n",
      "years\n",
      "way\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for word in word_num.index:\n",
    "    if word in word_pop_tag:\n",
    "        print(word)\n",
    "        k +=1\n",
    "    if k == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oio-XBYkwC5t"
   },
   "source": [
    "При ручном анализе результатом является time, хотя при использовании простого цикла результатом является to, которая на самом деле является частицей\n",
    "\n",
    "> Ответ: time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-OGc1rSwC5x"
   },
   "source": [
    "Впоследствии обучение моделей может занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb7MhxVRwC5y"
   },
   "source": [
    "Категории нашего корпуса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:43.915750Z",
     "start_time": "2021-10-20T11:42:43.886747Z"
    },
    "id": "GSiVcP1TwC51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjSlFatJwC53"
   },
   "source": [
    "Будем работать с категорией humor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f1rl5x0wC55"
   },
   "source": [
    "Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:44.040752Z",
     "start_time": "2021-10-20T11:42:43.917747Z"
    },
    "id": "GX9t-1qowC58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\AppData\\Local\\Temp/ipykernel_16836/647096870.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  my_brown_tagged_sents = np.array(my_brown_tagged_sents)\n"
     ]
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\", categories='humor')\n",
    "# Приведем слова к нижнему регистру\n",
    "my_brown_tagged_sents = []\n",
    "for sent in brown_tagged_sents:\n",
    "    my_brown_tagged_sents.append(list(map(lambda x: (x[0].lower(), x[1]), sent)))\n",
    "my_brown_tagged_sents = np.array(my_brown_tagged_sents)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sents, test_sents = train_test_split(my_brown_tagged_sents, random_state=0,train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:44.056752Z",
     "start_time": "2021-10-20T11:42:44.042747Z"
    },
    "id": "pXkVwUjYwC5-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:44.071748Z",
     "start_time": "2021-10-20T11:42:44.058746Z"
    },
    "id": "JQMjzJ2YwC6C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rEasLVcwC6G"
   },
   "source": [
    "### Метод максимального правдоподобия для обучения модели\n",
    "\n",
    "* $\\normalsize S = s_0, s_1, ..., s_N$ - скрытые состояния, то есть различные теги\n",
    "* $\\normalsize O = o_0, o_1, ..., o_M$ - различные слова\n",
    "* $\\normalsize a_{i,j} = p(s_j|s_i)$ - вероятность того, что, находясь в скрытом состоянии $s_i$, мы попадем в состояние $s_j$ (элемент матрицы $A$)\n",
    "* $\\normalsize b_{k,j}=p(o_k|s_j)$ - вероятность того, что при скрытом состоянии $s_j$ находится слово $o_k$(элемент матрицы $B$)\n",
    "\n",
    "$$\\normalsize x_t \\in O, y_t \\in S$$\n",
    "$\\normalsize (x_t, y_t)$ - слово и тег, стоящие на месте $t$ $\\Rightarrow$ \n",
    "* $\\normalsize X$ - последовательность слов\n",
    "* $\\normalsize Y$ - последовательность тегов\n",
    "\n",
    "Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
    "\n",
    "- Вероятности переходов между скрытыми состояниями $p(y_t | y_{t - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
    "\n",
    "\n",
    "- Вероятности эмиссий наблюдаемых состояний $p(x_t | y_t)$ посчитайте на основе частот \"POS-тег - слово\".\n",
    "\n",
    "\n",
    "- Распределение вероятностей начальных состояний $p(y_0)$ задайте равномерным.\n",
    "\n",
    "Пример $X = [x_0, x_1], Y = [y_0, y_1]$:<br><br>\n",
    "$$p(X, Y) = p(x_0, x_1, y_0, y_1) = p(y_0) \\cdot p(x_0, x_1, y_1 | y_0) = p(y_0) \\cdot p(x_0 | y_0) \\cdot\n",
    "p(x_1, y_1 | x_0, y_0) = \\\\ = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | x_0, y_0) \\cdot p(x_1 | x_0, y_0, y_1)\n",
    "= (\\text{в силу условий нашей модели}) = \\\\ = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | y_0) \\cdot p(x_1 | y_1) \\Rightarrow$$ <br>\n",
    "Для последовательности длины $n + 1$:<br>\n",
    "$$p(X, Y) = p(x_0 ... x_{n - 1}, y_0 ... y_{n - 1}) \\cdot p(y_n | y_{n - 1}) \\cdot p(x_n | y_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tysPoe5rwC6I"
   },
   "source": [
    "#### Алгоритм Витерби для применения модели\n",
    "\n",
    "\n",
    "Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
    "\n",
    "$$ \\hat{Y} = \\arg \\max_{Y} p(Y|X) = \\arg \\max_{Y} p(Y, X) $$\n",
    "\n",
    "Пусть $\\normalsize Q_{t,s}$ - самая вероятная последовательность скрытых состояний длины $t$ с окончанием в состоянии $s$. $\\normalsize q_{t, s}$ - вероятность этой последовательности.\n",
    "$$(1)\\: \\normalsize q_{t,s} = \\max_{s'} q_{t - 1, s'} \\cdot p(s | s') \\cdot p(o_t | s)$$\n",
    "$\\normalsize Q_{t,s}$ можно восстановить по argmax-ам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:44.102747Z",
     "start_time": "2021-10-20T11:42:44.073746Z"
    },
    "id": "QpEXdhOfwC6J"
   },
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:    \n",
    "    def __init__(self):\n",
    "    \n",
    "        pass\n",
    "        \n",
    "    def fit(self, train_tokens_tags_list):\n",
    "        \"\"\"\n",
    "        train_tokens_tags_list: массив предложений пар слово-тег (выборка для train) \n",
    "        \"\"\"\n",
    "        tags = [tag for sent in train_tokens_tags_list\n",
    "                for (word, tag) in sent]\n",
    "        words = [word for sent in train_tokens_tags_list\n",
    "                 for (word, tag) in sent]\n",
    "        tag_num = pd.Series(nltk.FreqDist(tags)).sort_index() # '''your code'''\n",
    "        word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False) # '''your code'''\n",
    "         \n",
    "        self.tags = tag_num.index\n",
    "        self.words = word_num.index\n",
    "        \n",
    "        A = pd.DataFrame({'{}'.format(tag) : [0] * len(tag_num) for tag in tag_num.index}, index=tag_num.index)\n",
    "        B = pd.DataFrame({'{}'.format(tag) : [0] * len(word_num) for tag in tag_num.index}, index=word_num.index)\n",
    "        \n",
    "        # Вычисляем матрицу A и B по частотам слов и тегов\n",
    "        \n",
    "        # sent - предложение\n",
    "        # sent[i][0] - i слово в этом предложении, sent[i][1] - i тег в этом предложении\n",
    "        for sent in train_tokens_tags_list:\n",
    "            for i in range(len(sent)):\n",
    "                B.loc[sent[i][0],sent[i][1]] += 1 # текущая i-пара слово-тег (обновите матрицу B аналогично A)\n",
    "                if len(sent) - 1 != i: # для последнего тега нет следующего тега\n",
    "                    A.loc[sent[i][1], sent[i + 1][1]] += 1 # пара тег-тег\n",
    "                \n",
    "        \n",
    "        # переходим к вероятностям\n",
    "        \n",
    "        # нормируем по строке, то есть по всем всевозможным следующим тегам\n",
    "        A = A.divide(A.sum(axis=1), axis=0)\n",
    "        \n",
    "        # нормируем по столбцу, то есть по всем всевозможным текущим словам\n",
    "        B = B / np.sum(B, axis=0)\n",
    "        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def predict(self, test_tokens_list):\n",
    "        \"\"\"\n",
    "        test_tokens_list : массив предложений пар слово-тег (выборка для test)\n",
    "        \"\"\"\n",
    "        predict_tags = OrderedDict({i : np.array([]) for i in range(len(test_tokens_list))})\n",
    "        \n",
    "        for i_sent in range(len(test_tokens_list)):\n",
    "            \n",
    "            current_sent = test_tokens_list[i_sent] # текущее предложение\n",
    "            len_sent = len(current_sent) # длина предложения \n",
    "            \n",
    "            q = np.zeros(shape=(len_sent + 1, len(self.tags)))\n",
    "            q[0] = 1 # нулевое состояние (равномерная инициализация по всем s)\n",
    "            back_point = np.zeros(shape=(len_sent + 1, len(self.tags))) # # argmax\n",
    "            \n",
    "            for t in range(len_sent):\n",
    "                \n",
    "                # если мы не встречали такое слово в обучении, то вместо него будет \n",
    "                # самое популярное слово с самым популярным тегом (вопрос 2)\n",
    "                if current_sent[t] not in self.words:\n",
    "                    current_sent[t] = 'time' # '''your code'''\n",
    "                    \n",
    "                # через max выбираем следующий тег\n",
    "                for i_s in range(len(self.tags)):\n",
    "                    \n",
    "                    s = self.tags[i_s]\n",
    "                    \n",
    "                    # формула (1)\n",
    "                    q[t + 1][i_s] = np.max(q[t] * # '''your code'''\n",
    "                        self.A.loc[:,s] *  # '''your code'''\n",
    "                        self.B.loc[current_sent[t], s])\n",
    "                    \n",
    "                    # argmax формула(1)\n",
    "                    \n",
    "                    # argmax, чтобы восстановить последовательность тегов\n",
    "                    back_point[t + 1][i_s] = (q[t] * self.A.loc[:,s] * \n",
    "                        self.B.loc[current_sent[t],s]).reset_index()[s].idxmax() # индекс \n",
    "                    \n",
    "            back_point = back_point.astype('int')\n",
    "            \n",
    "            # выписываем теги, меняя порядок на реальный\n",
    "            back_tag = deque()\n",
    "            current_tag = np.argmax(q[len_sent])\n",
    "            for t in range(len_sent, 0, -1):\n",
    "                back_tag.appendleft(self.tags[current_tag])\n",
    "                current_tag = back_point[t, current_tag]\n",
    "             \n",
    "            predict_tags[i_sent] = np.array(back_tag)\n",
    "        \n",
    "        \n",
    "        return predict_tags                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0BLgsWkwC6M"
   },
   "source": [
    "Обучите скрытую марковскую модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:44.117748Z",
     "start_time": "2021-10-20T11:42:44.104748Z"
    },
    "id": "ZcSoyUAxwC6M"
   },
   "outputs": [],
   "source": [
    "my_model = HiddenMarkovModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:51.301791Z",
     "start_time": "2021-10-20T11:42:44.119747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.HiddenMarkovModel at 0x2c1d0d9b2e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(train_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeVNt19kwC6P"
   },
   "source": [
    "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
    "\n",
    "- 'He can stay'\n",
    "- 'a cat and a dog'\n",
    "- 'I have a television'\n",
    "- 'My favourite character'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:51.676769Z",
     "start_time": "2021-10-20T11:42:51.303770Z"
    },
    "id": "cMJErf7NwC6Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, array(['NOUN', 'VERB', 'VERB'], dtype='<U4')),\n",
       "             (1, array(['DET', 'NOUN', 'CONJ', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (2, array(['NOUN', 'VERB', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (3, array(['NOUN', 'NOUN', 'NOUN'], dtype='<U4'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [['He', 'can', 'stay'], ['a', 'cat', 'and', 'a', 'dog'], ['I', 'have', 'a', 'television'],\n",
    "         ['My', 'favourite', 'character']]\n",
    "my_model.predict(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suDCwbGMwC6T"
   },
   "source": [
    "### Вопрос 3:\n",
    "* Какой тег вы получили для слова `can`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReHeG3IjwC6U"
   },
   "source": [
    "> Ответ: VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObAslurlwC6X"
   },
   "source": [
    "### Вопрос 4:\n",
    "* Какой тег вы получили для слова `favourite`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T16:52:24.570047Z",
     "start_time": "2021-10-19T16:52:24.548049Z"
    },
    "id": "94crVrrXwC6Y"
   },
   "source": [
    "> Ответ: NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPC4NZ4HwC6a"
   },
   "source": [
    "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:51.692768Z",
     "start_time": "2021-10-20T11:42:51.678768Z"
    },
    "id": "-7aioBc1wC6b"
   },
   "outputs": [],
   "source": [
    "def accuracy_score(model, sents):\n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "\n",
    "    sent_tags = []\n",
    "    sent_words = []\n",
    "    \n",
    "    for sent in sents:\n",
    "        tags = [tag for (word,tag) in sent]\n",
    "        words = [word for (word,tag) in sent]\n",
    "        sent_tags.append(tags)\n",
    "        sent_words.append(words)\n",
    "        \n",
    "        #'''your code'''\n",
    "        predict = model.predict(sent_words)\n",
    "        #print(1)\n",
    "        print(1,predict)\n",
    "        #return predict\n",
    "        predict = [(i, s) for i, s in predict.items()]\n",
    "        #print(2,predict)\n",
    "        for (i,s) in predict:\n",
    "            #print(1)\n",
    "            for num in range(len(s)):\n",
    "                if sent_tags[i][num] == s[num]:\n",
    "                    true_pred += 1\n",
    "                num_pred += 1\n",
    "    #return predict\n",
    "    print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:55.449791Z",
     "start_time": "2021-10-20T11:42:51.694769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 OrderedDict([(0, array(['.', 'VERB', 'VERB', 'ADJ', 'ADP', 'NOUN', 'CONJ', 'VERB', 'ADV',\n",
      "       'PRT', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN',\n",
      "       'ADP', 'NOUN', '.', '.', 'NUM', 'ADP', 'PRON', 'VERB', '.'],\n",
      "      dtype='<U4'))])\n",
      "1 OrderedDict([(0, array(['.', 'VERB', 'VERB', 'ADJ', 'ADP', 'NOUN', 'CONJ', 'VERB', 'ADV',\n",
      "       'PRT', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN',\n",
      "       'ADP', 'NOUN', '.', '.', 'NUM', 'ADP', 'PRON', 'VERB', '.'],\n",
      "      dtype='<U4')), (1, array(['.', 'ADV', 'PRON', 'VERB', '.', '.', 'VERB', 'NOUN', 'ADV', '.',\n",
      "       'ADP', 'ADP', 'PRON', 'VERB', 'NOUN', 'DET', 'NOUN', 'NOUN',\n",
      "       'NOUN', 'ADP', 'DET', 'NOUN', 'ADV', 'ADJ', 'NOUN', '.'],\n",
      "      dtype='<U4'))])\n",
      "1 OrderedDict([(0, array(['.', 'VERB', 'VERB', 'ADJ', 'ADP', 'NOUN', 'CONJ', 'VERB', 'ADV',\n",
      "       'PRT', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN',\n",
      "       'ADP', 'NOUN', '.', '.', 'NUM', 'ADP', 'PRON', 'VERB', '.'],\n",
      "      dtype='<U4')), (1, array(['.', 'ADV', 'PRON', 'VERB', '.', '.', 'VERB', 'NOUN', 'ADV', '.',\n",
      "       'ADP', 'ADP', 'PRON', 'VERB', 'NOUN', 'DET', 'NOUN', 'NOUN',\n",
      "       'NOUN', 'ADP', 'DET', 'NOUN', 'ADV', 'ADJ', 'NOUN', '.'],\n",
      "      dtype='<U4')), (2, array(['ADP', 'PRON', 'VERB', 'PRT', 'ADP', 'DET', 'NOUN', '.', 'PRON',\n",
      "       'VERB', 'ADV', 'DET', 'NOUN', '.', 'VERB', 'NOUN', '.', 'ADV',\n",
      "       'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'NOUN', 'CONJ', 'DET',\n",
      "       'NOUN', 'ADP', 'ADJ', 'NOUN', '.'], dtype='<U4'))])\n",
      "Accuracy: 87.87878787878788 %\n"
     ]
    }
   ],
   "source": [
    "test123 = accuracy_score(my_model, test_sents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:55.465767Z",
     "start_time": "2021-10-20T11:42:55.451768Z"
    },
    "id": "roesKrPCcMbp"
   },
   "outputs": [],
   "source": [
    "#accuracy_score(my_model, test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff_W7J8XwC6e"
   },
   "source": [
    "### Вопрос 5:\n",
    "* Какое качество вы получили(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptvlpc-6wC6f"
   },
   "source": [
    "> Ответ: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpAgfZRTwC6h"
   },
   "source": [
    "## DefaultTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b4cPKyiwC6j"
   },
   "source": [
    "### Вопрос 6:\n",
    "* Какое качество вы бы получили, если бы предсказывали любой тег, как самый популярный тег на выборке train(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td-0Pe0vwC6k"
   },
   "source": [
    "Вы можете испоьзовать DefaultTagger(метод tag для предсказания частей речи предложения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:55.481767Z",
     "start_time": "2021-10-20T11:42:55.470768Z"
    },
    "id": "NfZYlMxJwC6m"
   },
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:55.497767Z",
     "start_time": "2021-10-20T11:42:55.483769Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_score2(tagger, sents):\n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "\n",
    "    sent_tags = []\n",
    "    sent_words = []\n",
    "    \n",
    "    for sent in sents:\n",
    "        sent_tags = [tag for (word,tag) in sent]\n",
    "        sent_words = [word for (word,tag) in sent]\n",
    "        #print(0,sent_words[:100])\n",
    "        #sent_tags.append(tags)\n",
    "        #sent_words.append(words)\n",
    "        #print(1,sent_tags)\n",
    "        #print(2,sent_words)\n",
    "        predict = tagger.tag(sent_words)\n",
    "        #return predict\n",
    "        #print(3,predict)\n",
    "        predict = [tag for (word,tag) in predict]\n",
    "        #print(4,predict)\n",
    "        #predict = [(i, s) for i, s in predict]\n",
    "        for tag in sent_tags:\n",
    "            for pred in predict:\n",
    "                if tag == pred:\n",
    "                    true_pred += 1\n",
    "                num_pred += 1\n",
    "\n",
    "    print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:55.513769Z",
     "start_time": "2021-10-20T11:42:55.499768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.717686759497894 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_score2(default_tagger,test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ответ: 21.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lz7Q3BfbwC6o"
   },
   "source": [
    "## NLTK, Rnnmorph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZvdB22Oyycz"
   },
   "source": [
    "Вспомним первый [семинар](https://colab.research.google.com/drive/1FHZVU6yJT61J8w1hALno0stD4VU36rit?usp=sharing) нашего курса. В том семинаре мы с вами работали c некоторыми библиотеками.\n",
    "\n",
    "Не забудьте преобразовать систему тэгов из `'en-ptb' в 'universal'` с помощью функции `map_tag` или используйте `tagset='universal'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:55.529768Z",
     "start_time": "2021-10-20T11:42:55.515770Z"
    },
    "id": "9bn1TGlGAfuL"
   },
   "outputs": [],
   "source": [
    "from nltk.tag.mapping import map_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:56.393768Z",
     "start_time": "2021-10-20T11:42:55.531772Z"
    },
    "id": "JJQFfbp8A_cj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'isdigit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/2937092188.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'averaged_perceptron_tagger'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'universal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#nltk.map_tag('universal')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \"\"\"\n\u001b[0;32m    160\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    116\u001b[0m         )\n\u001b[0;32m    117\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Maps to the specified tagset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, tokens, return_conf, use_tagdict)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             tag, conf = (\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             tag, conf = (\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"-\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"!HYPHEN\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"!YEAR\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'isdigit'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.pos_tag(tokens=train_sents, tagset='universal')\n",
    "#nltk.map_tag('universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:12:08.355022Z",
     "start_time": "2021-10-20T12:12:01.689950Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:14:17.908412Z",
     "start_time": "2021-10-20T12:14:17.895412Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:14:56.483446Z",
     "start_time": "2021-10-20T12:14:56.454440Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Adam' from 'keras.optimizers' (C:\\Users\\BIT\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6192/2577481425.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Adam' from 'keras.optimizers' (C:\\Users\\BIT\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers.py)"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:17:53.935204Z",
     "start_time": "2021-10-20T12:17:53.459231Z"
    },
    "id": "8LD_61W7N35q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\BIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Method `model_from_yaml()` has been removed due to security risk of arbitrary code execution. Please use `Model.to_json()` and `model_from_json()` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6192/3855790570.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrnnmorph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRNNMorphPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNNMorphPredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\rnnmorph\\predictor.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, language, eval_model_config_path, eval_model_weights_path, gram_dict_input, gram_dict_output, word_vocabulary, char_set_path, build_config)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMMorphoAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram_dict_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgram_dict_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_vocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_set_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_model_config_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_model_weights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_all_forms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWordFormOut\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\rnnmorph\\model.py\u001b[0m in \u001b[0;36mload_eval\u001b[1;34m(self, config, eval_model_config_path, eval_model_weights_path)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[0mcustom_objects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'ReversedLSTM'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mReversedLSTM\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_yaml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_model_weights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_yaml\u001b[1;34m(yaml_string, custom_objects)\u001b[0m\n\u001b[0;32m     72\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mannounces\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mposes\u001b[0m \u001b[0ma\u001b[0m \u001b[0msecurity\u001b[0m \u001b[0mrisk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \"\"\"\n\u001b[1;32m---> 74\u001b[1;33m   raise RuntimeError(\n\u001b[0m\u001b[0;32m     75\u001b[0m       \u001b[1;34m'Method `model_from_yaml()` has been removed due to security risk of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[1;34m'arbitrary code execution. Please use `Model.to_json()` and '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Method `model_from_yaml()` has been removed due to security risk of arbitrary code execution. Please use `Model.to_json()` and `model_from_json()` instead."
     ]
    }
   ],
   "source": [
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "predictor = RNNMorphPredictor(language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:42:56.398769Z",
     "start_time": "2021-10-20T11:42:56.398769Z"
    }
   },
   "outputs": [],
   "source": [
    "rnnmorph_result = predictor.predict_sentences(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
    "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score3(predictor, sents):\n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "\n",
    "    sent_tags = []\n",
    "    sent_words = []\n",
    "    \n",
    "    for sent in sents:\n",
    "        sent_tags = [tag for (word,tag) in sent]\n",
    "        sent_words = [word for (word,tag) in sent]\n",
    "        #print(0,sent_words[:100])\n",
    "        #sent_tags.append(tags)\n",
    "        #sent_words.append(words)\n",
    "        #print(1,sent_tags)\n",
    "        #print(2,sent_words)\n",
    "        predict = tagger.tag(sent_words)\n",
    "        #return predict\n",
    "        #print(3,predict)\n",
    "        predict = [tag for (word,tag) in predict]\n",
    "        #print(4,predict)\n",
    "        #predict = [(i, s) for i, s in predict]\n",
    "        for tag in sent_tags:\n",
    "            for pred in predict:\n",
    "                if tag == pred:\n",
    "                    true_pred += 1\n",
    "                num_pred += 1\n",
    "\n",
    "    print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1z8x4vvwC6s"
   },
   "source": [
    "### Вопрос 7:\n",
    "* Какое качество вы получили, используя каждую из двух библиотек? Сравните их результаты.\n",
    "\n",
    "* Качество с библиотекой rnnmorph должно быть хуже, так как там используется немного другая система тэгов. Какие здесь отличия?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBd3RgqVwC6s"
   },
   "outputs": [],
   "source": [
    "'''your code'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w1W5hSkcMcV"
   },
   "source": [
    "## BiLSTMTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm1-S3t2cMcW"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GayTl7mUcMcX"
   },
   "source": [
    "Изменим структуру данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:48.722726Z",
     "start_time": "2021-10-20T09:43:48.624728Z"
    },
    "id": "CnXcI64fxoj4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'was', 'among', 'these', 'that', 'Hinkle', 'identified', 'a', 'photograph', 'of', 'Barco', '!', '!'), ('PRON', 'VERB', 'ADP', 'DET', 'ADP', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_data = [list(zip(*sent)) for sent in brown_tagged_sents]\n",
    "print(pos_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpRE3c-3cMcc"
   },
   "source": [
    "До этого мы писали много кода сами, теперь пора эксплуатировать pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:48.988725Z",
     "start_time": "2021-10-20T09:43:48.959724Z"
    },
    "id": "gvFlzrYnxokE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\.conda\\envs\\deep\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\BIT\\.conda\\envs\\deep\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "import torchtext\n",
    "\n",
    "# наши поля\n",
    "WORD = Field(lower=True)\n",
    "TAG = Field(unk_token=None) # все токены нам извсетны\n",
    "\n",
    "# создаем примеры\n",
    "examples = []\n",
    "for words, tags in pos_data:\n",
    "    examples.append(torchtext.data.Example.fromlist([list(words), list(tags)], fields=[('words', WORD), ('tags', TAG)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjl6u6cpOc1u"
   },
   "source": [
    "Вот один наш пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:49.351327Z",
     "start_time": "2021-10-20T09:43:49.342328Z"
    },
    "id": "dnrzktytN9rL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['it', 'was', 'among', 'these', 'that', 'hinkle', 'identified', 'a', 'photograph', 'of', 'barco', '!', '!'], 'tags': ['PRON', 'VERB', 'ADP', 'DET', 'ADP', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUhTrWCWcMcj"
   },
   "source": [
    "Теперь формируем наш датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:49.913193Z",
     "start_time": "2021-10-20T09:43:49.902189Z"
    },
    "id": "LGKkbZUIxokO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 842\n",
      "Number of validation examples: 106\n",
      "Number of testing examples: 105\n"
     ]
    }
   ],
   "source": [
    "# кладем примеры в наш датасет\n",
    "dataset = torchtext.data.Dataset(examples, fields=[('words', WORD), ('tags', TAG)])\n",
    "\n",
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T89unpppcMcp"
   },
   "source": [
    "Построим словари. Параметр `min_freq` выберете сами. При построении словаря испольузем только **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:50.304937Z",
     "start_time": "2021-10-20T09:43:50.284941Z"
    },
    "id": "tZwkwhlrxoka",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 4068\n",
      "Unique tokens in target (en) vocabulary: 13\n",
      "['<unk>', 'before', 'count', 'misplaced', 'chicken', 'laid', 'slacks', 'amazingly', 'booze', 'community', 'diego', 'explanatory', 'grandeur', 'insults', 'manny', 'obsessed', 'president', 'rid', 'soloist', 'timed', 'whereupon']\n",
      "['<pad>', 'NOUN', 'VERB', '.', 'DET', 'ADP', 'ADJ', 'PRON', 'ADV', 'CONJ', 'PRT', 'NUM', 'X']\n"
     ]
    }
   ],
   "source": [
    "WORD.build_vocab(train_data, min_freq=0.5)\n",
    "TAG.build_vocab(train_data)\n",
    "\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(WORD.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TAG.vocab)}\")\n",
    "\n",
    "print(WORD.vocab.itos[::200])\n",
    "print(TAG.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:50.490997Z",
     "start_time": "2021-10-20T09:43:50.480996Z"
    },
    "id": "vjn07NP-xokl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['there', \"wasn't\", 'any', 'such', 'thing', 'any', 'more', '.'], 'tags': ['PRT', 'VERB', 'DET', 'ADJ', 'NOUN', 'DET', 'ADV', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxgkU4cZcMcz"
   },
   "source": [
    "Посмотрим с насколько большими предложениями мы имеем дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:51.103262Z",
     "start_time": "2021-10-20T09:43:50.860259Z"
    },
    "id": "dVpMi1_0xoku",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = map(len, [vars(x)['words'] for x in train_data.examples])\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.title(\"Length distribution in Train data\")\n",
    "plt.hist(list(length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi28N2RBcMc5"
   },
   "source": [
    "Для обучения `BiLSTM` лучше использовать colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:51.290563Z",
     "start_time": "2021-10-20T09:43:51.274563Z"
    },
    "id": "LAGSrqWsxok2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DSWm0UjcMc-"
   },
   "source": [
    "Для более быстрого и устойчивого обучения сгруппируем наши данные по батчам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:51.851897Z",
     "start_time": "2021-10-20T09:43:51.838900Z"
    },
    "id": "dmwAyhNgxok_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\.conda\\envs\\deep\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# бьем нашу выборку на батч, не забывая сначала отсортировать выборку по длине\n",
    "def _len_sort_key(x):\n",
    "    return len(x.words)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:43:52.088514Z",
     "start_time": "2021-10-20T09:43:52.073516Z"
    },
    "id": "6aTjW00nxolI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 4, 4]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посморим  на количество батчей\n",
    "list(map(len, [train_iterator, valid_iterator, test_iterator]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyLQsizhcMdI"
   },
   "source": [
    "### Модель и её обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i9oHzcrcMdJ"
   },
   "source": [
    "Инициализируем нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T10:44:34.014992Z",
     "start_time": "2021-10-20T10:44:33.948998Z"
    },
    "id": "Ff7BLWs_xolS",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/500112019.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mBIDIRECTIONAL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEMB_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mHID_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOUTPUT_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDROPOUT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBIDIRECTIONAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# инициализируем веса\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, dropout, bidirectional=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(input_dim,emb_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=emb_dim,hidden_size=hid_dim,bidirectional=bidirectional)\n",
    "        # если bidirectional, то предсказываем на основе конкатенации двух hidden\n",
    "        self.tag = nn.Linear((1 + bidirectional) * hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, sent):\n",
    "        \n",
    "        #sent = [sent len, batch size] \n",
    "        \n",
    "        # не забываем применить dropout к embedding\n",
    "        embedded = self.dropout(self.embeddings(sent))\n",
    "\n",
    "        output, _ = self.rnn(embedded)\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "\n",
    "        prediction = self.tag(output)\n",
    "    \n",
    "        return prediction\n",
    "        \n",
    "# параметры модели\n",
    "INPUT_DIM = len(WORD.vocab)\n",
    "OUTPUT_DIM = len(TAG.vocab)\n",
    "EMB_DIM = 100\n",
    "HID_DIM = 10\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "model = LSTMTagger(INPUT_DIM,EMB_DIM,HID_DIM,OUTPUT_DIM,DROPOUT,BIDIRECTIONAL).to(device)\n",
    "\n",
    "# инициализируем веса\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJLqq8IHcMdQ"
   },
   "source": [
    "Подсчитаем количество обучаемых параметров нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:33:28.845575Z",
     "start_time": "2021-10-20T09:33:28.838577Z"
    },
    "id": "_Auu53Kdxolm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 404,223 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters()  if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSBfvf9HcMd9"
   },
   "source": [
    "Погнали обучать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:27:44.563668Z",
     "start_time": "2021-10-20T09:27:44.535658Z"
    },
    "id": "AjD1Y7Rmxolu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PAD_IDX = TAG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        #'''your code'''\n",
    "        words = batch.words\n",
    "        tags = batch.tags\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(words)\n",
    "        #tags = [sent len, batch size]\n",
    "        #output = [sent len, batch size, output dim]\n",
    "        print('0out',output.shape)\n",
    "        output = torch.squeeze(output,1)\n",
    "        tags = tags.view(-1)\n",
    "        print('1out',output.shape)\n",
    "        print('1tag',tags.shape)\n",
    "        #tags = [sent len * batch size]\n",
    "        #output = [sent len * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output,tags)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping(решение проблемы взрыва граденты), clip - максимальная норма вектора\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            \n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            words = batch.words\n",
    "            tags = batch.tags\n",
    "\n",
    "            output = model(words)\n",
    "            #tags = [sent len, batch size]\n",
    "            #output = [sent len, batch size, output dim]\n",
    "\n",
    "            output = torch.squeeze(output,1)\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            #tags = [sent len * batch size]\n",
    "            #output = [sent len * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output,tags)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T09:28:20.527718Z",
     "start_time": "2021-10-20T09:28:20.446720Z"
    },
    "id": "TJdXIyTHxol2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\.conda\\envs\\deep\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'LSTM' object has no attribute 'embedded'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/4081651411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/149674719.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip, train_history, valid_history)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#tags = [sent len, batch size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/2930072307.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sent)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m#output = [sent len, batch size, hid dim * n directions]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'LSTM' object has no attribute 'embedded'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 2\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-val-model.pt')\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T10:10:35.257279Z",
     "start_time": "2021-10-20T10:10:35.228273Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BucketIterator' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/89687471.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'BucketIterator' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(train_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fr860UPacMeI"
   },
   "source": [
    "### Применение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sDAfAq9xol9"
   },
   "outputs": [],
   "source": [
    "def accuracy_model(model, iterator):\n",
    "    model.eval()\n",
    "    \n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "           '''your code'''\n",
    "\n",
    "            output = model('''your code''')\n",
    "            \n",
    "            #output = [sent len, batch size, output dim]\n",
    "            output = '''your code'''\n",
    "            \n",
    "            #output = [sent len, batch size]\n",
    "            predict_tags = output.cpu().numpy()\n",
    "            true_tags = tags.cpu().numpy()\n",
    "\n",
    "            true_pred += np.sum((true_tags == predict_tags) & (true_tags != PAD_IDX))\n",
    "            num_pred += np.prod(true_tags.shape) - (true_tags == PAD_IDX).sum()\n",
    "        \n",
    "    return round(true_pred / num_pred * 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2n0H85mxomE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_model(model, test_iterator), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FacTKSPJcMeP"
   },
   "source": [
    "Вы можете улучшить качество, изменяя параметры модели. Но чтобы добиться нужного качества, вам неообходимо взять все выборку, а не только категорию `humor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXqXg0gbcMeR"
   },
   "outputs": [],
   "source": [
    "#brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnpi2R6rcMeU"
   },
   "source": [
    "Вам неоходимо добиться качества не меньше, чем `accuracy = 93 %` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqD1lZuwxomK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = LSTMTagger(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, DROPOUT, BIDIRECTIONAL).to(device)\n",
    "best_model.load_state_dict(torch.load('best-val-model.pt'))\n",
    "assert accuracy_model(best_model, test_iterator) >= 93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVfdJM-lcMeZ"
   },
   "source": [
    "Пример решение нашей задачи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3GUbwldxomW"
   },
   "outputs": [],
   "source": [
    "def print_tags(model, data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        words, _ = data\n",
    "        example = torch.LongTensor([WORD.vocab.stoi[elem] for elem in words]).unsqueeze(1).to(device)\n",
    "        \n",
    "        output = model(example).argmax(dim=-1).cpu().numpy()\n",
    "        tags = [TAG.vocab.itos[int(elem)] for elem in output]\n",
    "\n",
    "        for token, tag in zip(words, tags):\n",
    "            print(f'{token:15s}{tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mQoHc_EcMed",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_tags(model, pos_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "zMIJDOBmwC6v"
   },
   "source": [
    "## Сравните результаты моделей HiddenMarkov, LstmTagger:\n",
    "* при обучение на маленькой части корпуса, например, на категории humor\n",
    "* при обучении на всем корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDdsG2AjO-sp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]language_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
